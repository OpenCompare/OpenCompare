This page contains general information about [[Nvidia]]'s [[Graphics processing unit|GPUs]] and videocards based on official Nvidia specifications.

{{toclimit|3}}

==DirectX version note==
[[DirectX]] version indicates which [[Direct3D]] graphics acceleration operations the card supports.
* Direct3D 6.0 - [[Texture mapping|Multitexturing]]
* Direct3D 7.0 - Hardware [[Transform and lighting|Transformation, Clipping and Lighting]] (TCL/T&L)
* Direct3D 8.0 - Pixel [[Shader]] 1.1 & Vertex Shader 1.1
* Direct3D 8.1 - Pixel Shader 1.4 & Vertex Shader 1.1
* Direct3D 9.0 - Shader Model 2.0
* Direct3D 9.0b - Pixel Shader 2.0b & Vertex Shader 2.0b
* Direct3D 9.0c - Shader Model 3.0, [[GPGPU]]
* Direct3D 9.0L - [[Windows Vista]] only, Vista version of DirectX 9.0c, Shader Model 3.0, Windows Graphics Foundation 1.0, [[DXVA]] 1.0, [[GPGPU]]
* Direct3D 10.0 - Windows Vista/Windows 7, [[Unified shader model|Shader Model 4.0]], Windows Graphics Foundation 2.0, DXVA 2.0, [[GPGPU]]
* Direct3D 10.1 - Windows Vista SP1/Windows 7, Shader Model 4.1, Windows Graphics Foundation 2.1, DXVA 2.1, [[GPGPU]]
* Direct3D 11.0 - [[Windows Vista]] (With Patch)/[[Windows 7]], Shader Model 5.0, Tessellation, Multithreaded rendering, Compute shaders, supported by hardware and software running Direct3D 9/10/10.1, [[GPGPU]]
* Direct3D 11.1 - [[Windows 8]], Stereoscopic 3D Rendering, [[GPGPU]]
* Direct3D 11.2 - [[Windows 8.1]], Tiled resources, [[GPGPU]]
* Direct3D 11.3<ref>http://www.anandtech.com/show/8526/nvidia-geforce-gtx-980-review/4</ref><ref>http://www.anandtech.com/show/8544</ref>
* Direct3D 12.0 - [[Windows 10]], low-level [[Rendering (computer graphics)|rendering]] [[Application programming interface|API]], [[GPGPU]]

==OpenGL version note==
[[OpenGL]] version indicates which graphics acceleration operations the card supports.
* OpenGL 1.1 - Texture objects
* OpenGL 1.2 - 3D Ttextures, BGRA and [[packed pixel]] formats<ref name='Gamedev1929'>{{cite news | first=Dave | last=Astle | coauthors= | title=Moving Beyond OpenGL 1.1 for Windows | date=2003-04-01 | publisher= | url =http://www.gamedev.net/reference/articles/article1929.asp | work =gamedev.net | pages = | accessdate = 2007-11-15 | language = }}</ref>
* OpenGL 1.3 - [[Texture mapping|Multitexturing]], [[multisampling]], texture compression
* OpenGL 1.4 - Depth textures
* OpenGL 1.5 - [[Vertex Buffer Object|VBO]], Occlusion Queries<ref name="OpenGLSpec">http://www.opengl.org/documentation/specs/version2.1/glspec21.pdf OpenGL 2.1 specification, retrieved Jule 18, 2008</ref>
* OpenGL 2.0 - [[GLSL]] 1.1, [[Multiple Render Targets|MRT]], Non Power of Two textures, [[Point Sprites]], Two-sided stencil<ref name="OpenGLSpec"/>
* OpenGL 2.1 - [[GLSL]] 1.2, Pixel Buffer Object (PBO), sRGB Textures<ref name="OpenGLSpec"/>
* OpenGL 3.0 - [[GLSL]] 1.3, Texture Arrays, Conditional rendering, FBO<ref name="OpenGL3Spec">http://www.opengl.org/registry/doc/glspec30.20080811.pdf OpenGL 3.0 specification, retrieved August 12, 2008</ref>
* OpenGL 3.1 - [[GLSL]] 1.4, Instancing, Texture Buffer Object, Uniform Buffer Object, Primitive restart<ref>[http://www.opengl.org/registry/doc/glspec31.20090528.pdf OpenGL 3.1 specification, retrieved October 1, 2009]</ref>
* OpenGL 3.2 - [[GLSL]] 1.5, Geometry Shaders, Multi-sampled textures<ref>[http://www.opengl.org/registry/doc/glspec32.core.20090803.pdf OpenGL 3.2 specification, retrieved October 1, 2009]</ref>
* OpenGL 3.3 - [[GLSL]] 3.30, Backports as much functionality possible from the OpenGL 4.0 specification
* OpenGL 4.0 - [[GLSL]] 4.00, Tessellation on GPU, shaders with 64-bit precision
* OpenGL 4.1 - [[GLSL]] 4.10, Developer-friendly debug outputs, compatibility with OpenGL ES 2.0
* OpenGL 4.2 - [[GLSL]] 4.20, Shaders with atomic counters, transform feedback, shader packing, performance improvements
* OpenGL 4.3 - [[GLSL]] 4.30, Shader storage buffer objects, Texture parameter queries, [[Ericsson Texture Compression|ETC2/EAC]], Increased memory security, A multi-application robustness extension
* OpenGL 4.4 - [[GLSL]] 4.40, Buffer Placement Control, Efficient Asynchronous Queries, Shader Variable Layout, Efficient Multiple Object Binding, Streamlined Porting of Direct3D applications, Bindless Texture Extension, Sparse Texture Extension
* OpenGL 4.5 - [[GLSL]] 4.50

==Field explanations==
The fields in the table listed below describe the following:

* '''Model''' - The marketing name for the processor assigned by Nvidia.
* '''Launch''' - Date of release for the processor.
* '''Code name''' - The internal engineering codename for the processor (typically designated by an NVXY name and later GXY where X is the series number and Y is the schedule of the project for that generation).
* '''[[Semiconductor device fabrication|Fab]]''' - Fabrication process. Average feature size of components of the processor.
* '''[[Bus (computing)|Bus interface]]''' - Bus by which the graphics processor is attached to the system (typically an expansion slot, such as PCI, AGP, or PCI-Express).
* '''[[Random-access memory|Memory]]''' - The amount of graphics memory available to the processor.
* '''SM Count''' - Number of streaming multiprocessors.<ref name="SMCount-motherboardsdotorg">{{cite web | url=http://www.motherboards.org/reviews/hardware/2038_5.html | title=NVIDIA GeForce GTX480 Video Card Review :: Streaming Multiprocessor | date=March 26, 2010 | author=Benjamin Sun}}</ref>
* '''Core [[Clock rate|clock]]''' - The factory core clock frequency (while some manufacturers adjust clocks lower and higher, this number will always be the reference clocks used by Nvidia).
* '''Memory clock''' - The factory effective memory clock frequency (while some manufacturers adjust clocks lower and higher, this number will always be the reference clocks used by Nvidia). All DDR/GDDR memories operate at half this frequency, except for GDDR5, which operates at one quarter of this frequency.
* '''Core config''' - The layout of the graphics pipeline, in terms of functional units. Over time the number, type, and variety of functional units in the GPU core has changed significantly; before each section in the list there is an explanation as to what functional units are present in each generation of processors. In later models, shaders are integrated into a unified shader architecture, where any one shader can perform any of the functions listed.
* '''[[Fillrate]]''' - Maximum theoretical fillrate in textured pixels per second. This number is generally used as a "maximum throughput number" for the GPU and generally, a higher fillrate corresponds to a more powerful (and faster) GPU.
* '''Memory subsection'''
** '''Bandwidth''' - Maximum theoretical bandwidth for the processor at factory clock with factory bus width. GB=10^9 bytes.
** '''Bus type''' - Type of memory bus or buses utilized.
** '''Bus width''' - Maximum bit width of the memory bus or buses utilized. This will always be a factory bus width.
* '''API support section'''
** '''DirectX''' - Maximum version of DirectX fully supported.
** '''OpenGL''' - Maximum version of OpenGL fully supported.
* '''Features''' - Additional features that are not standard as a part of the two graphics libraries.

==Comparison tables: Desktop GPUs==

===Pre-GeForce===
{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
!colspan=2|[[Application programming interface|API]] support
|-
!MOperations/s
!MPixels/s
!MTexels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
![[DirectX]]
![[OpenGL]]
|-
!style="text-align:left"|[[NV1|STG-2000]]
|September 1995
|NV1
|?
|PCI
|2<br>4
|12
|75
|1:1:1
|12
|12
|12
|0
|0.6
|EDO<br>VRAM
|64
|n/a
|n/a
|-
!style="text-align:left"|[[Riva 128|Riva128]]
|April 1997
|NV3
|350
|PCI
|4
|100
|100
|1:1:1
|100
|100
|100
|0
|1.6
|SDR
|128
|5.0
|1.0
|-
!style="text-align:left"|Riva128ZX
|February 23, 1998
|NV3
|350
|AGP 2x, PCI
|8
|100
|100
|1:1:1
|100
|100
|100
|0
|1.6
|SDR
|128
|5.0
|1.0
|-
!style="text-align:left"|[[Riva TNT]]
|March 23, 1998
|NV4
|350
|AGP 2x, PCI
|8<br>16
|90
|110
|2:2:2
|180
|180
|180
|0
|1.76
|SDR
|128
|6.0
|1.2
|-
!style="text-align:left"|Vanta
|March 22, 1999
|NV6
|250
|AGP 4x
|16
|100
|125
|2:2:2
|200
|200
|200
|0
|1
|SDR
|64
|6.0
|1.2
|-
!style="text-align:left"|Vanta LT
|March, 2000
|NV6
|250
|AGP 4x
|8<br>16
|80
|100
|2:2:2
|160
|160
|160
|0
|0.8
|SDR
|64
|6.0
|1.2
|-
!style="text-align:left"|Riva TNT2 M64
|October, 1999
|NV6
|250
|AGP 4x, PCI
|8, 16<br>32
|125
|150
|2:2:2
|250
|250
|250
|0
|1.2
|SDR
|64
|6.0
|1.2
|-
!style="text-align:left"|[[Riva TNT2]]
|March 15, 1999
|NV5
|250
|AGP 4x, PCI
|16<br>32
|125
|150
|2:2:2
|250
|250
|250
|0
|2.4
|SDR
|128
|6.0
|1.2
|-
!style="text-align:left"|[[Riva TNT2]] Pro
|October 12, 1999
|NV5
|220
|AGP 4x
|32
|143
|166
|2:2:2
|286
|286
|286
|0
|2.656
|SDR
|128
|6.0
|1.2
|-
!style="text-align:left"|[[Riva TNT2]] Ultra
|March 15, 1999
|NV5
|250
|AGP 4x
|16<br>32
|150
|183
|2:2:2
|300
|300
|300
|0
|2.928
|SDR
|128
|6.0
|1.2
|}

* <sup>1</sup> [[Pixel pipeline]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce256 Series===
{{Main|GeForce 256 }}
* All models are manufactured with a 220&nbsp;nm fabrication process
* All models support [[DirectX]] 7.0 and [[OpenGL]] 1.2
* All models support hardware Transform and Lighting (T&L) and Cube Environment Mapping

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce256
|October 11, 1999
|NV10
|AGP 4x<br>PCI
|32<br>64
|120
|166
|4:4:4
|480
|480
|480
|0
|2.656
|SDR
|128
|-
!style="text-align:left"|GeForce256 DDR
|February 1, 2000
|NV10
|AGP 4x<br>PCI
|32<br>64
|120
|300
|4:4:4
|480
|480
|480
|0
|4.8
|DDR
|128
|}

* <sup>1</sup> [[Pixel pipeline]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce2 Series===
{{Main|GeForce 2 Series}}

* All models are manufactured with a 180&nbsp;nm manufacturing process
* All models support [[DirectX]] 7 and [[OpenGL]] 1.2
* All models support TwinView Dual-Display Architecture, Second Generation Transform and Lighting (T&L), NVIDIA Shading Rasterizer (NSR), High-Definition Video Processor (HDVP)
* GeForce2 MX models support Digital Vibrance Control (DVC)

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce2 MX IGP + nForce 220/420
|June 4, 2001
|NV1A
|FSB
|Up to 32 system RAM
|175
|266
|2:4:2
|350
|350
|700
|0
|2.128<br>4.256
|DDR
|64<br>128
|-
!style="text-align:left"|GeForce2 MX200
|March 3, 2001
|NV11
|AGP 4x<br>PCI
|32<br>64
|175
|166
|2:4:2
|350
|350
|700
|0
|1.328
|SDR
|64
|-
!style="text-align:left"|GeForce2 MX
|June 28, 2000
|NV11
|AGP 4x<br>PCI
|32<br>64
|175
|166
|2:4:2
|350
|350
|700
|0
|2.656
|SDR
|128
|-
!style="text-align:left"|GeForce2 MX400
|March 3, 2001
|NV11
|AGP 4x<br>PCI
|32<br>64
|200
|166 (SDR)<br>332 (DDR)
|2:4:2
|400
|400
|800
|0
|2.656
|SDR<br>DDR
|128 (SDR)<br>64 (DDR)
|-
!style="text-align:left"|GeForce2 GTS
|April 26, 2000
|NV15
|AGP 4x<br>PCI
|32<br>64
|200
|332
|4:8:4
|800
|800
|1600
|0
|5.312
|DDR
|128
|-
!style="text-align:left"|GeForce2 Pro
|December 5, 2000
|NV15
|AGP 4x<br>PCI
|32<br>64
|200
|400
|4:8:4
|800
|800
|1600
|0
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce2 Ti
|October 1, 2001
|NV15
|AGP 4x<br>PCI
|32<br>64
|250
|400
|4:8:4
|1000
|1000
|2000
|0
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce2 Ultra
|August 14, 2000
|NV16
|AGP 4x<br>PCI
|64
|250
|460
|4:8:4
|1000
|1000
|2000
|0
|7.36
|DDR
|128
|}

* <sup>1</sup> [[Pixel pipeline]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce3 Series===
{{Main|GeForce 3 Series}}

* All models are manufactured with a 150&nbsp;nm manufacturing process
* All models support [[DirectX]] 8.0 and [[OpenGL]] 1.3
* All models support 3D Textures, Lightspeed Memory Architecture (LMA), nFiniteFX Engine, Shadow Buffers

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce3 Ti200
|October 1, 2001
|NV20
|AGP 4x<br>PCI
|64<br>128
|175
|400
|4:1:8:4
|700
|700
|1400
|42.75
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce3
|February 27, 2001
|NV20
|AGP 4x<br>PCI
|64
|200
|460
|4:1:8:4
|800
|800
|1600
|50
|7.36
|DDR
|128
|-
!style="text-align:left"|GeForce3 Ti500
|October 1, 2001
|NV20
|AGP 4x<br>PCI
|64<br>128
|240
|500
|4:1:8:4
|960
|960
|1920
|60
|8
|DDR
|128
|}

* <sup>1</sup>[[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce4 Series===
{{Main|GeForce 4 Series}}

* All models are manufactured with a 150&nbsp;nm manufacturing process
* All models support Accuview Antialiasing (AA), Lightspeed Memory Architecture II (LMA II), nView

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
!colspan=2|[[Application programming interface|API]] support (version)
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
![[DirectX]]
![[OpenGL]]
|-
!style="text-align:left"|GeForce4 MX IGP + nForce2
|October 1, 2002
|NV1F
|FSB
|Up to 128 system RAM
|250
|266<br>400{{citation needed|date=September 2012}}<!-- originally was 266-400 -->
|2:0:4:2
|500
|500
|1000
|0
|2.128<br>6.4{{citation needed|date=September 2012}}<!-- originally was 2.128-6.4 -->
|DDR
|64<br>128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 MX420
|February 6, 2002
|NV17
|AGP 4x<br>PCI
|64
|250
|166
|2:0:4:2
|500
|500
|1000
|0
|2.656
|SDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 MX440 SE
|2002
|NV17
|AGP 4x<br>PCI
|64<br>128
|250
|332
|2:0:4:2
|500
|500
|1000
|0
|5.312
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce MX4000 
|December 14, 2003
|NV18B
|AGP 8x<br>PCI
|64<br />128
|250
|332
|2:0:4:2
|500
|500
|1000
|0
|2.656
|DDR
|64
|7.0
|1.2
|-
!style="text-align:left"|GeForce PCX4300 
|February 19, 2004
|NV18B
|PCI-E x16
|128
|250
|666
|2:0:4:2
|500
|500
|1000
|0
|5.328
|DDR
|64
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 MX440
|February 6, 2002
|NV17
|AGP 4x<br>PCI
|64<br>128
|275
|400
|2:0:4:2
|550
|550
|1100
|0
|6.4
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 MX440 8x
|September 25, 2002
|NV18
|AGP 8x<br>PCI
|64<br>128
|275
|500
|2:0:4:2
|550
|550
|1100
|0
|8
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 MX460
|February 6, 2002
|NV17
|AGP 4x<br>PCI
|64<br>128
|300
|550
|2:0:4:2
|600
|600
|1200
|0
|8.8
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Ti4200
|April 16, 2002
|NV25
|AGP 4x
|64<br>128
|250
|444 (128 MB)<br>500 (64 MB)
|4:2:8:4
|1000
|1000
|2000
|125
|7.104 (128 MB)<br>8 (64 MB)
|DDR
|64<br>128
|8.1
|1.3
|-
!style="text-align:left"|GeForce4 Ti4400
|February 6, 2002
|NV25
|AGP 4x
|128
|275
|550 
|4:2:8:4
|1100
|1100
|2200
|137.5
|8.8
|DDR
|128
|8.1
|1.3
|-
!style="text-align:left"|GeForce4 Ti4800 SE
|January 20, 2003
|NV28
|AGP 8x
|128
|275
|550
|4:2:8:4
|1100
|1100
|2200
|137.5
|8.8
|'''DDR'''
|128
|8.1
|1.3
|-
!style="text-align:left"|GeForce4 Ti4600
|February 6, 2002
|NV25
|AGP 4x
|128
|300
|650 
|4:2:8:4
|1200
|1200
|2400
|150
|10.4
|DDR
|128
|8.1
|1.3
|-
!style="text-align:left"|GeForce4 Ti4800
|January 20, 2003
|NV28
|AGP 8x
|128
|300
|640
|4:2:8:4
|1200
|1200
|2400
|150
|10.4
|DDR
|128
|8.1
|1.3
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
!colspan=2|[[Application programming interface|API]] support (version)
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
![[DirectX]]
![[OpenGL]]
|-
|}

*<sup>1</sup>[[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=5 style="text-align:center;" | Features
|-
! nFiniteFX II Engine
! Video Processing Engine (VPE)
|-
! style="text-align:left;"| GeForce4 MX420
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce4 MX440 SE
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce4 MX4000
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce4 PCX4300
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce4 MX440
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce4 MX440 8X
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce4 MX460
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce4 Ti4200
| {{yes}}
| {{no}}
|-
! style="text-align:left;"| GeForce4 Ti4400
| {{yes}}
| {{no}}
|-
! style="text-align:left;"| GeForce4 Ti4600
| {{yes}}
| {{no}}
|-
! style="text-align:left;"| GeForce4 Ti4800
| {{yes}}
| {{no}}
|}

===GeForce FX (5xxx) Series===
{{Main|GeForce FX Series}}

* All models support [[DirectX]] 9.0b and [[OpenGL]] 1.5 (2.1 (software) with latest drivers)
* The GeForce FX Series runs vertex shaders in an array

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce FX 5200
|March 2003
|NV34
|150
|AGP 8X<br>PCI
|64<br>128
|250
|400
|4:1:4:4
|1000
|1000
|1000
|62.5
|3.2<br>6.4{{citation needed|date=September 2012}}<!-- originally was 3.2-6.4 -->
|DDR
|64<br>128
|-
!style="text-align:left"|GeForce FX 5200 Ultra
|March 6, 2003
|NV34
|150
|AGP 8X
|64<br>128
|325
|650
|4:1:4:4
|1300
|1300
|1300
|81.25
|10.4
|DDR
|128
|-
!style="text-align:left"|GeForce PCX 5300
|March 17, 2004
|NV34
|150
|PCI-E x16
|128
|250
|400
|4:1:4:4
|1000
|1000
|1000
|62.5
|3.2<br>6.4{{citation needed|date=September 2012}}<!-- originally was 3.2-6.4 -->
|DDR
|64<br>128
|-
!style="text-align:left"|GeForce FX 5500
|March 2004
|NV34B
|140
|AGP 8X<br>AGP 4X<br>PCI
|64<br>128<br>256
|270
|400
|4:1:4:4
|1080
|1080
|1080
|67.5
|3.2<br>6.4{{citation needed|date=September 2012}}<!-- originally was 3.2-6.4 -->
|DDR
|64<br>128
|-
!style="text-align:left"|GeForce FX 5600 XT
|October 2003
|NV31
|130
|AGP 8X
|64<br>128
|235
|400
|4:1:4:4
|940
|940
|940
|58.75
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5600
|March 2003
|NV31
|130
|AGP 8X<br>PCI
|64<br>128<br>256<ref>[http://www.nvidia.com/page/fx_5600.html GeForce FX 5600] www.nvidia.com</ref>
|325
|550
|4:1:4:4
|1300
|1300
|1300
|81.25
|8.8
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5600 Ultra
|March 6, 2003
|NV31
|130
|AGP 8X
|64<br>128
|350
|700
|4:1:4:4
|1400
|1400
|1400
|87.5
|11.2
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5600 Ultra Rev.2
|March 6, 2003
|NV31
|130
|AGP 8X
|64<br>128
|400
|800
|4:1:4:4
|1600
|1600
|1600
|100
|12.8
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5700 VE
|September 2004
|NV36
|130
|AGP 8X
|128<br>256
|235
|400
|4:3:4:4
|940
|940
|940
|106.5
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5700 LE
|March 2004
|NV36
|130
|AGP 8X
|128<br>256
|250
|400
|4:3:4:4
|1000
|1000
|1000
|187.5
|6.4
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5700
|2003
|NV36
|130
|AGP 8X
|128<br>256
|425
|500
|4:3:4:4
|1700
|1700
|1700
|318.75
|8
|DDR
|128
|-
!style="text-align:left"|GeForce PCX 5750
|March 17, 2004
|NV36
|130
|PCI-E x16
|128
|425
|500
|4:3:4:4
|1700
|1700
|1700
|318.75
|8
|DDR
|128
|-
!style="text-align:left"|GeForce FX 5700 Ultra
|October 23, 2003
|NV36
|130
|AGP 8X
|128<br>256
|475
|900
|4:3:4:4
|1900
|1900
|1900
|356.25
|14.4
|GDDR2
|128
|-
!style="text-align:left"|GeForce FX 5700 Ultra GDDR3
|March 15, 2004
|NV36
|130
|AGP 8X
|128<br>256
|475
|950
|4:3:4:4
|1900
|1900
|1900
|356.25
|15.2
|GDDR3
|128
|-
!style="text-align:left"|GeForce FX 5800
|January 27, 2003
|NV30
|130
|AGP 8X
|128
|400
|800
|4:2:8:4
|1600
|1600
|3200
|200
|12.8
|GDDR2
|128
|-
!style="text-align:left"|GeForce FX 5800 Ultra
|January 27, 2003
|NV30
|130
|AGP 8X
|256
|500
|1000
|4:2:8:4
|2000
|2000
|4000
|250
|16
|GDDR2
|128
|-
!style="text-align:left"|GeForce FX 5900 ZT
|December 15, 2003
|NV35
|130
|AGP 8X
|128
|325
|700
|4:3:8:4
|1300
|1300
|2600
|343.75
|22.4
|DDR
|256
|-
!style="text-align:left"|GeForce FX 5900 XT
|2003
|NV35
|130
|AGP 8X
|128
|390
|700
|4:3:8:4
|1600
|1600
|3200
|300
|22.4
|DDR
|256
|-
!style="text-align:left"|GeForce FX 5900
|May 2003
|NV35
|130
|AGP 8X
|128
|400
|850
|4:3:8:4
|1600
|1600
|3200
|300
|27.2
|DDR
|256
|-
!style="text-align:left"|GeForce FX 5900 Ultra
|May 12, 2003
|NV35
|130
|AGP 8X
|128<br>256
|450
|850
|4:3:8:4
|1800
|1800
|3600
|337.5
|27.2
|DDR
|256
|-
!style="text-align:left"|GeForce PCX 5900
|March 17, 2004
|NV35
|130
|PCI-E x16
|128<br>256
|450
|850
|4:3:8:4
|1800
|1800
|3600
|337.5
|27.2
|DDR
|256
|-
!style="text-align:left"|GeForce FX 5950 Ultra
|October 23, 2003
|NV38
|130
|AGP 8X
|256
|475
|950
|4:3:8:4
|1900
|1900
|3800
|356.25
|30.4
|DDR
|256
|-
!style="text-align:left"|GeForce PCX 5950
|February 17, 2004
|NV38
|130
|PCI-E x16
|256
|475
|950
|4:3:8:4
|1900
|1900
|3800
|356.25
|30.4
|GDDR3
|256
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
|}

* <sup>1</sup> [[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce 6 (6xxx) Series===
{{Main|GeForce 6 Series}}

* All models support [[DirectX]] 9.0c and [[OpenGL]] 2.1
* All models support Transparency [[Spatial anti-aliasing|AA]] (starting with version 91.47 of the ForceWare drivers) and PureVideo

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce 6100 + nForce 410
|October 20, 2005
|MCP51
|90
|HyperTransport
|Up to 256 system RAM
|425
|200-400 (DDR)<br>400-1066 (DDR2)
|2:1:2:1
|850
|425
|850
|106.25
|1.6-6.4 (DDR)<br>3.2-17.056 (DDR2)
|DDR<br>DDR2
|64<br>128
|-
!style="text-align:left"|GeForce 6150 SE + nForce 430
|June 2006
|MCP61
|90
|HyperTransport
|Up to 256 system RAM
|425
|400<br>800{{citation needed|date=September 2012}}<!-- originally was 400-800 -->
|2:1:2:1
|850
|425
|850
|106.25
|3.2<br>16.0{{citation needed|date=September 2012}}<!-- originally was 3.2-16.0 -->
|DDR2
|64<br>128
|-
!style="text-align:left"|GeForce 6150 LE + nForce 430
|June 2006
|MCP61
|90
|HyperTransport
|Up to 256 system RAM
|425
|200-400 (DDR)<br>400-1066 (DDR2)
|2:1:2:1
|850
|425
|850
|106.25
|1.6-6.4 (DDR)<br>3.2-17.056 (DDR2)
|DDR<br>DDR2
|64<br>128
|-
!style="text-align:left"|GeForce 6150 + nForce 430
|October 20, 2005
|MCP51
|90
|HyperTransport
|Up to 256 system RAM
|475
|200-400 (DDR)<br>400-1066 (DDR2)
|2:1:2:1
|950
|475
|950
|118.75
|1.6-6.4 (DDR)<br>3.2-17.056 (DDR2)
|DDR<br>DDR2
|64<br>128
|-
!style="text-align:left"|GeForce 6200 LE
|2005
|NV44
|110
|AGP 8x<br>PCI-E x16
|128<br>256
|350
|532
|2:1:2:2
|700
|700
|700
|87.5
|4.256
|DDR
|64
|-
!style="text-align:left"|GeForce 6200A
|April 4, 2005
|NV44A
|110
|AGP 8x
|128
|350
|500
|4:2:4:4
|1400
|1400
|1400
|175
|4
|DDR
|64
|-
!style="text-align:left"|GeForce 6200 
|October 12, 2004 (PCI-E)<br>January 17, 2005 (AGP)
|NV43
|110
|AGP 8x<br>PCI<br>PCI-E x16
|128<br>256
|300
|550
|4:3:4:2
|1200
|600
|1200
|225
|8.8
|DDR2
|128
|-
!style="text-align:left"|GeForce 6200 TurboCache
|December 15, 2004
|NV44
|110
|PCI-E x16
|128-256 System RAM incl.16/32-64/128 onboard
|350
|700
|4:3:4:2
|1400
|700
|1400
|262.5
|5.6
|DDR
|64
|-
!style="text-align:left"|GeForce 6500
|October 1, 2005
|NV44
|110
|PCI-E x16
|128<br>256 
|400
|666
|4:3:4:2
|1600
|800
|1600
|300
|5.328
|DDR
|128
|- 
!style="text-align:left"|GeForce 6600 LE
|2005
|NV43
|110
|AGP 8x<br>PCI-E x16
|128<br>256 
|300
|400
|4:3:4:4
|1200
|1200
|1200
|225
|6.4
|DDR
|128
|- 
!style="text-align:left"|GeForce 6600
|August 12, 2004
|NV43
|110
|AGP 8x<br>PCI-E x16
|128<br>256 
|300
|550
|8:3:8:4
|2400
|1200
|2400
|225
|8.8
|DDR
|128
|- 
!style="text-align:left"|GeForce 6600 GT
|August 12, 2004 (PCI-E)<br>November 14, 2004 (AGP)
|NV43
|110
|AGP 8x<br>PCI-E x16
|128<br>256 
|500
|950 (AGP)<br>1000 (PCI-E)
|8:3:8:4
|4000
|2000
|4000
|375
|15.2<ref>{{cite web |url=http://www.techpowerup.com/gpudb/115/geforce-6600-gt-agp.html |title=NVIDIA GeForce 6600 GT AGP |accessdate=2015-04-16}}</ref> (AGP)<br>16 (PCI-E)
|GDDR3
|128
|- 
!style="text-align:left"|GeForce 6800 LE
|July 22, 2004 (AGP)<br>January 16, 2005 (PCI-E)
|NV40 (AGP)<br>NV41 (PCI-E)
|130
|AGP 8x<br>PCI-E x16
|128 
|320 (AGP)<br>325 (PCI-E)
|700
|8:4:8:8
|2560 (AGP)<br>2600 (PCI-E)
|2560 (AGP)<br>2600 (PCI-E)
|2560 (AGP)<br>2600 (PCI-E)
|320 (AGP)<br>325 (PCI-E)
|22.4
|DDR
|256
|- 
!style="text-align:left"|GeForce 6800 XT
|September 30, 2005
|NV40 (AGP)<br>NV41 (PCI-E)
|130
|AGP 8x<br>PCI-E x16
|256
|325
|700
|8:4:8:8
|2600 
|2600 
|2600 
|325 
|22.4
|DDR
|256
|- 
!style="text-align:left"|GeForce 6800
|April 14, 2004 (AGP)<br>November 8, 2004 (PCI-E)
|NV40 (AGP)<br>NV41 (PCI-E)
|130
|AGP 8x<br>PCI-E x16
|128<br>256 
|325
|700
|12:5:12:12
|3900
|3900
|3900
|406.25
|22.4
|DDR
|256
|- 
!style="text-align:left"|GeForce 6800 GTO 
|April 14, 2004 
|NV45
|130
|PCI-E x16
|256 
|350
|900
|12:5:12:12
|4200
|4200
|4200
|437.5
|28.8
|GDDR3
|256
|-
!style="text-align:left"|GeForce 6800 GS 
|November 7, 2005 (PCI-E)<br>December 8, 2005 (AGP) 
|NV40 (AGP)<br>NV42 (PCI-E)
|130
|PCI-E x16
|128<br>256
|425
|1000
|12:5:12:12
|5100
|5100
|5100
|531.25
|32
|GDDR3
|256
|-
!style="text-align:left"|GeForce 6800 GT
|May 4, 2004 (AGP)<br>June 28, 2004 (PCI-E)
|NV40 (AGP)<br>NV45 (PCI-E)
|130
|AGP 8x<br>PCI-E x16
|128<br>256
|350
|1000
|16:6:16:16
|5600
|5600
|5600
|525
|32
|GDDR3
|256
|- 
!style="text-align:left"|GeForce 6800 Ultra
|May 4, 2004 (AGP)<br>June 28, 2004 (PCI-E)<br>March 14, 2005 (512 MB)
|NV40 (AGP)<br>NV45 (PCI-E)
|130
|AGP 8x<br>PCI-E x16
|256<br>512
|400
|1050 (512 MB)<br>1100 (256 MB)
|16:6:16:16
|6400
|6400
|6400
|600
|33.6 (512 MB)<br>35.2 (256 MB)
|GDDR3
|256
|- 
!style="text-align:left"|GeForce 6800 Ultra Extreme
|May 4, 2004
|NV40 
|130
|AGP 8x
|256
|450
|1100 
|16:6:16:16
|7200
|7200
|7200
|675
|35.2 
|GDDR3
|256
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
|}

* <sup>1</sup> [[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

====Features====
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=6 style="text-align:center;" | Features
|-
! OpenEXR HDR
! [[Scalable Link Interface]] (SLI)
! [[TurboCache]]
! [[Nvidia PureVideo|PureVideo]] WMV9 Decoding
|-
! style="text-align:left;"| GeForce 6100
| {{no}}
| {{no}}
| {{no}}
| {{Partial|Limited}}
|-
! style="text-align:left;"| GeForce 6150 SE
| {{no}}
| {{no}}
| {{Partial|Driver-Side Only}}
| {{Partial|Limited}}
|-
! style="text-align:left;"| GeForce 6150
| {{no}}
| {{no}}
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce 6150 LE
| {{no}}
| {{no}}
| {{Partial|Driver-Side Only}}
| {{yes}}
|-
! style="text-align:left;"| GeForce 6200
| {{no}}
| {{no}}
| {{yes2}} Yes (PCI-E only)
| {{yes}}
|-
! style="text-align:left;"| GeForce 6500
| {{no}}
| {{yes}}
| {{yes}}
| {{yes}}
|-
! style="text-align:left;"| GeForce 6600 LE
| {{yes}}
| {{yes2}} Yes (No SLI Connector)
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce 6600
| {{yes}}
| {{yes2}} Yes (SLI Connector or PCI-E Interface)
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce 6600 DDR2
| {{yes}}
| {{yes2}} Yes (SLI Connector or PCI-E Interface)
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce 6600 GT
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
|-
! style="text-align:left;"| GeForce 6800 LE
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
|-
! style="text-align:left;"| GeForce 6800 XT
| {{yes}}
| {{yes2}} Yes (PCI-E only)
| {{no}}
| {{yes2}} Yes (NV42 only)
|-
! style="text-align:left;"| GeForce 6800
| {{yes}}
| {{yes2}} Yes (PCI-E only)
| {{no}}
| {{yes2}} Yes (NV41, NV42 only)
|-
! style="text-align:left;"| GeForce 6800 GTO
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
|-
! style="text-align:left;"| GeForce 6800 GS
| {{yes}}
| {{yes2}} Yes (PCI-E only)
| {{no}}
| {{yes2}} Yes (NV42 only)
|-
! style="text-align:left;"| GeForce 6800 GT
| {{yes}}
| {{yes2}} Yes (PCI-E only)
| {{no}}
| {{no}}
|-
! style="text-align:left;"| GeForce 6800 Ultra
| {{yes}}
| {{yes2}} Yes (PCI-E only)
| {{no}}
| {{no}}
|-
|}

===GeForce 7 (7xxx) Series===
{{Main|GeForce 7 Series}}

* All models support [[DirectX]] 9.0c and [[OpenGL]] 2.1
* All models support Transparency [[Spatial anti-aliasing|AA]] (starting with version 91.47 of the ForceWare drivers)

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce 7025 + nForce 630a
|July 2007
|MCP68S
|110
|HyperTransport
|Up to 256 system RAM
|425
|533<br>800{{citation needed|date=September 2012}}<!-- originally was 533-800 -->
|2:1:2:2
|850
|850
|850
|106.25
|8.528<br>12.8{{citation needed|date=September 2012}}<!-- originally was 8.528-12.8 -->
|DDR2
|128
|-
!style="text-align:left"|GeForce 7050PV + nForce 630a
|July 2007
|MCP67QV
|110
|HyperTransport
|Up to 256 system RAM
|425
|533<br>800{{citation needed|date=September 2012}}<!-- originally was 533-800 -->
|2:1:2:2
|850
|850
|850
|106.25
|8.528<br>12.8{{citation needed|date=September 2012}}<!-- originally was 8.528-12.8 -->
|DDR2
|128
|- 
!style="text-align:left"|GeForce 7050 + nForce 610i/630i
|July 2007
|MCP73
|90
|HyperTransport/FSB
|Up to 256 system RAM
|500
|667
|2:1:2:2
|1000
|1000
|1000
|125
|5.336
|DDR2
|64
|-
!style="text-align:left"|GeForce 7100 + nForce 630i
|July 2007
|MCP76
|90
|FSB
|Up to 256 system RAM
|600
|800
|2:1:2:2
|1200
|1200
|1200
|150
|6.4
|DDR2
|64
|-
!style="text-align:left"|GeForce 7150 + nForce 630i
|July 2007
|MCP76
|90
|FSB
|Up to 256 system RAM
|630
|800
|2:1:2:2
|1260
|1260
|1260
|157.5
|6.4
|DDR2
|64
|-
!style="text-align:left"|GeForce 7100 GS
|August 8, 2006
|NV44
|110
|PCI-E x16
|128<br>256
|350
|600
|4:3:4:2
|1400
|700
|1400
|262.5
|4.8
|DDR2
|64
|-
!style="text-align:left"|GeForce 7200 GS
|January 18, 2006
|G72
|90
|AGP 8x<br>PCI-E x16
|128<br>256
|450
|800
|2:2:4:2
|1800
|900
|1800
|337.5
|6.4
|DDR2
|64
|-
!style="text-align:left"|GeForce 7300 SE
|March 22, 2006
|G72
|90
|PCI-E x16
|128
|350
|666
|4:3:4:2
|1800
|900
|1800
|337.5
|5.328
|DDR2
|64
|-
!style="text-align:left"|GeForce 7300 LE
|March 22, 2006
|G72
|90
|PCI-E x16
|128
|350
|666
|4:3:4:2
|1800
|900
|1800
|337.5
|5.328
|DDR2
|64
|-
!style="text-align:left"|GeForce 7300 GS
|January 18, 2006
|G72
|90
|AGP 8x<br>PCI-E x16
|128<br>256
|550
|800
|4:3:4:2
|2200
|1100
|2200
|412.5
|6.4
|DDR2
|64
|-
!style="text-align:left"|GeForce 7300 GT
|May 15, 2006
|G73
|90
|AGP 8x<br>PCI-E x16
|128<br>256
|350
|650
|8:5:8:4
|2800
|1400
|2800
|437.5
|10.4
|DDR2
|128
|-
!style="text-align:left"|GeForce 7500 LE
|
|G72
|90
|AGP 8x<br>PCI-E x16
|64<br>128<br>256
|263<br>324
|550
|4:3:4:2
|900<br>1100
|900<br>1100
|2200
|412.5
|2.6<br>6.8
|DDR2
|32<br>64
|-
!style="text-align:left"|GeForce 7600 GS
|March 22, 2006 (PCI-E)<br>July 1, 2006 (AGP)
|G73
|90
|AGP 8x<br>PCI-E x16
|256
|400
|800
|12:5:12:8
|4800
|3200
|4800
|500
|12.8
|DDR2
|128
|-
!style="text-align:left"|GeForce 7600 GT
|March 9, 2006 (PCI-E)<br>July 15, 2006 (AGP)
|G73
|90
|AGP 8x<br>PCI-E x16
|256
|560
|1400
|12:5:12:8
|6720
|4480
|6720
|700
|22.4
|GDDR3
|128
|-
!style="text-align:left"|GeForce 7600 GT 80&nbsp;nm
|January 8, 2007
|G73-B1
|80
|AGP 8x<br>PCI-E x16
|256
|560
|1400
|12:5:12:8
|6720
|4480
|6720
|700
|22.4
|GDDR3
|128
|-
!style="text-align:left"|GeForce 7800 GS
|February 2, 2006
|G70
|110
|AGP 8x
|256
|375
|1200
|16:8:16:8
|6000
|3000
|6000
|562.5
|38.4
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7800 GT
|August 11, 2005
|G70
|110
|PCI-E x16
|256
|400
|1000
|20:7:20:16
|8000
|6400
|8000
|700
|32
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7800 GTX
|June 22, 2005 (256 MB)<br>November 14, 2005 (512 MB)
|G70
|110
|PCI-E x16
|256<br>512
|430 (256 MB)<br>550 (512 MB)
|1200 (256 MB)<br>1700 (512 MB)
|24:8:24:16
|10320 (256 MB)<br>13200 (512 MB)
|6880 (256 MB)<br>8800 (512 MB)
|10320 (256 MB)<br>13200 (512 MB)
|860 (256 MB)<br>1100 (512 MB)
|38.4 (256 MB)<br> 54.4 (512 MB)
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7900 GS
|May 2006 (PCI-E)<br>April 2, 2007 (AGP)
|G71
|90
|AGP 8x<br>PCI-E x16
|256
|450
|1320
|20:7:20:16
|9000
|7200
|9000
|787.5
|42.24
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7900 GT
|March 9, 2006
|G71
|90
|PCI-E x16
|256
|450
|1320
|24:8:24:16
|10800
|7200
|10800
|900
|42.24
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7900 GTO
|October 1, 2006
|G71
|90
|PCI-E x16
|512
|650
|1320
|24:8:24:16
|15600
|10400
|15600
|1300
|42.24
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7900 GTX
|March 9, 2006
|G71
|90
|PCI-E x16
|512
|650
|1600
|24:8:24:16
|15600
|10400
|15600
|1300
|51.2
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7900 GX2
|March 9, 2006
|G71 x2
|90
|PCI-E x16
|1024
|500
|1200
|24:8:24:16 x2
|24000
|16000
|24000
|2000
|76.8
|GDDR3
|512
|-
!style="text-align:left"|GeForce 7950 GT
|September 6, 2006 (PCI-E)<br>April 2, 2007 (AGP)
|G71
|90
|AGP 8x<br>PCI-E x16
|512
|550
|1400
|24:8:24:16
|13200
|8800
|13200
|1100
|44.8
|GDDR3
|256
|-
!style="text-align:left"|GeForce 7950 GX2
|June 5, 2006
|G71 x2
|90
|PCI-E x16
|1024
|500
|1200
|24:8:24:16 x2
|24000
|16000
|24000
|2000
|76.8
|GDDR3
|512
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
|}
* <sup>1</sup> [[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

====Features====
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=6 style="text-align:center;" | Features
|-
! Gamma-correct antialiasing
! 64-bit OpenEXR HDR
! Scalable Link Interface (SLI)
! TurboCache
! Dual Link DVI
|-
! style="text-align:left;"| GeForce 7100 GS
| {{no}}
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
|-
! style="text-align:left;"| GeForce 7200 GS
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
|-
! style="text-align:left;"| GeForce 7300 SE
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
|-
! style="text-align:left;"| GeForce 7300 LE
| {{yes}}
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
|-
! style="text-align:left;"| GeForce 7300 GS
| {{yes}}
| {{yes}}
| {{yes2}} Yes (PCI-E only)<br>(No SLI bridge)
| {{yes}}
| {{no}}
|-
! style="text-align:left;"| GeForce 7300 GT
| {{yes}}
| {{yes}}
| {{yes2}} Yes (PCI-E only)<br>(No SLI bridge)
| {{no}}
| {{yes|One port}}
|-
! style="text-align:left;"| GeForce 7600 GS
| {{yes}}
| {{yes}}
| {{yes2}} Yes (PCI-E only)
| {{no}}
| {{yes|One port}}
|-
! style="text-align:left;"| GeForce 7600 GT
| {{yes}}
| {{yes}}
| {{yes2}} Yes (PCI-E only)
| {{no}}
| {{yes|One port}}
|-
! style="text-align:left;"| GeForce 7600 GT (80&nbsp;nm)
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes|One port}}
|-
! style="text-align:left;"| GeForce 7650 GS (80&nbsp;nm)
| {{yes}}
| {{yes}}
| {{yes2}} Yes (Depending on OEM Design)
| {{no}}
| {{yes|One port}}
|-
! style="text-align:left;"| GeForce 7800 GS
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes|One port}}
|-
! style="text-align:left;"| GeForce 7800 GT
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes|One port}}
|-
! style="text-align:left;"| GeForce 7800 GTX
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes|One port}}
|-
! style="text-align:left;"| GeForce 7800 GTX 512
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes|One port}}
|-
! style="text-align:left;"| GeForce 7900 GS
| {{yes}}
| {{yes}}
| {{yes2}} Yes (PCI-E only)
| {{no}}
| {{yes|Two ports}}
|-
! style="text-align:left;"| GeForce 7900 GT
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes|Two ports}}
|-
! style="text-align:left;"| GeForce 7900 GTO
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes|Two ports}}
|-
! style="text-align:left;"| GeForce 7900 GTX
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes|Two ports}}
|-
! style="text-align:left;"| GeForce 7950 GT
| {{yes}}
| {{yes}}
| {{yes2}} Yes (PCI-E only)
| {{no}}
| {{yes|Two ports}}
|-
! style="text-align:left;"| GeForce 7950 GX2
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{yes|Two ports}}
|}

===GeForce 8 (8xxx) Series===
{{Main|GeForce 8 Series|Tesla (microarchitecture)}}
All models support Coverage Sample Anti-Aliasing, Angle-Independent Anisotropic Filtering, 128-bit OpenEXR HDR
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Full G80 contains 32 texture address units and 64 texture filtering units unlike G92 which contains 64 texture address units and 64 texture filtering units<ref>[http://www.anandtech.com/show/2549/3 NVIDIA's 1.4 Billion Transistor GPU: GT200 Arrives as the GeForce GTX 280 & 260]</ref><ref>[http://www.anandtech.com/show/2116/6 NVIDIA's GeForce 8800 (G80): GPUs Re-architected for DirectX 10(page 6 of 29)]</ref>

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 | Clock rate
! colspan=2 | [[Fillrate]]
! colspan=3 | Memory
! colspan=2 | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power ([[GFLOPS]])
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;"| GeForce 8100 mGPU<ref name="8x00_mGPU">[http://www.tomshardware.com/reviews/amd-nvidia-chipset,1972-14.html Chipset Comparison Table]</ref>
| 2008
| MCP78
| 80
| {{unk}}
| {{unk}}
| PCIe 2.0 x16
| Up to 512 from system memory
| 8:8:4
| 500
| 1200
| 800<br>(system memory)
| 2
| 4
| 6.4<br>12.8
| DDR2
| 64<br>128
| 10.0
| 3.3
| 28.8
| {{unk}}
| {{unk}}
| The block of decoding of HD-video PureVideo HD is disconnected
|-
! style="text-align:left;"| GeForce 8200 mGPU<ref name="8x00_mGPU"/>
| 2008
| MCP78
| 80
| {{unk}}
| {{unk}}
| PCIe 2.0 x16
| Up to 512 from system memory
| 8:8:4
| 500
| 1200
| 800<br>(system memory)
| 2
| 4
| 6.4<br>12.8
| DDR2
| 64<br>128
| 10.0
| 3.3
| 28.8
| {{unk}}
| {{unk}}
| [[PureVideo]] 3 with VP3
|-
! style="text-align:left;"| GeForce 8300 mGPU<ref name="8x00_mGPU"/>
| 2008
| MCP78
| 80
| {{unk}}
| {{unk}}
| PCIe 2.0 x16
| Up to 512 from system memory
| 8:8:4
| 500
| 1500
| 800<br>(system memory)
| 2
| 4
| 6.4<br>12.8
| DDR2
| 64<br>128
| 10.0
| 3.3
| 36
| {{unk}}
| {{unk}}
| [[PureVideo]] 3 with VP3
|-
! style="text-align:left;" | GeForce 8300 GS<ref name=G84_G86_Shader_Specs>[http://www.theinquirer.net/default.aspx?article=38884 Nvidia GF8600/8500/8300 details revealed], Theinquirer.net, accessed April 12, 2007.</ref>
| July 2007
| G86<br>G98
| 65
| 210
| 86
| PCIe 2.0 x16
| 128<br>512
| 8:8:4
| 450
| 900
| 800
| 1.8
| 3.6
| 6.4
| DDR2
| 64
| 10.0
| 3.3
| 22
| 40
| 0.55
| OEM only
|-
! style="text-align:left;" | GeForce 8400 GS
| June 15, 2007
| G86
| 80
| 210
| 127
| PCIe 1.0 x16<br>PCI
| 128<br>256<br>512
| 16:8:4
| 450
| 900
| 800
| 1.8
| 3.6
| 6.4
| DDR2
| 64
| 10.0
| 3.3
| 43
| 40
| 1.08
|
|-
! style="text-align:left;" | GeForce 8400 GS rev.2
| December 4, 2007
| G98
| 65
| 210
| 86
| PCIe 2.0 x16<br>PCIe x1<br>PCI
| 128<br>256<br>512
| 8:8:4
| 567
| 1400
| 800
| 2.268
| 4.536
| 6.4
| DDR2
| 64
| 10.0
| 3.3
| 33
| 25
| 1.32
|
|-
! style="text-align:left;" | GeForce 8400 GS rev.3
| April 2009
| GT218
| 40
| 260
| 57
| PCIe 2.0 x16
| 512<br>1024
| 8:4:4
| 520<br>589
| 1230
| 600 (1200)
| 2.08<br>2.356
| 2.08<br>2.356
| 4.8<br>9.6
| DDR3
| 32<br>64
| 10.1
| 3.3
| 30.5
| 25
| 1.22
|
|-
! style="text-align:left;"| GeForce 8500 GT
| April 17, 2007
| G86
| 80
| 210
| 127
| PCIe 1.0 x16<br>PCI
| 256<br>512<br>1024
| 16:8:4
| 450
| 900
| 400 (800)
| 1.8
| 3.6
| 12.8
| DDR2
| 128
| 10.0
| 3.3
| 43
| 45
| 0.96
|
|-
! style="text-align:left;"| GeForce 8600 GS
| April 2007
| G84
| 80
| 289
| 169
| PCIe 1.0 x16
| 256<br>512
| 32:16:8
| 540
| 1180
| 800
| 4.32
| 8.64
| 12.8
| DDR2
| 128
| 10.0
| 3.3
| 113
| 47
| 2.40
| OEM only
|-
! style="text-align:left;"| GeForce 8600 GT
| April 17, 2007
| G84
| 80
| 289
| 169
| PCIe 1.0 x16<br>PCI
| 256<br>512<br>1024
| 32:16:8
| 540
| 1188
| 800<br>1400
| 4.32
| 8.64
| 12.8<br>22.4
| DDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 113
| 47
| 2.40
|
|-
! style="text-align:left;"| GeForce 8600 GTS
| April 17, 2007
| G84
| 80
| 289
| 169
| PCIe 1.0 x16
| 256<br>512
| 32:16:8
| 675
| 1450
| 2000
| 5.4
| 10.8
| 32
| GDDR3
| 128
| 10.0
| 3.3
| 139
| 75
| 1.85
|
|-
! style="text-align:left;"| GeForce 8800 GS
| Jan 2008
| G92
| 65
| 754
| 324
| PCIe 2.0 x16
| 384<br>768
| 96:48:12
| 550
| 1375
| 1600
| 6.6
| 26.4
| 38.4
| GDDR3
| 192
| 10.0
| 3.3
| 396
| 85
| 3.77
|
|-
! style="text-align:left;"| GeForce 8800 GTS (G80)
| February 12, 2007 (320) <br>November 8, 2006 (640)
| G80
| 90
| 681
| 484
| PCIe 1.0 x16
| 320<br>640
| 96:24:20
| 513
| 1188
| 1600
| 10.3
| 24.6
| 64
| GDDR3
| 320
| 10.0
| 3.3
| 346
| 105
| 2.42
|
|-
! style="text-align:left;"| GeForce 8800 GTS 112 (G80)
| November 19, 2007
| G80
| 90
| 681
| 484
| PCIe 1.0 x16
| 640
| 112:28<sup>2</sup>:20
| 500
| 1200
| 1600
| 10
| 24
| 64
| GDDR3
| 320
| 10.0
| 3.3
| 399
| 150
| 2.66
| only XFX, EVGA and BFG models, very short-lived<ref>[http://www.computerbase.de/news/hardware/grafikkarten/nvidia/2007/november/zwei-neue-geforce-8800-gts-bis-dezember/ Zwei neue GeForce 8800 GTS bis Dezember - ComputerBase<!-- Bot generated title -->]</ref>
|-
! style="text-align:left;"| GeForce 8800 GT
| October 29, 2007 (512)<br>December 11, 2007 (256, 1024)
| G92
| 65
| 754
| 324
| PCIe 2.0 x16
| 256<br>512<br>1024
| 112:56:16
| 600
| 1500
| 1400 (256)<br>1800 (512, 1024)
| 9.6
| 33.6
| 57.6
| GDDR3
| 256
| 10.0
| 3.3
| 504
| 125
| 4.03
|
|-
! style="text-align:left;"| GeForce 8800 GTS (G92)
| December 11, 2007
| G92
| 65
| 754
| 324
| PCIe 2.0 x16
| 512
| 128:64:16
| 650
| 1625
| 1940
| 10.4
| 41.6
| 62.1
| GDDR3
| 256
| 10.0
| 3.3
| 624
| 135
| 4.62
|
|-
! style="text-align:left;"| GeForce 8800 GTX
| November 8, 2006
| G80
| 90
| 681
| 484
| PCIe 1.0 x16
| 768
| 128:32<sup>2</sup>:24
| 575
| 1350
| 1800
| 13.8
| 36.8
| 86.4
| GDDR3
| 384
| 10.0
| 3.3
| 518 (343)
| 155
| 3.34
|
|-
! style="text-align:left;"| GeForce 8800 Ultra
| May 2, 2007
| G80
| 90
| 681
| 484
| PCIe 1.0 x16
| 768
| 128:32<sup>2</sup>:24
| 612
| 1500
| 2160
| 14.7
| 39.2
| 103.7
| GDDR3
| 384
| 10.0
| 3.3
| 576
| 171
| 3.37
|
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory min ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! rowspan=2 | Processing Power (GFLOPS)
! rowspan=2 | TDP (Watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! colspan=3 | Clock rate
! colspan=2 | [[Fillrate]]
! colspan=3 | Memory
! colspan=2 | API support (version)
|}

====Features====
* Compute Capability 1.1: has support for Atomic functions, which are used to write thread-safe programs.
* Compute Capability 1.2: for details see [[CUDA#Version features and specifications|CUDA]]
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=9 style="text-align:center;" | Features
|-
! Scalable<br>Link<br>Interface<br>(SLI)
! 3-Way<br>SLI
! [[PureVideo]] HD<br>with VP1
! [[PureVideo]] 2 with VP2,
BSP Engine, and AES128 Engine
! [[PureVideo]] 3 with VP3,
BSP Engine, and AES128 Engine
! [[PureVideo]] 4 with VP4
! Compute<br>capability
|-
! style="text-align:left;"| GeForce 8300 GS (G86)
| {{no}}
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes|1.1}}
|-
! style="text-align:left;"| GeForce 8400 GS Rev. 2 (G98)
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
| {{yes|1.1}}
|-
! style="text-align:left;"| GeForce 8400 GS Rev. 3 (GT218)
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{no}}
| {{yes}}
| {{yes|1.2}}
|-
! style="text-align:left;"| GeForce 8500 GT
| {{yes2}} Yes (No SLI Bridge)
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes|1.1}}
|-
! style="text-align:left;"| GeForce 8600 GT
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes|1.1}}
|-
! style="text-align:left;"| GeForce 8600 GTS
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes|1.1}}
|-
! style="text-align:left;"| GeForce 8800 GS (G92)
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes|1.1}}
|-
! style="text-align:left;"| GeForce 8800 GTS (G80)
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{no|1.0}}
|-
! style="text-align:left;"| GeForce 8800 GTS Rev. 2 (G80)
| {{yes}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{no|1.0}}
|-
! style="text-align:left;"| GeForce 8800 GT (G92)
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes|1.1}}
|-
! style="text-align:left;"| GeForce 8800 GTS (G92)
| {{yes}}
| {{no}}
| {{no}}
| {{yes}}
| {{no}}
| {{no}}
| {{yes|1.1}}
|-
! style="text-align:left;"| GeForce 8800 GTX
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{no|1.0}}
|-
! style="text-align:left;"| GeForce 8800 Ultra
| {{yes}}
| {{yes}}
| {{yes}}
| {{no}}
| {{no}}
| {{no}}
| {{no|1.0}}
|}

===GeForce 9 (9xxx) Series===
{{Main|GeForce 9 Series|Tesla (microarchitecture)}}

All models support Coverage Sample Anti-Aliasing, Angle-Independent Anisotropic Filtering, 128-bit OpenEXR HDR

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>[1]</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power [[Giga-|G]][[FLOPS]]
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;"| GeForce 9300 mGPU
| October 2008
| MCP7A-S
| 65
| 282
| 162
| 1
| PCIe 2.0 x16
| Up to 512 from system memory
| 16:8:4
| 450
| 1200
| 800<br>1333
| 1.8
| 3.6
| 6.4/12.8<br>10.664/21.328
| DDR2<br>DDR3
| 64<br>128
| 10.0
| 3.3
| 57.6
| {{unk}}
| {{unk}}
| based on 8400 GS
|-
! style="text-align:left;"| GeForce 9400 mGPU
| October 2008
| MCP7A-U
| 65
| 282
| 162
| 1
| PCIe 2.0 x16
| Up to 512 from system memory
| 16:8:4
| 580
| 1400
| 800<br>1333
| 2.32
| 4.64
| 6.4/12.8<br>10.664/21.328
| DDR2<br>DDR3
| 64<br>128
| 10.0
| 3.3
| 67.2
| 12
| 5.6
| based on 8400 GS
|-
! style="text-align:left;"| GeForce 9300 GE<ref name="pcinpact9300GE9300GS">{{cite web | url=http://www.pcinpact.com/affichage/43963-NVIDIA-9600GT-9300GE-9300GS/58125.htm | title=Nvidia GeForce 9300 GE | year=2008 | author=Nvidia Corporation}}</ref>
| June 2008
| G98
| 65
| 210
| 86
| 1
| PCIe 2.0 x16
| 256
| 8:8:4
| 540
| 1300
| 1000
| 2.16
| 4.32
| 8
| DDR2
| 64
| 10.0
| 3.3
| 31.2
| ??
| {{unk}}
|
|-
! style="text-align:left;"| GeForce 9300 GS<ref name="pcinpact9300GE9300GS"/>
| June 2008
| G98
| 65
| 210
| 86
| 1
| PCIe 2.0 x16
| 256
| 8:8:4
| 567
| 1400
| 1000
| 2.268
| 4.536
| 8
| DDR2
| 64
| 10.0
| 3.3
| 33.6
| ??
| {{unk}}
|
|-
! style="text-align:left;"| GeForce 9400 GT
| August 27, 2008
| G96a<br>G96b
| 65<br>55
| 314
| 144
| 1
| PCIe 2.0 x16<br>PCI
| 256<br>512<br>1024
| 16:8:4
| 550
| 1400
| 800<br>1600
| 2.2
| 4.4
| 12.8<br>25.6
| GDDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 67.2
| 50
| 1.34
|
|-
! style="text-align:left;"| GeForce 9500 GT
| July 29, 2008
| G96-300-C1
| 65<br>55
| 314
| 144
| 1
| PCIe 2.0 x16<br>PCI
| 256<br>512<br>1024
| 32:16:8
| 550
| 1400
| 1000<br>1600
| 4.4
| 8.8
| 16.0<br>25.6
| DDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 134.4
| 50
| 2.69
|
|-
! style="text-align:left;"| GeForce 9600 GS
| July 29, 2008
| G94a
| 65
| 505
| 240
| 1
| PCIe 2.0 x16<br>PCI
| 768
| 48:24:12
| 500
| 1250
| 1000
| 6
| 12
| 24
| DDR2
| 192
| 10.0
| 3.3
| 180
| {{unk}}
| {{unk}}
| OEM
|-
! style="text-align:left;"| GeForce 9600 GSO
| May 2008
| G92
| 65
| 754
| 324
| 1
| PCIe 2.0 x16
| 384<br>768<br>1536
| 96:48:12
| 550
| 1375
| 1600
| 6.6
| 26.4
| 38.4
| GDDR3
| 192
| 10.0
| 3.3
| 396
| 84
| 4.71
| 
|-
! style="text-align:left;"| GeForce 9600 GSO 512
| October 2008
| G94a<br>G94b
| 65<br>55
| 505
| 240<br>196?{{citation needed|date=September 2012}}
| 1
| PCIe 2.0 x16
| 512
| 48:24:16
| 650
| 1625
| 1800
| 10.4
| 15.6
| 57.6
| GDDR3
| 256
| 10.0
| 3.3
| 234
| 90
| 2.6
|
|-
! style="text-align:left;"| GeForce 9600 GT Green Edition
| 2009
| G94b
| 55
| 505
| 196?{{citation needed|date=September 2012}}
| 1
| PCIe 2.0 x16
| 512<br>1024
| 64:32:16
| 600<br>625
| 1500<br>1625
| 1400/1800<br>1800{{citation needed|date=September 2012}}
| 9.6<br>10.0
| 19.2<br>20.0
| 44.8/57.6<br>57.6{{citation needed|date=September 2012}}
| GDDR3
| 256
| 10.0
| 3.3
| 288<br>312
| 59
| 4.88<br>5.29
| Core Voltage - 1 volt
|-
! style="text-align:left;"| GeForce 9600 GT
| February 21, 2008
| G94-300-A1
| 65<br>55
| 505
| 240<br>196?{{citation needed|date=September 2012}}
| 1
| PCIe 2.0 x16
| 512<br>1024
| 64:32:16
| 650
| 1625
| 1800
| 10.4
| 20.8
| 57.6
| GDDR3
| 256
| 10.0
| 3.3
| 312
| 95
| 3.28
|
|-
! style="text-align:left;"| GeForce 9800 GT Green Edition
| 2009
| G92b
| 55
| 754
| 260
| 1
| PCIe 2.0 x16
| 512<br>1024
| 112:56:16
| 550
| 1375
| 1400<br>1600<br>1800
| 8.8
| 30.8
| 44.8<br>51.2<br>57.6
| GDDR3
| 256
| 10.0
| 3.3
| 462
| 75
| 6.16
| Core Voltage - 1 volt
|-
! style="text-align:left;"| GeForce 9800 GT
| July 2008
| G92a<br>G92b
| 65<br>55
| 754
| 324<br>260
| 1
| PCIe 2.0 x16
| 512<br>1024
| 112:56:16
| 600
| 1500
| 1800
| 9.6
| 33.6
| 57.6
| GDDR3
| 256
| 10.0
| 3.3
| 504
| 125<br>105
| 4.03<br>4.8
| 
|-
! style="text-align:left;"| GeForce 9800 GTX
| April 1, 2008
| G92
| 65
| 754
| 324
| 1
| PCIe 2.0 x16
| 512
| 128:64:16
| 675
| 1688
| 2200
| 10.8
| 43.2
| 70.4
| GDDR3
| 256
| 10.0
| 3.3
| 648
| 140
| 4.63
|
|-
! style="text-align:left;"| GeForce 9800 GTX+
| July 16, 2008
| G92b
| 55
| 754
| 260
| 1
| PCIe 2.0 x16
| 512<br>1024
| 128:64:16
| 738
| 1836
| 2200
| 11.808
| 47.232
| 70.4
| GDDR3
| 256
| 10.0
| 3.3
| 705
| 141
| 5.0
|
|-
! style="text-align:left;"| GeForce 9800 GX2
| March 18, 2008
| G92
| 65
| 2x 754
| 2x 324
| 2
| PCIe 2.0 x16
| 2x 512
| 2x 128:64:16
| 600
| 1500
| 2000
| 2x 9.6
| 2x 38.4
| 2x 64.0
| GDDR3
| 2x 256
| 10.0
| 3.3
| 2x 576
| 197
| 5.85
|
|-
! style="text-align:center;"| Model
! Launch
! [[Codename]]
! Fab ([[Nanometer|nm]])
! Transistors (Million)
! Die Size (mm<sup>2</sup>)
! Die Count
! [[Computer bus|Bus]] [[I/O interface|interface]]
! Memory ([[Megabyte|MB]])
! Core config<sup>[1]</sup>
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! Processing Power [[Giga-|G]][[FLOPS]]
! [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! Comments
|}

====Features====
*Compute Capability: 1.1 has support for Atomic functions, which are used to write thread-safe programs.

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=9 style="text-align:center;" | Features
|-
! Scalable Link Interface (SLI)
! [[PureVideo]] 2 with VP2,
BSP Engine, and AES128 Engine
! [[PureVideo]] 3 with VP3,
BSP Engine, and AES128 Engine
|-
! style="text-align:left;"| GeForce 9300 GE (G98)
| rowspan="7" {{yes}}
| rowspan="2" {{no}}
| rowspan="2" {{yes}}
|-
! style="text-align:left;"| GeForce 9300 GS (G98)
|-
! style="text-align:left;"| GeForce 9400 GT
| rowspan="8" {{yes}}
| rowspan="8" {{no}}
|-
! style="text-align:left;"| GeForce 9500 GT
|-
! style="text-align:left;"| GeForce 9600 GSO
|-
! style="text-align:left;"| GeForce 9600 GT
|-
! style="text-align:left;"| GeForce 9800 GT
|-
! style="text-align:left;"| GeForce 9800 GTX
| rowspan="2" {{yes}}<br/>3-way
|-
! style="text-align:left;"| GeForce 9800 GTX+
|-
! style="text-align:left;"| GeForce 9800 GX2
| {{yes}}
|}

===GeForce 100 Series===
{{Main|GeForce 100 Series|Tesla (microarchitecture)}}

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab Process ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config <sup>1</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power GFLOPS
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;"| GeForce G 100
| March 10, 2009
| G98
| 65
| {{unk}}
| 86
| 1
| PCIe 2.0 x16
| 512
| 8:8:4
| 567
| 1400
| 500
| 2.15
| 4.3
| 8.0
| DDR2
| 64
| 10.0
| 3.3
| 33.6
| 35
| 0.96
| OEM products
|-
! style="text-align:left;"| GeForce GT 120
| March 10, 2009
| G96b
| 55
| 314
| 121
| 1
| PCIe 2.0 x16
| 512
| 32:16:8
| 500
| 1400
| 800
| 4.4
| 8.8
| 16.0
| DDR2
| 128
| 10.0
| 3.3
| 134.4
| 50
| 2.69
| OEM products
|-
! style="text-align:left;"| GeForce GT 130
| March 10, 2009
| G94b
| 55
| 505
| 196?{{citation needed|date=September 2012}}
| 1
| PCIe 2.0 x16
| 1536
| 48:24:12
| 500
| 1250
| 500
| 6
| 12
| 24.0
| DDR2
| 192
| 10.0
| 3.3
| 180
| 75
| 2.4
| OEM products
|-
! style="text-align:left;"| GeForce GT 140
| March 10, 2009
| G94b
| 55
| 505
| 196?
| 1
| PCIe 2.0 x16
| 512 
1024
| 64:32:16
| 650
| 1625
| 1800
| 10.4
| 20.8
| 57.6
| GDDR3
| 256
| 10.0
| 3.3
| 312
| 105
| 2.97
| OEM products
|-
! style="text-align:left;"| GeForce GTS 150
| March 10, 2009
| G92b
| 55
| 754
| 260
| 1
| PCIe 2.0 x16
| 1024
| 128:64:16
| 738
| 1836
| 1000
| 11.808
| 47.232
| 64.0
| GDDR3
| 256
| 10.0
| 3.3
| 705
| 141
| 5.0
| OEM products
|}

===GeForce 200 Series===
{{Main|GeForce 200 Series|Tesla (microarchitecture)}}

All models support Coverage Sample Anti-Aliasing, Angle-Independent Anisotropic Filtering, 240-bit OpenEXR HDR
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config <sup>1</sup>
! colspan=3 | Clock rate
! colspan=2 | [[Fillrate]]
! colspan=3 | Memory Configuration
! colspan=2 | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power GFLOPS
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;"| GeForce 205
| November 26, 2009
| GT218
| 40
| 260
| 57
| 1
| PCIe 2.0 x16
| 512
| 8:4:4
| 589
| 1402
| 1000
| 2.356
| 2.356
| 8
| DDR2
| 64
| 10.1
| 3.3
| 33.4
| 30.5
| 1.06
| OEM only
|-
! style="text-align:left;"| GeForce 210
| October 12, 2009
| GT218-325-B1
| 40
| 260
| 57
| 1
| PCIe 2.0 x16<br>PCIe x1<br>PCI
| 512<br>1024
| 16:8:4
| 520<br>589
| 1230<br>1402
| 10001600
| 2.356
| 4.712
| 4.0<br>8.0<br>12.8
| DDR2<br>DDR3
| 32<br>64
| 10.1
| 3.3
| 67.296
| 30.5
| 2.21
|
|-
! style="text-align:left;"| GeForce GT 220
| October 12, 2009
| GT216
| 40
| 486
| 100
| 1
| PCIe 2.0 x16
| 512<br>1024
| 48:16:8
| 615(OEM)<br>625
| 1335(OEM)<br>1360
| 1000<br>1580
| 5
| 10
| 16.0<br>25.3
| DDR2<br>DDR3
| 128
| 10.1
| 3.3
| 192(OEM)<br>196
| 58
| 3.31(OEM)<br>3.38
|
|-
! style="text-align:left;"| GeForce GT 230 v.1
| 2009
| G94b
| 55
| 505
| 196?{{citation needed|date=September 2012}}
| 1
| PCIe 2.0 x16
| 512<br>1024
| 48:24:16
| 650
| 1625
| 1800
| 10.4
| 15.6
| 57.6
| GDDR3
| 256
| 10
| 3.3
| 234
| 75
| 3.12
| OEM only
|-
! style="text-align:left;"| GeForce GT 230 v.2
| 2009
| G92b
| 55
| 754
| 260
| 1
| PCIe 2.0 x16
| 1536
| 96:48:12
| 500
| 1242
| 1000
| 6
| 24
| 24
| DDR2
| 192
| 10
| 3.3
| 357.69
| 75
| 4.77
| OEM only
|-
! style="text-align:left;"| GeForce GT 240
| November 17, 2009
| GT215
| 40
| 727
| 139
| 1
| PCIe 2.0 x16
| 512<br>1024
| 96:32:8
| 550
| 1340
| 1800<br>2000<br>3400(GDDR5)
| 4.4
| 17.6
| 28.8(OEM)<br>32<br>54.4(GDDR5)
| DDR3<br>GDDR3<br>GDDR5
| 128
| 10.1
| 3.3
| 385.9
| 69
| 5.59
|
|-
! style="text-align:left;"| GeForce GTS 240
| Q4 2009
| G92a<br>G92b
| 65<br>55
| 754
| 324<br>260
| 1
| PCIe 2.0 x16
| 1024
| 112:56:16
| 675
| 1620
| 2200
| 10.8
| 37.8
| 70.4
| GDDR3
| 256
| 10.0
| 3.3
|554.32
| 120
| 4.62
| OEM only
|-
! style="text-align:left;"| GeForce GTS 250 Green
| 2009
| G92b
| 65<br>55
| 754
| 260
| 1
| PCIe 2.0 x16
| 512<br>1024
| 128:64:16
| 702
| 1512
| 2000
| 11.2
| 44.9
| 64.0
| GDDR3
| 256
| 10.0
| 3.3
| 581
| 130
| 4.47
| 
|-
! style="text-align:left;"| GeForce GTS 250
| March 3, 2009
| G92-428-B1
| 65<br>55
| 754
| 260
| 1
| PCIe 2.0 x16
| 512<br>1024
| 128:64:16
| 738
| 1836
| 2000<br>2200
| 11.808
| 47.232
| 64.0<br>70.4
| GDDR3
| 256
| 10.0
| 3.3
| 705.024
| 150
| 4.86
| Some cards are rebranded GeForce 9800 GTX+
|-
! style="text-align:left;"| GeForce GTX 260
| June 16, 2008
| GT200-100-A2
| 65
| 1400
| 576
| 1
| PCIe 2.0 x16
| 896
| 192:64:28
| 576
| 1242
| 1998
| 16.128
| 36.864
| 111.9
| GDDR3
| 448
| 10.0
| 3.3
| 715.392
| 202
| 3.54
| Replaced by GTX 260 Core 216
|-
! style="text-align:left;"| GeForce GTX 260 Core 216
| September 16, 2008
| GT200-103-A2<br>GT200-105-B3
| 65<br>55
| 1400
| 576<br>470
| 1
| PCIe 2.0 x16
| 896 (1792)
| 216:72:28
| 576
| 1242
| 1998
| 16.128
| 41.472
| 111.9
| GDDR3
| 448
| 10.0
| 3.3
| 804.816<br>874.8
| 182<br>171
| 4.42<br>4.71
|
|-
! style="text-align:left;"| GeForce GTX 275
| April 9, 2009
| GT200-400-B3
| 55
| 1400
| 470
| 1
| PCIe 2.0 x16
| 896
| 240:80:28
| 633
| 1404
| 2268
| 17.724
| 50.6
| 127.0
| GDDR3
| 448
| 10.0
| 3.3
| 1010.880
| 219
| 4.62
|Effectively one-half of the GTX 295
|-
! style="text-align:left;"| GeForce GTX 280
| June 17, 2008
| GT200-300-A2
| 65
| 1400
| 576
| 1
| PCIe 2.0 x16
| 1024
| 240:80:32
| 602
| 1296
| 2214
| 19.264
| 48.16
| 141.7
| GDDR3
| 512
| 10.0
| 3.3
| 933.120
| 236
| 3.95
| Replaced by GTX 285
|-
! style="text-align:left;"| GeForce GTX 285
| January 15, 2009
| GT200-350-B3
| 55
| 1400
| 470
| 1
| PCIe 2.0 x16
| 1024 (2048*)
| 240:80:32
| 648
| 1476
| 2484
| 20.736
| 51.84
| 159.0
| GDDR3
| 512
| 10.0
| 3.3
| 1062.72
| 204
| 5.24
| Palit and EVGA launched 2GB versions. EVGA GTX285 Classified can support 4-way SLI
|-
! style="text-align:left;"| GeForce GTX 295
| January 8, 2009
| GT200-400-B3
| 55
| '''2x''' 1400
| '''2x''' 470
| 2
| PCIe 2.0 x16
| '''2x''' 896
| '''2x''' 240:80:28
| 576
| 1242
| 1998
| '''2x''' 16.128
| '''2x''' 46.08
| '''2x''' 111.9
| GDDR3
| '''2x''' 448
| 10.0
| 3.3
| 1788.480
| 289
| 6.19
| Dual PCB models were phased out in favor of a single PCB model with 2 GPUs
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config <sup>1</sup>
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! rowspan=2 | GFLOPS (MADD+MUL)
! rowspan=2 | TDP (Watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! colspan=3 | Clock rate
! colspan=2 | [[Fillrate]]
! colspan=3 | Memory Configuration
! colspan=2 | API support (version)
|}

====Features====
Compute Capability: 1.1 (G92 [GTS250] GPU)
<br>Compute Capability: 1.2 (GT215, GT216, GT218 GPUs)
<br>Compute Capability: 1.3 has [[Double precision floating-point format|double precision]] support for use in [[GPGPU]] applications. (GT200a/b GPUs only)

{| class="wikitable" style="font-size: 85%; text-alig: center; width: auto;"
|-
! rowspan=2 | Model
! colspan=8 style="text-align:center;" | Features
|-
! Scalable Link Interface (SLI)
! [[PureVideo]] 2 with VP2
Engine: (BSP and 240 AES)
! [[PureVideo]] 4 with VP4 Engine
|-
! style="text-align:left;"| GeForce 210
| colspan="1" rowspan="3" {{no}}
| colspan="1" rowspan="3" {{no}}
| colspan="3" rowspan="3" {{yes}}
|-
! style="text-align:left;"| GeForce GT 220
|-
! style="text-align:left;"| GeForce GT 240
|-
! style="text-align:left;"| GeForce GTS 250
| rowspan="7" {{yes}}<br/>3-Way (4-way for EVGA 285 Classified)
| colspan="1" rowspan="8" {{yes}}
| colspan="1" rowspan="8" {{no}}
|-
! style="text-align:left;"| GeForce GTX 260
|-
! style="text-align:left;"| GeForce GTX 260 Core 216
|-
! style="text-align:left;"| GeForce GTX 260 Core 216 (55&nbsp;nm)
|-
! style="text-align:left;"| GeForce GTX 275
|-
! style="text-align:left;"| GeForce GTX 280
|-
! style="text-align:left;"| GeForce GTX 285
|-
! style="text-align:left;"| GeForce GTX 295
| {{yes}}<br/>
|}

===GeForce 300 Series===
{{Main|GeForce 300 Series|Tesla (microarchitecture)}}

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Each Streaming Multiprocessor(SM) in the chip of G80/GT200 architecture contains 8 SPs and 2 SFUs.  Each SP can fulfill up to two single precision operations MAD per clock. Each SFU can fulfill up to four operations SF per clock (these units can also handle single-precision floating-point multiplications per clock). The approximate ratio of operations MAD to operations SF is equal 2:1. The theoretical SP + SFU performance in single-precision floating point operations [''FLOPS<sub>sp + sfu</sub>'', [[GigaFLOPS|GFLOPS]]] of the graphics card with shader count [''n''] and shader frequency [''f'', GHz], is estimated by the following formula: ''FLOPS<sub>sp+sfu</sub>''  f  n  3.   Alternative formula:   ''FLOPS<sub>sp+sfu</sub>''  f  m  ( 8 SPs * 2 (MAD) + 4 * 2 SFUs ). [''m''] - SM count.<ref name="nvidiaanandtechGT200">[http://www.anandtech.com/show/2549/2 NVIDIA's 1.4 Billion Transistor GPU: GT200 Arrives as the GeForce GTX 280 & 260]</ref><ref name="nvidiaanandtechG80">[http://www.anandtech.com/show/2116/5 NVIDIA's GeForce 8800 (G80): GPUs Re-architected for DirectX 10 (page 5 0f 29)]</ref>
SP - Shader Processor (Unified Shader, [[CUDA]] Core), SFU - Special Function Unit, SM - Streaming Multiprocessor, MAD - ADD+MUL.

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config <sup>1</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 |Processing Power GFLOPS<sup>2</sup>
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Comments
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;"| GeForce 310
| November 27, 2009
| GT218
| 40
| 260
| 57
| 1
| PCIe 2.0 x16
| 512
| 16:8:4
| 589
| 1402
| 1000
| 2.356
| 4.712
| 8
| DDR2
| 64
| 10.1
| 3.3
| 67.296
| 30.5
| 2.21
| OEM Card, similar to Geforce 210
|-
! style="text-align:left;"| GeForce 315
| February, 2010
| GT216
| 40
| 486
| 100
| 1
| PCIe 2.0 x16
| 512
| 48:16:8
| 475
| 1100
| 1580
| 3.8
| 7.6
| 12.6
| DDR3
| 64
| 10.1
| 3.3
| 158.4
| 33
| 4.8
| OEM Card, similar to Geforce GT220
|-
! style="text-align:left;"| GeForce GT 320
| February, 2010
| GT215
| 40
| 727
| 144
| 1
| PCIe 2.0 x16
| 1024
| 72:24:8
| 540
| 1302
| 1580
| 4.32
| 12.96
| 25.3
| GDDR3
| 128
| 10.1
| 3.3
| 281.23
| 43
| 6.54
| OEM Card
|-
! style="text-align:left;"| GeForce GT 330 <ref>[http://www.techpowerup.com/gpudb/1758/geforce-gt-330-oem.html GeForce GT 330 | Specifications | OEM]</ref>
| February, 2010
| GT215-301-A3
| 40
| 727
| 144
| 1
| PCIe 2.0 x16
| 1024<br>1536<br>2048
| 96:32:8<br>96:48?:12?<br>112:56?:16?{{citation needed|date=September 2012}}
| 500<br>550{{citation needed|date=September 2012}}<!-- originally was 500-550 -->
| 1250<br>1340{{citation needed|date=September 2012}}<!-- originally was 1250-1340 -->
| 1000 (DDR2)<br>1600 (GDDR3)
| 4.40
| 17.6
| 24<br>32{{citation needed|date=September 2012}}<!-- originally was 24-32 -->
| DDR2<br>GDDR3
| 128<br>192<br>256
| 10.1
| 3.3
| 257.3
| 75
| {{unk}}
| Specifications vary depending on OEM, similar to GT230 v2.
|-
! style="text-align:left;"| GeForce GT 340
| February, 2010
| GT215
| 40
| 727
| 144
| 1
| PCIe 2.0 x16
| 512<br>1024
| 96:32:8
| 550
| 1340
| 3400
| 4.4
| 17.6
| 54.4
| GDDR5<ref>[http://www.nvidia.com/object/product_geforce_gt_340_us.html GeForce GT 340 Specification]</ref>
| 128
| 10.1
| 3.3
| 385.9
| 69
| 5.59
| OEM Card, similar to GT240
|}

===GeForce 400 Series===
{{Main|GeForce 400 Series|Fermi (microarchitecture)}}
'''Please take note''': Memory bandwidths mentioned in the following table refer nVidia reference designs. Actual bandwidth can be higher or ''lower'' depending on the manufacturer of the graphic board.

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Each Streaming Multiprocessor(SM) in the GPU of GF100 architecture contains 32 SPs and 4 SFUs. Each Streaming Multiprocessor(SM) in the GPU of GF104/106/108 architecture contains 48 SPs and 8 SFUs. Each SP can fulfill up to two single precision operations FMA per clock. Each SFU can fulfill up to four operations SF per clock. The approximate ratio of operations FMA to operations SF is equal: for GF100 4:1 and for GF104/106/108 3:1. The theoretical shader performance in single-precision floating point operations(FMA) [''FLOPS<sub>sp</sub>'', [[GigaFLOPS|GFLOPS]]] of the graphics card with shader count [''n''] and shader frequency [''f'', GHz], is estimated by the following: ''FLOPS<sub>sp</sub>''  f  n  2. Alternative formula: for GF100 ''FLOPS<sub>sp</sub>''  f  m  (32 SPs  2(FMA)) and for GF104/106/108 ''FLOPS<sub>sp</sub>''  f  m  (48 SPs  2(FMA)). [''m''] - SM count. Total Processing Power: for GF100 ''FLOPS<sub>sp</sub>''  f  m (32 SPs  2(FMA) + 4  4 SFUs) and for GF104/106/108 ''FLOPS<sub>sp</sub>''  f  m  (48 SPs  2(FMA) + 4  8 SFUs) or for GF100 ''FLOPS<sub>sp</sub>''  f  n  2.5 and for GF104/106/108 ''FLOPS<sub>sp</sub>''  f  n  8 / 3.<ref name="nvidiatesla-siliconmadness">{{cite web | url=http://www.siliconmadness.com/2009/11/nvidia-announces-tesla-20-Series.html | title=Nvidia Announces Tesla 20 Series | year=2010 | author=siliconmadness.com}}</ref> where:
SP - Shader Processor (Unified Shader, [[CUDA]] Core), SFU - Special Function Unit, SM - Streaming Multiprocessor, [[Fused multiplyadd|FMA]] - Fused MUL+ADD.
* <sup>3</sup> Each SM in the GF100 contains 4 texture filtering units for every texture address unit. The complete GF100 die contains 64 texture address units and 256 texture filtering units.<ref name="anandtech.com">[http://anandtech.com/show/2977/nvidia-s-geforce-gtx-480-and-gtx-470-6-months-late-was-it-worth-the-wait-/3 NVIDIA's GeForce GTX 480 and GTX 470: 6 Months Late, Was It Worth the Wait?]</ref> Each SM in the GF104/106/108 architecture contains 8 texture filtering units for every texture address unit but has doubled both addressing and filtering units. The complete GF104 die also contains 64 texture address units and 512 texture filtering units despite the halved SM count, the complete GF106 die contains 32 texture address units and 256 texture filtering units and the complete GF108 die contains 16 texture address units and 128 texture filtering units.<ref>[http://www.anandtech.com/show/3809/nvidias-geforce-gtx-460-the-200-king/2 NVIDIA's GeForce GTX 460: The $200 King]</ref>
* <sup>4</sup> Note that while GTX 460's TDP is comparable to that of AMD's HD5000 Series, GF100-based cards (GTX 480/470/465) are rated much lower but pull significantlly more power, e.g. GTX 480 with 250W TDP consumes More power than an HD 5970 with 297W TDP.<ref>[http://www.tomshardware.com/reviews/geforce-gtx-480,2585-15.html Power Consumption And Heat - GeForce GTX 480 And 470: From Fermi And GF100 To Actual Cards!<!-- Bot generated title -->]</ref>
* <sup>6</sup> The 400 Series is the only non-OEM family since GeForce 8 not to include an official dual-GPU system. However, on March 18, 2011, [[EVGA Corporation|EVGA]] released the first single-PCB card with dual 460's on board. The card came with 2048 MB of memory at 3600&nbsp;MHz and 672 shader processors at 1400&nbsp;MHz and was offered at the MSRP of $429.
* <sup>7</sup> The GeForce 405 card is a remarked GeForce 310 which itself is a remarked GeForce 210.

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1,3</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)<sup>2</sup>
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)<sup>4</sup>
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]<sup>5</sup>
|-
! style="text-align:left;"| GeForce 405 (OEM)<sup>7</sup>
| September 16, 2011
| GT216<br>GT218
| 40
| 486<br>260
| 100<br>57
| 1
| PCIe 2.0 x16
| 512<br>1024
| 1
| 48:16:8<br>16:8:4
| 475<br>589
| 1100<br>1402
| 800<br>790
| 3.8<br>2.36
| 7.6<br>4.71
| 12.6
| DDR3
| 64
| 10.1
| 3.3
| 1.1
| 105.6<br>44.86
| 30.5
| 
| OEM
|-
! style="text-align:left;"| GeForce GT 420 (OEM)
| September 3, 2010
| GF108
| 40
| 585
| 116
| 1
| PCIe 2.0 x16
| 2048
| 1
| 48:4:4
| 700
| 1400
| 1800
| 2.8
| 2.8
| 28.8
| GDDR3
| 128
| 11
| 4.5
| 1.1
| 134.4
| 50
| 2.69
| OEM
|-
! style="text-align:left;"| GeForce GT 430 (OEM)
| October 11, 2010
| GF108
| 40
| 585
| 116
| 1
| PCIe 2.0 x16
| 2048
| 2
| 96:16:4
| 700
| 1400
| 1600<br>1800
| 2.8
| 11.2
| 25.6<br>28.8
| GDDR3
| 128
| 11
| 4.5
| 1.1
| 268.8
| 60
| 4.48
| OEM
|-
! style="text-align:left;" rowspan=2| GeForce GT 430
|rowspan=2| October 11, 2010
|rowspan=2| GF108
|rowspan=2| 40
|rowspan=2| 585
|rowspan=2| 116
|rowspan=2| 1
|rowspan=2| PCIe 2.0 x16<br>PCI
|rowspan=2| 512<br>1024
|rowspan=2| 2
|rowspan=2| 96:16:4
|rowspan=2| 700
|rowspan=2| 1400
| 1800
|rowspan=2| 2.8
|rowspan=2| 11.2
| 28.8
|rowspan=2| GDDR3
| 128
|rowspan=2| 11
|rowspan=2| 4.5
|rowspan=2| 1.1
|rowspan=2| 268.8
|rowspan=2| 49
|rowspan=2| 5.49
|rowspan=2| $79
|-
| 1300
| 10.4
| 64
|-
! style="text-align:left;"| GeForce GT 440
| February 1, 2011
| GF108
| 40
| 585
| 116
| 1
| PCIe 2.0 x16
| 512<br>1024<br>2048
| 2
| 96:16:4
| 810
| 1620
| 1800<br>3200
| 3.24
| 12.96
| 28.8<br>51.2
| GDDR3<br>GDDR5
| 128
| 11
| 4.5
| 1.1
| 311.04
| 65
| 4.78
| $100
|-
! style="text-align:left;"| GeForce GT 440 (OEM)
| October 11, 2010
| GF106
| 40
| 1170
| 238
| 1
| PCIe 2.0 x16
| 1536<br>3072
| 3
| 144:24:24
| 594
| 1189
| 1800
| 14.26
| 14.26
| 43.2
| GDDR3
| 192
| 11
| 4.5
| 1.1
| 342.43
| 56
| 6.11
| OEM
|-
! style="text-align:left;"| GeForce GTS 450 (OEM)
| October 11, 2010
| GF106
| 40
| 1170
| 238
| 1
| PCIe 2.0 x16
| 1024<br>1536
| 3
| 144:24:24
| 790
| 1580
| 4000
| 18.96
| 18.96
| 96
| GDDR5
| 192
| 11
| 4.5
| 1.1
| 455.04
| 106
| 4.29
| OEM
|-
! style="text-align:left;"| GeForce GTS 450
| September 13, 2010<br>March 15, 2011
| GF106-250<br>GF116-200
| 40
| 1170
| 238
| 1
| PCIe 2.0 x16
| 512<br>1024
| 4
| 192:32:16
| 783
| 1566
| 3608
| 12.53
| 25.06
| 57.73
| GDDR5
| 128
| 11
| 4.5
| 1.1
| 601.34
| 106
| 5.67
| $129
|-
! style="text-align:left;"| GeForce GTX 460 SE
| November 15, 2010
| GF104-225-A1
| 40
| 1950
| 332
| 1
| PCIe 2.0 x16
| 1024
| 6
| 288:48:32
| 650
| 1300
| 3400
| 20.8
| 31.2
| 108.8
| GDDR5
| 256
| 11
| 4.5
| 1.1
| 748.8
| 150
| 4.99
| $160
|-
! style="text-align:left;"| GeForce GTX 460 (OEM)
| October 11, 2010
| GF104
| 40
| 1950
| 332
| 1
| PCIe 2.0 x16
| 1024
| 7
| 336:56:32
| 650
| 1300
| 3400
| 20.8
| 36.4
| 108.8
| GDDR5
| 256
| 11
| 4.5
| 1.1
| 873.6
| 150
| 5.82
| OEM
|-
! style="text-align:left;" rowspan=2| GeForce GTX 460<sup>6</sup>
|rowspan=2| July 12, 2010
|rowspan=2| GF104-300-KB-A1
|rowspan=2| 40
|rowspan=2| 1950
|rowspan=2| 332
|rowspan=2| 1
|rowspan=2| PCIe 2.0 x16
| 768
|rowspan=2| 7
| 336:56:24
|rowspan=2| 675
|rowspan=2| 1350
|rowspan=2| 3600
| 16.2
|rowspan=2| 37.8
| 86.4
|rowspan=2| GDDR5
| 192
|rowspan=2| 11
|rowspan=2| 4.5
|rowspan=2| 1.1
|rowspan=2| 907.2
|150
| 6.05
| $199
|-
|1024<br>2048
|336:56:32
|21.6
|115.2
|256
|160
|5.67
|$229
|-
! style="text-align:left;"| GeForce GTX 460 v2
| September 24, 2011
| GF114
| 40
| 1950
| 332
| 1
| PCIe 2.0 x16
| 1024
| 7
| 336:56:24
| 778
| 1556
| 4008
| 18.67
| 43.57
| 96.2
| GDDR5
| 192
| 11
| 4.5
| 1.1
| 1045.6
| 160
| 6.54
| $199
|-
! style="text-align:left;"| GeForce GTX 465
| May 31, 2010
| GF100
| 40
| 3000<ref>{{PDFlink|[http://www.nvidia.com/content/PDF/fermi_white_papers/NVIDIA_Fermi_Compute_Architecture_Whitepaper.pdf NVIDIA Fermi Compute Architecture Whitepaper.pdf]| 855KB}}, page 11 of 22</ref>
| 529
| 1
| PCIe 2.0 x16
| 1024
| 11
| 352:44:32
| 607
| 1215
| 3206
| 19.42
| 26.71
| 102.6
| GDDR5
| 256
| 11
| 4.5
| 1.1
| 855.36
| 200<sup>4</sup>
| 4.28
| $279
|-
! style="text-align:left;"| GeForce GTX 470
| March 26, 2010
| GF100
| 40
| 3000
| 529
| 1
| PCIe 2.0 x16
| 1280
| 14
| 448:56:40
| 607
| 1215
| 3348
| 24.28
| 34
| 133.9
| GDDR5
| 320
| 11
| 4.5
| 1.1
| 1088.64
| 215<sup>4</sup>
| 5.06
| $349
|-
! style="text-align:left;"| GeForce GTX 480
| March 26, 2010
| GF100
| 40
| 3000
| 529
| 1
| PCIe 2.0 x16
| 1536
| 15
| 480:60:48
| 700
| 1401
| 3696
| 33.60
| 42
| 177.4
| GDDR5
| 384
| 11
| 4.5
| 1.1
| 1344.96
| 250<sup>4</sup>
| 5.38
| $499
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1,3</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)<sup>2</sup>
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)<sup>4</sup>
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]
|}

===GeForce 500 Series===
{{Main|GeForce 500 Series|Fermi (microarchitecture)}}
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Each Streaming Multiprocessor(SM) in the GPU of GF110 architecture contains 32 SPs and 4 SFUs. Each Streaming Multiprocessor(SM) in the GPU of GF114/116/118/119 architecture contains 48 SPs and 8 SFUs.  Each SP can fulfill up to two single precision operations FMA per clock.  Each SFU can fulfill up to four SF operations per clock. The approximate ratio of operations FMA to operations SF is equal 4:1. The theoretical shader performance in single-precision floating point operations(FMA)[''FLOPS<sub>sp</sub>'', [[GigaFLOPS|GFLOPS]]] of the graphics card with shader count [''n''] and shader frequency [''f'', GHz], is estimated by the following: ''FLOPS<sub>sp</sub>''  f  n  2. Alternative formula: ''FLOPS<sub>sp</sub>''  f  m  (32 SPs  2(FMA)). [''m''] - SM count. Total Processing Power: ''FLOPS<sub>sp</sub>''  f  m  (32 SPs  2(FMA) + 4  4 SFUs) or ''FLOPS<sub>sp</sub>''  f  n  2.5.
* <sup>3</sup> Each SM in the GF110 contains 4 texture filtering units for every texture address unit. The complete GF110 die contains 64 texture address units and 256 texture filtering units.<ref>[http://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/2 NVIDIA's GeForce GTX 580: Fermi Refined]</ref> Each SM in the GF114/116/118 architecture contains 8 texture filtering units for every texture address unit but has doubled both addressing and filtering units.
* <sup>4</sup> Internally referred to as GF104B<ref>[http://www.gpu-tech.org/content.php/144-%E2%80%A6and-GF110s-real-name-is-GF100B-%28and-who-guesses-what-GF114-is-%29 and GF110s real name is: GF100B (and who guesses what GF114 is?)], by Carsten on 11/30/2010, www.gpu-tech.org</ref>
* <sup>5</sup> Internally referred to as GF100B<ref>[http://www.gpu-tech.org/content.php/144-%E2%80%A6and-GF110s-real-name-is-GF100B-%28and-who-guesses-what-GF114-is-%29 and GF110s real name is: GF104B (and who guesses what GF114 is?)], by Carsten on 11/30/2010, www.gpu-tech.org</ref>
* <sup>6</sup> Similar to previous generation, GTX 580 and most likely future GTX 570, while reflecting its improvement over GF100, still have lower rated TDP and higher power consumption, e.g. GTX580 (243W TDP) is slightly less power hungry than GTX 480 (250W TDP). This is managed by clock throttling through drivers when a dedicated power hungry application is identified that could breach card TDP. Application name changing will disable throttling and enable full power consumption, which in some cases could be close to that of GTX480.<ref>[http://www.anandtech.com/Show/Index/4008?cPage=14&all=False&sort=0&page=17&slug=nvidias-geforce-gtx-580 NVIDIA's GeForce GTX 580: Fermi Refined], by Ryan Smith on 11/9/2010, www.anandtech.com</ref>
* <sup>7</sup> Some companies have announced that they will be offering the GTX580 with 3GB VRAM.<ref>[http://www.evga.com/products/moreInfo.asp?pn=03G-P3-1584-AR&family=GeForce+500+Series+Family&sw EVGA GeForce GTX 580 3072MB]</ref>
* <sup>9</sup> 1024 MB RAM on 192-bit bus assemble with 4 * (128 MB) + 2 * (256 MB).

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1,3</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)<sup>2</sup>
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)<sup>6</sup>
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]<sup>8</sup>
|-
! style="text-align:left;"| GeForce 510
| September 29, 2011
| GF119
| 40
| 292
| 79
| 1
| PCIe 2.0 x16
| 1024<br>2048
| 1
| 48:8:4
| 523
| 1046
| 1800
| 2.1
| 4.4
| 14.4
| DDR3
| 64
| 11
| 4.5
| 1.1
| 100.4
| 25
| 4.02
| OEM
|-
! style="text-align:left;"| GeForce GT 520
| April 12, 2011
| GF119
| 40
| ?
| 79
| 1
| PCIe 2.0 x16<br>PCIe 2.0 x1<br>PCI
| 1024<br>2048
| 1
| 48:8:4
| 810
| 1620
| 1800
| 3.25
| 6.5
| 14.4
| DDR3
| 64
| 11
| 4.5
| 1.1
| 155.5
| 29
| 5.36
| $59
|-
! style="text-align:left;"| GeForce GT 530
| May 14, 2011
| GF108? / GF118{{citation needed|date=September 2012}}
| 40
| ~585
| ~116
| 1
| PCIe 2.0 x16
| 1024<br>2048
| 2
| 96:16:4
| 700
| 1400
| 1800
| 2.8
| 11.2
| 28.8
| DDR3
| 128
| 11
| 4.5
| 1.1
| 268.8
| 50
| 5.38
| OEM
|-
! style="text-align:left;"| GeForce GT 545 DDR3
| May 14, 2011
| GF116
| 40
| ~1170
| ~238
| 1
| PCIe 2.0 x16
| 1536<br>3072
| 3
| 144:24:16
| 720
| 1440
| 1800
| 11.52
| 17.28
| 43
| DDR3
| 192
| 11
| 4.5
| 1.1
| 415.07
| 70
| 5.93
| $149
|-
! style="text-align:left;"| GeForce GT 545 GDDR5
| May 14, 2011
| GF116
| 40
| ~1170
| ~238
| 1
| PCIe 2.0 x16
| 1024
| 3
| 144:24:16
| 870
| 1740
| 1998
| 13.92
| 20.88
| 64
| GDDR5
| 128
| 11
| 4.5
| 1.1
| 501.12
| 105
| 4.77
| OEM
|-
! style="text-align:left;"| GeForce GTX 550 Ti
| March 15, 2011
| GF116-400
| 40
| ~1170
| ~238
| 1
| PCIe 2.0 x16
| 1024<br>3072
| 4
| 192:32:24
| 900
| 1800
| 4104
| 21.6
| 28.8
| 98.5
| GDDR5
| 192 <sup>9</sup>
| 11
| 4.5
| 1.1
| 691.2
| 116
| 5.96
| $149
|-
! style="text-align:left;"| GeForce GTX 555
| 14 May 2011
| GF114
| 40
| 1950
| 332
| 1
| PCIe 2.0 x16
| 1024
| 6
| 288:48:24
| 736
| 1472
| 3828
| 17.6
| 35.3
| 91.9
| GDDR5
| 192 <sup>9</sup>
| 11
| 4.5
| 1.1
| 847.9
| 150
| 5.65
| OEM
|-
! style="text-align:left;"| GeForce GTX 560 SE
| N/A
| GF114<sup>4</sup>
| 40
| 1950
| ~332
| 1
| PCIe 2.0 x16
| 1024
| 6
| 288:48:24
| 736
| 1472
| 3828
| 17.7
| 35.3
| 91.9
| GDDR5
| 192 <sup>9</sup>
| 11
| 4.5
| 1.1
| 847.8
| 150
| 5.65
| OEM
|-
! style="text-align:left;"| GeForce GTX 560
| May 17, 2011
| GF114<sup>4</sup>
| 40
| 1950
| ~332
| 1
| PCIe 2.0 x16
| 1024 2048
| 7
| 336:56:32
| 810
| 1620
| 4008
| 25.92
| 45.36
| 128.1
| GDDR5
| 256
| 11
| 4.5
| 1.1
| 1088.6
| 150
| 7.26
| $199
|-
! style="text-align:left;"| GeForce GTX 560 Ti
| January 25, 2011
| GF114<sup>4</sup>
| 40
| 1950
| ~332
| 1
| PCIe 2.0 x16
| 1024<br>2048
| 8
| 384:64:32
| 822
| 1645
| 4008
| 26.3
| 52.61
| 128.26
| GDDR5
| 256
| 11
| 4.5
| 1.1
| 1263.4
| 170
| 7.43
| $249
|-
! style="text-align:left;"| GeForce GTX 560 Ti OEM
| May 30, 2011
| GF110<sup>5</sup>
| 40
| 3000
| 520
| 1
| PCIe 2.0 x16
| 1280<br>2560
| 11
| 352:44:40
| 732
| 1464
| 3800<!--according to Field explanations-->
| 29.28
| 32.21
| 152
| GDDR5
| 320
| 11
| 4.5
| 1.1
| 1030.7
| 210<sup>6</sup>
| 4.91
| OEM
|-
! style="text-align:left;"| GeForce GTX 560 Ti 448 Cores Limited Edition
| November 29, 2011
| GF110-270-A1<sup>5</sup>
| 40
| 3000
| 520
| 1
| PCIe 2.0 x16
| 1280 
| 14
| 448:56:40
| 732
| 1464
| 3800
| 29.28
| 40.99
| 152
| GDDR5
| 320
| 11
| 4.5
| 1.1
| 1311.7
| 210<sup>6</sup>
| 6.25
| $289
|-
! style="text-align:left;"| GeForce GTX 570
| December 7, 2010
| GF110-275-A1<sup>5</sup>
| 40
| 3000
| 520
| 1
| PCIe 2.0 x16
| 1280
2560
| 15
| 480:60:40
| 732
| 1464
| 3800<!--according to Field explanations-->
| 29.28
| 43.92
| 152
| GDDR5
| 320
| 11
| 4.5
| 1.1
| 1405.4
| 219<sup>6</sup>
| 6.41
| $349
|-
! style="text-align:left;"| GeForce GTX 580
| November 9, 2010
| GF110-375-A1<sup>5</sup>
| 40
| 3000<ref name="GTX580-anandtech">{{cite web | url=http://www.anandtech.com/show/4008/nvidias-geforce-gtx-580 | title=NVIDIA's GeForce GTX 580: Fermi Refined | date= November 9, 2010 | author= Ryan Smith}}</ref>
| 520<ref name="GTX580-anandtech"/>
| 1
| PCIe 2.0 x16
| 1536<br>3072<sup>7</sup>
| 16
| 512:64:48
| 772
| 1544
| 4008
| 37.05
| 49.41
| 192.384
| GDDR5
| 384
| 11
| 4.5
| 1.1
| 1581.1
| 244<sup>6</sup><ref>[http://www.techpowerup.com/reviews/NVIDIA/GeForce_GTX_580/3.html Techpowerup NVIDIA GeForce GTX 580 1536 MB]</ref>
| 6.48
| $499
|-
! style="text-align:left;"| GeForce GTX 590
| March 24, 2011
| '''2x'''
GF110-351-A1
| 40
| '''2x'''
3000
| '''2x'''
520
| 2
| PCIe 2.0 x16
| '''2x'''
1536
| 216
| '''2x'''
512:64:48
| 607
| 1215
| 3414
| 229.14
| 238.85
| 2163.87
| GDDR5
| 2384
| 11
| 4.5
| 1.1
| 2488.3
| 365
| 6.82
| $699
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1,3</sup>
! colspan=3 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)<sup>2</sup>
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)<sup>4</sup>
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]<sup>8</sup>
|}

===GeForce 600 Series===
{{Main|GeForce 600 Series|Kepler (microarchitecture)}}
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> The GeForce 605 (OEM) card is a rebranded GeForce 510.
* <sup>3</sup> The GeForce GT 610 card is a rebranded GeForce GT 520.
* <sup>4</sup> The GeForce GT 620 (OEM) card is a rebranded GeForce GT 520.
* <sup>5</sup> The GeForce GT 620 card is a rebranded GeForce GT 530.
* <sup>6</sup> The GeForce GT 630 (DDR3, 128-bit, retail) card is a rebranded GeForce GT 430 (DDR3, 128-bit).
* <sup>7</sup> The GeForce GT 630 (GDDR5) card is a rebranded GeForce GT 440 (GDDR5).
* <sup>8</sup> The GeForce GT 640 (OEM) card is a rebranded GeForce GT 545 (DDR3).
* <sup>9</sup> The GeForce GT 645 (OEM) card is a rebranded GeForce GTX 560 SE.

{| class="wikitable" style="font-size: 80%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1</sup>
! colspan=5 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Average Boost ([[Hertz|MHz]])
! Max Boost ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]
|-
! style="text-align:left;"| GeForce 605<sup>2</sup>
| April 3, 2012
| GF119
| 40
| 292
| 79
| 1
| PCIe 2.0 x16
| 512
1024
| 1
| 48:8:4
| 523
|{{n/a}}
|{{n/a}}
| 1046
| 898<br>(1796)
| 1.05
| 4.2
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 1.1
| 100.4
| 25
| 4.02
| OEM
|-
! style="text-align:left;"| GeForce GT 610 <sup>3</sup>
| May 15, 2012
| GF119-300-A1
| 40
| 292
| 79
| 1
| PCIe 2.0 x16, PCIe x1, PCI
| 512<br>1024<br>2048
| 1
| 48:8:4
| 810
| {{n/a}}
| {{n/a}}
| 1620
| 1000<br>1800
| 1.62
| 6.5
| 8<br>14.4
| DDR3
| 64
| 11.0
| 4.5
| 1.1
| 155.5
| 29
| 5.36
| Retail
|-
! style="text-align:left;"| GeForce GT 620 <sup>4</sup>
| April 3, 2012
| GF119
| 40
| 292
| 79
| 1
| PCIe 2.0 x16, PCI
| 512<br>1024
| 1
| 48:8:4
| 810
|{{n/a}}
|{{n/a}}
| 1620
| 898<br>(1796)
| 1.62
| 6.5
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 1.1
| 155.5
| 30
| 5.18
| OEM
|-
! style="text-align:left;"| GeForce GT 620<sup>5</sup>
| May 15, 2012
| GF108-100-KB-A1
| 40
| 585
| 116
| 1
| PCIe 2.0 x16, PCI
| 1024<br>2048
| 2
| 96:16:4
| 700
| {{n/a}}
| {{n/a}}
| 1400
| 10001800
| 2.8
| 11.2
| 814.4
| DDR3
| 64
| 11.0
| 4.5
| 1.1
| 268.8
| 49
| 5.49
| Retail
|-
! style="text-align:left;"| GeForce GT 625
| February 19, 2013
| GF119
| 40
| 292
| 79
| 1
| PCIe 2.0 x16
| 512
1024
| 1
| 48:8:4
| 810
|{{n/a}}
|{{n/a}}
| 1620
| 898<br>(1796)
| 3.24
| 6.5
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 1.1
| 155.5
| 30
| 5.18
| OEM
|-
! style="text-align:left;"| GeForce GT 630
| April 24, 2012
| GK107
| 28
| 1300
| 118
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 1
| 192:16:16
| 875
| {{n/a}}
| {{n/a}}
| 875
| 891<br>(1782)
| 14
| 14
| 28.5
| DDR3
| 128
| 11.0
| 4.5
| 1.2
| 336
| 50
| 6.72
| OEM
|-
! style="text-align:left;"| GeForce GT 630 (DDR3)<sup>6</sup>
| May 15, 2012
| GF108-400-A1
| 40
| 585
| 116
| 1
| PCIe 2.0 x16, PCI
| 1024<br>2048<br>4096
| 2
| 96:16:4
| 700
| {{n/a}}
| {{n/a}}
| 1620
| 16001800
| 2.8
| 11.2
| 25.628.8
| DDR3
| 128
| 11.0
| 4.5
| 1.1
| 311
| 65
| 4.79
| Retail
|-
! style="text-align:left;"| GeForce GT 630 (GDDR5)<sup>7</sup>
| May 15, 2012
| GF108
| 40
| 585
| 116
| 1
| PCIe 2.0 x16, PCI
| 1024
| 2
| 96:16:4
| 810
| {{n/a}}
| {{n/a}}
| 1620
| 800<br>(3200)
| 3.2
| 13
| 51.2
| GDDR5
| 128
| 11.0
| 4.5
| 1.1
| 311
| 65
| 4.79
| Retail
|-
! style="text-align:left;"| GeForce GT 630 (Rev. 2)
| May 29, 2013
| GK208-301-A1
| 28
| 1020
| 79
| 1
| PCIe 2.0 x8
| 1024<br>2048
| 1
| 384:16:8
| 902
| {{n/a}}
| {{n/a}}
| 902
| 900<br>(1800)
| 7.22
| 14.44
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 1.2
| 692.7
| 25
| 27.68
| 
|-
! style="text-align:left;"| GeForce GT 635 (OEM)
| February 19, 2013
| GK208
| 28
| 1020
| 79
| 1
| PCIe 3.0 x8
| 1024<br>2048
| 1
| 384:16:8
| 967
| {{n/a}}
| {{n/a}}
| 967
| 1001<br>(2002)
| 7.74
| 15.5
| 16
| DDR3
| 64
| 11.0
| 4.5
| 1.2
| 742.7
| 35
| 21.22
| OEM
|-
! style="text-align:left;"| GeForce GT 640<sup>8</sup>
| April 24, 2012
| GF116
| 40
| 1170
| 238
| 1
| PCIe 2.0 x16
| 1536<br>3072
| 3
| 144:24:24
| 720
| {{n/a}}
| {{n/a}}
| 1440
| 891<br>(1782)
| 17.3
| 17.3
| 42.8
| DDR3
| 192
| 11.0
| 4.5
| 1.1
| 414.7
| 75
| 5.53
| OEM
|-
! style="text-align:left;"| GeForce GT 640 (DDR3)
| April 24, 2012
| GK107-301-A2
| 28
| 1300
| 118
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 2
| 384:32:16
| 797
| {{n/a}}
| {{n/a}}
| 797
| 891<br>(1782)
| 12.8
| 25.5
| 28.5
| DDR3
| 128
| 11.0
| 4.5
| 1.2
| 612.1
| 50
| 12.24
| OEM
|-
! style="text-align:left;"| GeForce GT 640 (DDR3)
| June 5, 2012
| GK107
| 28
| 1300
| 118
| 1
| PCIe 3.0 x16
| 2048<br>4096
| 2
| 384:32:16
| 900
| {{n/a}}
| {{n/a}}
| 900
| 891<br>(1782)
| 14.4
| 28.8
| 28.5
| DDR3
| 128
| 11.0
| 4.5
| 1.2
| 691.2
| 65
| 10.63
| $100
|-
! style="text-align:left;"| GeForce GT 640 (GDDR5)
| April 24, 2012
| GK107
| 28
| 1300
| 118
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 2
| 384:32:16
| 950
| {{n/a}}
| {{n/a}}
| 950
| 1250<br>(5000)
| 15.2
| 30.4
| 80
| GDDR5
| 128
| 11.0
| 4.5
| 1.2
| 729.6
| 75
| 9.73
| OEM
|-
! style="text-align:left;"| GeForce GT 640 Rev. 2
| May 29, 2013
| GK208-400-A1
| 28
| 1020
| 79
| 1
| PCIe 2.0 x8
| 1024
| 2
| 384:32:8
| 1046
| {{n/a}}
| {{n/a}}
| 1046
| 1252<br>(5008)
| 8.37
| 33.4
| 40.1
| GDDR5
| 64
| 11.0
| 4.5
| 1.2
| 803.3
| 49
| 16.39
| 
|-
! style="text-align:left;"| GeForce GT 645<sup>9</sup>
| April 24, 2012
| GF114-400-A1
| 40
| 1950
| 332
| 1
| PCIe 2.0 x16
| 1024
| 6
| 288:48:24
| 776
| {{n/a}}
| {{n/a}}
| 1552
| 1914
| 18.6
| 37.3
| 91.9
| GDDR5
| 192
| 11.0
| 4.5
| 1.1
| 894
| 140
| 6.39
| OEM
|-
! style="text-align:left;"| GeForce GTX 645
| April 22, 2013
| GK106
| 28
| 2540
| 221
| 1
| PCIe 3.0 x16
| 1024
| 3
| 576:48:16
| 823.5
| 888.5
| {{n/a}}
| 823
| 1000<br>(4000)
| 14.16
| 39.5
| 64
| GDDR5
| 128
| 11.0
| 4.5
| 1.2
| 948.1
| 64
| 14.81
| OEM
|-
! style="text-align:left;"| GeForce GTX 650
| September 13, 2012
| GK107-450-A2
| 28
| 1300
| 118
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 2
| 384:32:16
| 1058
| {{n/a}}
| {{n/a}}
| 1058
| 1250<br>(5000)
| 16.9
| 33.8
| 80
| GDDR5
| 128
| 11.0
| 4.5
| 1.2
| 812.54
| 64
| 12.7
| $110
|-
! style="text-align:left;"| GeForce GTX 650 Ti
| October 9, 2012
| GK106-220-A1
| 28
| 2540
| 221
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 4
| 768:64:16
| 928
| {{n/a}}
| {{n/a}}
| 928
| 1350<br>(5400)
| 14.8
| 59.4
| 86.4
| GDDR5
| 128
| 11.0
| 4.5
| 1.2
| 1425.41
| 110
| 12.92
| $150 (130)
|-
! style="text-align:left;"| GeForce GTX 650 Ti Boost
| March 26, 2013
| GK106-240-A1
| 28
| 2540
| 221
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 4
| 768:64:24
| 980
| 1032
| {{n/a}}
| 980
| 1502<br>(6008)
| 23.5
| 62.7
| 144.2
| GDDR5
| 192
| 11.0
| 4.5
| 1.2
| 1505.28
| 134
| 11.23
| $170 (150)
|-
! style="text-align:left;"| GeForce GTX 660
| September 13, 2012
| GK106-400-A1
| 28
| 2540
| 221
| 1
| PCIe 3.0 x16
| 2048<br />3072
| 5
| 960:80:24
| 980
| 1032
| 1084
| 980
| 1502<br>(6008)
| 23.5
| 78.4
| 144.2
| GDDR5
| 192
| 11.0
| 4.5
| 1.2
| 1881.6
| 140
| 13.44
| $230 (180)
|-
! style="text-align:left;"| GeForce GTX 660 (OEM<ref>{{cite web|url=http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-660-oem|accessdate=2012-09-13|title=GeForce GTX 660 (OEM)|publisher=GeForce.com}}</ref>)
| August 22, 2012
| GK104-200-KD-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 1536<br />2048
| 6
| 1152:96:24<br>1152:96:32
| 823.5
| 888.5
| 899
| 823
| 1450<br>(5800)
| 19.8
| 79
| 134
| GDDR5
| 192<br>256
| 11.0
| 4.5
| 1.2
| 2108.6
| 130
| 16.22
| OEM
|-
! style="text-align:left;"| GeForce GTX 660 Ti
| August 16, 2012
| GK104-300-KD-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048<br />3072
| 7
| 1344:112:24
| 915
| 980
| 1058
| 915
| 1502<br>(6008)
| 22.0
| 102.5
| 144.2
| GDDR5
| 192
| 11.0
| 4.5
| 1.2
| 2459.52
| 150
| 16.40
| $300
|-
! style="text-align:left;"| GeForce GTX 670
| May 10, 2012
| GK104-325-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048<br>4096
| 7
| 1344:112:32
| 915
| 980
| 1084
| 915
| 1502<br>(6008)
| 29.3
| 102.5
| 192.256
| GDDR5
| 256
| 11.0
| 4.5
| 1.2
| 2459.52
| 170
| 14.47
| $400
|-
! style="text-align:left;"| GeForce GTX 680
| March 22, 2012
| GK104-400-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048<br>4096
| 8
| 1536:128:32
| 1006<ref name="gtx680-nvidia-paper">{{PDFlink|[http://www.geforce.com/Active/en_US/en_US/pdf/GeForce-GTX-680-Whitepaper-FINAL.pdf NVIDIA GeForce GTX 680 Whitepaper.pdf]| 1405KB}}, page 6 of 29</ref>
| 1058
| 1110
| 1006
| 1502<br>(6008)
| 32.2
| 128.8
| 192.256
| GDDR5
| 256
| 11.0
| 4.5
| 1.2
| 3090.43
| 195
| 15.85
| $500
|-
! style="text-align:left;"| GeForce GTX 690
| April 29, 2012
| 2 GK104-355-A2
| 28
| 2 3540
| 2 294 
| 2
| PCIe 3.0 x16
| 2 2048
| 2 8
| 2 1536:128:32
| 915
| 1019
| 1058
| 915
| 1502<br>(6008)
| 2 29.28
| 2 117.12
| 2 192.256
| GDDR5
| 2 256
| 11.0
| 4.5
| 1.2
| 2 2810.88
| 300
| 18.74
| $1000
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | SM count
! rowspan=2 | Core config <sup>1</sup>
! colspan=5 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | GFLOPS (FMA)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Core ([[Hertz|MHz]])
! Average Boost ([[Hertz|MHz]])
! Max Boost ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]
|}

===GeForce 700 Series===
{{Main|GeForce 700 Series|Kepler (microarchitecture)}}
The GeForce 700 series for desktop. The GM107-chips are [[Maxwell (microarchitecture)|Maxwell]]-based, the GKxxx-chips [[Kepler (microarchitecture)|Kepler]].

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Max Boost depends on ASIC quality. For example some GTX Titan with over 80% ASIC quality can hit 1019&nbsp;MHz by default, lower ASIC quality will be 1006&nbsp;MHz or 993&nbsp;MHz.
* <sup>3</sup> Kepler supports some optional 11.1 features on [[Direct3D feature level|feature level]] 11_0 through the DirectX 11.1 API, however Nvidia did not enable four non-gaming features to qualify Kepler for level 11_1.<ref>[http://www.guru3d.com/news_story/nvidia_kepler_not_fully_compliant_with_directx_11_1.html NVIDIA Kepler not fully compliant with DirectX 11.1]</ref><ref>[http://www.brightsideofnews.com/news/2012/11/21/nvidia-doesnt-fully-support-directx-111-with-kepler-gpus2c-bute280a6.aspx Nvidia Doesn't Fully Support DirectX 11.1 with Kepler GPUs, But - Bright Side Of News ]</ref>
* <sup>4</sup> The GeForce GT 705 (OEM) is a rebranded GeForce GT 620 (OEM), which itself is a rebranded GeForce GT 520.
* <sup>5</sup> The GeForce GT 730 (DDR3, 64-bit) is a rebranded GeForce GT 630 (Rev. 2).
* <sup>6</sup> The GeForce GT 730 (DDR3, 128-bit) is a rebranded GeForce GT 430 (128-bit).
* <sup>7</sup> The GeForce GTX 760 Ti (OEM) is a rebranded GeForce GTX 670.

{| class="wikitable" style="font-size: 80%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | SMX count
! rowspan=2 | Core config <sup>1</sup>
! colspan=4 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! colspan=2 style="text-align:center;" | Processing Power (peak) <br> [[GFLOPS]]
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! colspan=2 style="text-align:center;" | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Base ([[Hertz|MHz]])
! Average Boost ([[Hertz|MHz]])
! Max Boost <sup>2</sup>([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]<sup>3</sup>
! [[OpenGL]]
! [[OpenCL]]
! Single Precision
! Double Precision
! Single Precision
! Double Precision
|-
! style="text-align:left;"| GeForce GT 705<ref>http://www.techpowerup.com/gpudb/2578/geforce-gt-705.html</ref><sup>4</sup>
| March 27, 2014
| GF119-300-A1
| 40
| 292
| 79
| 1
| PCIe 2.0 x16
| 512<br>1024
| 1
| 48:8:4
| 810
|{{n/a}}
|{{n/a}}
| 898<br>(1796)
| 3.24
| 6.5
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 1.1
| 155.5
| {{unk}}
| 29
| 5.18
| {{unk}}
| OEM
|-
! style="text-align:left;"| GeForce GT 710<ref>http://www.techpowerup.com/gpudb/1990/geforce-gt-710.html</ref>
| Mar 27, 2014
| GK208-301-A1
| 28
| 1020
| 79
| 1
| PCIe 2.0 x8
| 512
| 1
| 192:16:8
| 823
| {{n/a}}
| {{n/a}}
| 900 (1800)
| 6.6
| 13.2
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 1.2
| 316
| {{unk}}
| 
| 
| {{unk}}
| OEM
|-
! style="text-align:left;"| GeForce GT 720<ref>http://www.techpowerup.com/gpudb/1989/geforce-gt-720.html</ref>
| Mar 27, 2014
| GK208
| 28
| 1020
| 79
| 1
| PCIe 2.0 x8
| 1024<br>2048
| 2
| 192:16:8
| 797
| {{n/a}}
| {{n/a}}
| 900 (1800)
| 6.4
| 12.8
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 1.2
| 306
| {{No}}
| 19
| 16.1
| {{n/a}}
| $4959
|-
! style="text-align:left;"| GeForce GT 730<br>(64b&nbsp;DDR3)<ref name="gt730">http://www.geforce.com/hardware/desktop-gpus/geforce-gt-730/specifications</ref><sup>5</sup>
| June 18, 2014
| GK208-301-A1
| 28
| 1020
| 79
| 1
| PCIe 2.0 8 
| 1024<br>2048<br>4096
| 2
| 384:32:8
| 902
|{{n/a}}
|{{n/a}}
| 900<br>(1800)
| 7.22
| 28.8
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 1.2
| 692.7
| {{No}}
| 23
| 30.12
| {{n/a}}
| $6979
|-
! style="text-align:left;"| GeForce GT 730<br>(128b&nbsp;DDR3)<ref name="gt730"/><sup>6</sup>
| June 18, 2014
| GF108
| 40
| 585
| 116
| 1
| PCIe 2.0 16 
| 1024<br>2048<br>4096
| 2
| 96:16:4	
| 700
|{{n/a}}
|{{n/a}}
| 900<br>(1800)
| 2.8
| 11.2
| 28.8
| DDR3
| 128
| 11.0
| 4.5
| 1.1
| 268.8
| {{No}}
| 49
| 5.49
| {{n/a}}
| $6979
|-
! style="text-align:left;"| GeForce GT 730 (GDDR5)<ref name="gt730"/>
| June 18, 2014
| GK208-400-A1
| 28
| 1020
| 79
| 1
| PCIe 2.0 x8 
| 1024
| 2
| 384:32:8
| 902
|{{n/a}}
|{{n/a}}
| 1250<br>(5000)
| 7.22
| 28.8
| 40.0
| GDDR5
| 64
| 11.0
| 4.5
| 1.2
| 692.7
| {{No}}
| 38
| 18.23
| {{n/a}}
| $6979
|-
! style="text-align:left;" | GeForce GT 740 (DDR3)
| May 29, 2014
| GK107-425-A2
| 28
| 1270
| 118
| 1
| PCIe 3.0 x16
| 1024<br>2048<br>4096
| 2
| 384:32:16
| 993
| {{n/a}}
| {{n/a}}
| 891<br>(1782)
| 15.9
| 31.8
| 28.5
| DDR3
| 128
| 11.0
| 4.5
| 1.2
| 762.6
| {{unk}}
| 64
| 11.9
| {{unk}}
| $8999
|-
! style="text-align:left;" | GeForce GT 740 (GDDR5)<ref>http://www.techpowerup.com/gpudb/1987/geforce-gt-740.html</ref>
| May 29, 2014
| GK107-425-A2
| 28
| 1270
| 118
| 1
| PCIe 3.0 x16
| 1024<br>2048<br>4096
| 2
| 384:32:16
| 993
| {{n/a}}
| {{n/a}}
| 1252<br>(5008)
| 15.9
| 31.8
| 80.1
| GDDR5
| 128
| 11.0
| 4.5
| 1.2
| 762.6
| {{unk}}
| 64
| 11.9
| {{unk}}
| $8999
|-
! style="text-align:left;" | GeForce GTX 745<ref>http://www.techpowerup.com/gpudb/2561/geforce-gtx-745.html</ref><ref>http://www.dell.com/us/p/alienware-x51-r2/pd</ref><ref>http://www.shopping.hp.com/en_US/home-office/-/products/Desktops/HP-ENVY/J0X43AV</ref>
| February 18, 2014
| GM107-300-A2
| 28
| 1870
| 148
| 1
| PCIe 3.0 x16
| 1024<br />4096
| 3
| 384:24:16
| 1033
| {{unk}}
| {{unk}}
| 900<br>(1800)
| 16.5
| 24.8
| 28.8
| DDR3
| 128
| 11.2
| 4.5
| 1.2
| 793.3
| 24.8
| 55
| 14.4
| 0.45
| OEM
|-
! style="text-align:left;" | GeForce GTX 750
| February 18, 2014
| GM107-300-A2
| 28
| 1870
| 148
| 1
| PCIe 3.0 x16
| 1024<br>2048
| 4
| 512:32:16
| 1020
| 1085
| 1163
| 1250<br>(5000)
| 16.3
| 32.6
| 80
| GDDR5
| 128
| 11.2
| 4.5
| 1.2
| 1044
| 32.6
| 55
| 19
| 0.59
| $119
|-
! style="text-align:left;" | GeForce GTX 750 Ti
| February 18, 2014
| GM107-400-A2
| 28
| 1870
| 148
| 1
| PCIe 3.0 x16
| 2048<br>4096
| 5
| 640:40:16
| 1020
| 1085
| 1200
| 1350<br />(5400)
| 16.3
| 40.8
| 88
| GDDR5
| 128
| 11.2
| 4.5
| 1.2
| 1306
| 40.8
| 60
| 21.8
| 0.68
| $149
|-
! style="text-align:left;" | GeForce GTX 760 192-bit
| {{unk}}
| GK104
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 1536<br>3072
| 6
| 1152:96:24
| 823
| 888
| {{unk}}
| 1450<br>(5800)
| 19.8
| 79
| 134
| GDDR5
| 192
| 11.0
| 4.5
| 1.2
| 1896
| 79
| 130
| 14.6
| 0.60
| OEM
|-
! style="text-align:left;" | GeForce GTX 760
| June 25, 2013
| GK104-225-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048<br>4096
| 6
| 1152:96:32
| 980
| 1033
| 1124
| 1502<br>(6008)
| 31.4
| 94
| 192.3
| GDDR5
| 256
| 11.0
| 4.5
| 1.2
| 2257
| 94
| 170
| 13.3
| 0.55
| $249 ($219)
|-
! style="text-align:left;" | GeForce GTX 760 Ti
| {{unk}}
| GK104
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048
| 7
| 1344:112:32
| 915
| 980
| 1084
| 1502<br>(6008)
| 29.3
| 102.5
| 192.3
| GDDR5
| 256
| 11.0
| 4.5
| 1.2
| 2460
| 103
| 170
| 14.5
| 0.60
| OEM
|-
! style="text-align:left;" | GeForce GTX 770
| May 30, 2013
| GK104-425-A2
| 28
| 3540
| 294
| 1
| PCIe 3.0 x16
| 2048
4096
| 8
| 1536:128:32
| 1046
| 1085
| 1130
| 1752.5<br>(7010)
| 33.5
| 134
| 224
| GDDR5
| 256
| 11.0
| 4.5
| 1.2
| 3213
| 134
| 230
| 14.0
| 0.58
| $399 ($329)
|-
! style="text-align:left;" | GeForce GTX 780
| May 23, 2013
| GK110-300-A1
| 28
| 7080
| 561
| 1
| PCIe 3.0 x16
| 3072
6144<ref>http://www.evga.com/articles/00830/</ref>
| 12
| 2304:192:48
| 863
| 900
| 1002
| 1502<br>(6008)
| 41.4
| 160.5
| 288.4
| GDDR5
| 384
| 11.0
| 4.5
| 1.2
| 3977
| 166
| 250
| 15.9
| 0.66
| $649 ($499)
|-
! style="text-align:left;" | GeForce GTX 780 Ti<ref>{{cite web|url=http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-780-ti/specifications|title=GeForce GTX780 Ti. Specifications}}</ref><ref>{{cite web|url=http://videocardz.com/47508/videocardz-nvidia-geforce-gtx-780-ti-2880-cuda-cores|title=NVIDIA GeForce GTX 780 Ti has 2880 CUDA cores.}}</ref><ref>{{cite web|url=http://web-engage.augure.com/pub/link/282593/04601926874847631383752919307-hl-com.com.html|title=PNY dvoile son nouveau foudre de guerre : la GeForce GTX 780 TI.}}</ref>
| Nov 7, 2013
| GK110-425-B1
| 28
| 7080
| 561
| 1
| PCIe 3.0 x16
| 3072
| 15
| 2880:240:48
| 876
| 928
| 1019
| 1752.5<br>(7010)
| 42.0
| 210.2
| 336.5
| GDDR5
| 384 
| 11.0<ref>http://www.techpowerup.com/gpudb/2512/geforce-gtx-780-ti.html</ref>
| 4.5
| 1.2
| 5046
| 210
| 250
| 20.2
| 0.84
| $699
|-
! style="text-align:left;"| GeForce <br> GTX Titan<ref>{{cite web|url=http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-titan|title=GeForce GTX TITAN (Official Nvidia Site)}}</ref><ref>{{cite web|url=http://www.nvidia.com/titan-graphics-card|title=Titan Graphics Card (Official Nvidia Site)}}</ref><ref>{{cite web|url=http://www.anandtech.com/show/6760/nvidias-geforce-gtx-titan-part-1|title=NVIDIA's GeForce GTX Titan, Part 1: Titan For Gaming, Titan For Compute}}</ref>
| February 21, 2013
| GK110-400-A1
| 28
| 7080
| 561
| 1
| PCIe 3.0 x16
| 6144
| 14
| 2688:224:48
| 837
| 876
| 993
| 1502<br>(6008)
| 40.2
| 187.5
| 288.4
| GDDR5
| 384
| 11.0
| 4.5
| 1.2
| 4500
| 1300-1500<ref>[http://www.anandtech.com/show/6774/nvidias-geforce-gtx-titan-part-2-titans-performance-unveiled/3] // AndandTech, "At 837MHz, the calculated fp64 peak of Titan is 1.5 TFlops. ..  Thus, fp64 ALU peak can vary between 1.3 TFlops and 1.5 TFlops and our DGEMM results are within expectations."</ref>
| 250
| 18
| 5.2-6
| $999
|-
! style="text-align:left;"| GeForce GTX <br> Titan Black
| February 18, 2014
| GK110-430-B1
| 28
| 7080
| 561
| 1
| PCIe 3.0 x16
| 6144
| 15
| 2880:240:48
| 889
| 980
| 1058
| 1752.5<br>(7010)
| 42.7
| 213.4
| 336.5
| GDDR5
| 384
| 11.0
| 4.5
| 1.2
| 5121
| 1707
| 250
| 20.5
| 6.8
| $999
|-
! style="text-align:left;" | GeForce GTX <br> Titan Z
| March 25, 2014
| 2 GK110
| 28
| 2 7080
| 2 561
| 2
| PCIe 3.0 x16
| 2 6144
| 2 15
| 2 2880:240:48
| 705
| 876
| {{unk}}
| 1752.5<br>(7010)
| 2 33.8
| 2 169
| 2 336.5
| GDDR5
| 2 384
| 11.0
| 4.5
| 1.2
| 8122
| 2707
| 375
| 21.7
| 7.2 
| $2999 ($1499)
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm<sup>2</sup>)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | SMX count
! rowspan=2 | Core config <sup>1</sup>
! colspan=4 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! colspan=2 style="text-align:center;" | Processing Power (peak) <br> [[GFLOPS]]
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! colspan=2 style="text-align:center;" | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Base ([[Hertz|MHz]])
! Average Boost ([[Hertz|MHz]])
! Max Boost <sup>2</sup>([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]<sup>3</sup>
! [[OpenGL]]
! [[OpenCL]]
! Single Precision
! Double Precision
! Single Precision
! Double Precision
|}

===GeForce 900 Series===
{{Main|GeForce 900 Series|Maxwell (microarchitecture)}}
The GeForce 900 series for desktop. The GM20x chips are [[Maxwell (microarchitecture)|Maxwell]]-based.

* <sup>1</sup> [[Unified shader model|Shader Processors]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Pixel fillrate is calculated as the number of ROPs multiplied by the base core clock speed
* <sup>3</sup> Texture fillrate is calculated as the number of TMUs multiplied by the base core clock speed.
* <sup>4</sup> Single precision performance is calculated as 2 times the number of shaders multiplied by the base core clock speed.
* <sup>5</sup> Double precision performance of the '''Maxwell''' chips is 1/32 of single-precision performance.<ref>{{cite news |last1=Smith |first1=Ryan |date=September 18, 2014 |title=The NVIDIA GeForce GTX 980 Review: Maxwell Mark 2 |url=http://www.anandtech.com/show/8526/nvidia-geforce-gtx-980-review |newspaper=[[AnandTech]] |page=1 |accessdate=September 19, 2014}}</ref><ref>[http://anandtech.com/show/9059/the-nvidia-geforce-gtx-titan-x-review AnandTech | The NVIDIA GeForce GTX Titan X Review]</ref>
* <sup>6</sup> For accessing its memory, the GTX 970 stripes data across 7 of its 8 32-bit physical memory lanes, at 196&nbsp;GB/s. The last 1/8 of its memory (0.5&nbsp;GiB on a 4&nbsp;GiB card) is accessed on a non-interleaved solitary 32-bit connection at 28 GB/s, one seventh the speed of the rest of the memory space.  Because this smaller memory pool uses the same connection as the 7th lane to the larger main pool, it contends with accesses to the larger block reducing the effective memory bandwidth not adding to it as an independent connection could.<ref>{{cite news |last1=Wasson |first1=Scott |date=January 26, 2015 |title=Nvidia: the GeForce GTX 970 works exactly as intended, A look inside the card's unusual memory config |url=http://techreport.com/review/27724/nvidia-the-geforce-gtx-970-works-exactly-as-intended |newspaper=[[The Tech Report]] |page=1 |accessdate=January 26, 2015}}</ref>

{| class="wikitable" style="font-size: 80%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | Transistors (Million)
! rowspan=2 | Die Size (mm)
! rowspan=2 | Die Count
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | SMM count
! rowspan=2 | Core config <sup>1</sup>
! colspan=4 style="text-align:center;" | Clock rate
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory Configuration
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! colspan=2 style="text-align:center;" | Processing Power (peak) <br> [[GFLOPS]]
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! colspan=2 style="text-align:center;" | GFLOPS/W
! rowspan=2 | Release Price (USD)
|-
! Base ([[Hertz|MHz]])
! Average Boost ([[Hertz|MHz]])
! Max Boost ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)<sup>2</sup>
! Texture ([[Texel (graphics)|GT]]/s)<sup>3</sup>
! Bandwidth ([[Gigabyte|GB]]/s)
! DRAM type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]
! Single Precision<sup>4</sup>
! Double Precision<sup>5</sup>
! Single Precision<sup>4</sup>
! Double Precision<sup>5</sup>
|-
! style="text-align:left;" | GeForce GTX 960 <ref>http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-960/specifications</ref>
| January 22, 2015
| GM206
| 28
| 2940
| 227
| 1
| PCIe 3.0 x16
| 2048<br>4096
| 8
| 1024:64:32
| 1127
| 1178
| 1228
| 1752.5<br>(7010)
| 36.1
| 72.1
| 112
| GDDR5
| 128
| 12.0
| 4.5
| 1.2
| 2308
| 72.1
| 120
| 19.2
| 0.6
| $199
|-
! style="text-align:left;" | GeForce GTX 970 <ref>http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-970/specifications</ref>
| September 18, 2014
| GM204-200
| 28
| 5200
| 398
| 1
| PCIe 3.0 x16
| 3584+512<sup>6</sup>
| 13
| 1664:104:56
| 1050 
| 1178
| 1250
| 1752.5<br>(7010)
| 58.8
| 109.2
| 196 and 28<sup>6</sup>
| GDDR5
| 224 and 32<sup>6</sup>
| 12.0
| 4.5
| 1.2
| 3494
| 109
| 145
| 24.1
| 0.75
| $329
|-
! style="text-align:left;" | GeForce GTX 980 <ref>http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-980/specifications</ref>
| September 18, 2014
| GM204-400
| 28
| 5200
| 398
| 1
| PCIe 3.0 x16
| 4096
| 16
| 2048:128:64
| 1126 
| 1216
| 1266
| 1752.5<br>(7010)
| 72.1
| 144
| 224
| GDDR5
| 256
| 12.0
| 4.5
| 1.2<ref>http://www.techpowerup.com/gpudb/2621/geforce-gtx-980.html</ref>
| 4612
| 144
| 165
| 28.0
| 0.87
| $549
|-
! style="text-align:left;" | GeForce GTX 980 Ti<ref>http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-980-ti/specifications</ref>
| June 1, 2015
| GM200-310
| 28
| 8000
| 601
| 1
| PCIe 3.0 x16
| 6144
| 22
| 2816:176:96
| 1000
| 1075
| 
| 1752.5<br>(7010)
| 96
| 176
| 336
| GDDR5
| 384
| 12.0
| 4.5
| 1.2
| 5632
| 176
| 250
| 22.5
| 0.70
| $649
|-
! style="text-align:left;" | GeForce GTX Titan X<ref>http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-titan-x/specifications</ref>
| March 17, 2015
| GM200-400
| 28
| 8000
| 601
| 1
| PCIe 3.0 x16
| 12288
| 24
| 3072:192:96
| 1000
| 1088.5
| 
| 1752.5<br>(7010)
| 106
| 196
| 336
| GDDR5
| 384
| 12.0
| 4.5
| 1.2
| 6144
| 192
| 250
| 24.6
| 0.77
| $999
|}

==Comparison table: Mobile GPUs==

===GeForce2 Go Series===
* All models are manufactured with a 180&nbsp;nm manufacturing process
* All models support [[DirectX]] 7.0 and [[OpenGL]] 1.2

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce2 Go 100 
|February 6, 2001
|NV11M
|AGP 4x
|8, 16
|125
|332
|2:0:4:2
|250
|250
|500
|0
|1.328
|DDR
|32
|-
!style="text-align:left"|GeForce2 Go 
|November 11, 2000
|NV11M
|AGP 4x
|16, 32
|143
|166<br>332 
|2:0:4:2
|286
|286
|572
|0
|2.656
|SDR<br>DDR
|128<br>64
|-
!style="text-align:left"|GeForce2 Go 200
|February 6, 2001
|NV11M
|AGP 4x
|16, 32
|143
|332 
|2:0:4:2
|286
|286
|572
|0
|2.656
|DDR
|64
|}

* <sup>1</sup>[[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce4 Go Series===
* All models are manufactured with a 150&nbsp;nm manufacturing process

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
!colspan=2|[[Application Programming Interface|API]] support
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
![[DirectX]]
![[OpenGL]] 
|-
!style="text-align:left"|GeForce4 Go 410 
|February 6, 2002
|NV17M
|AGP 8X
|16
|200
|200
|2:0:4:2
|400
|400
|800
|0
|1.6
|SDR
|64
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Go 420 
|February 6, 2002
|NV17M
|AGP 8X
|32
|200
|400
|2:0:4:2
|400
|400
|800
|0
|3.2
|DDR
|64
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Go 440 
|February 6, 2002
|NV17M
|AGP 8X
|64
|220
|440
|2:0:4:2
|440
|440
|880
|0
|7.04
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Go 460 
|October 14, 2002
|NV17M
|AGP 8X
|64
|250
|500
|2:0:4:2
|500
|500
|1000
|0
|8
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Go 488 
|
|NV18M
|AGP 8X
|64
|300
|550
|2:0:4:2
|600
|600
|1200
|0
|8.8
|DDR
|128
|7.0
|1.2
|-
!style="text-align:left"|GeForce4 Go 4200 
|November 14, 2002
|NV28M
|AGP 8X
|64
|200
|400
|4:2:8:4
|800
|800
|1600
|100
|6.4
|DDR
|128
|8.1
|1.3
|}

* <sup>1</sup>[[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce FX Go 5 (Go 5xxx) Series===
The GeForce FX Go 5 Series for notebooks architecture.
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>*</sup> NV31, NV34 and NV36 are 2x2 pipeline designs if running vertex shader, otherwise they are 4x1 pipeline designs.
* <sup>**</sup> GeForce FX Series has limited OpenGL 2.1 support(with the last Windows XP driver released for it, 175.19).
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=3 | Model
! rowspan=3 | Launch
! rowspan=3 | [[Code name]]
! rowspan=3 | Fab ([[Nanometer|nm]])
! rowspan=3 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=3 | Memory ([[Megabyte|MB]])
! rowspan=3 | Core clock ([[Hertz|MHz]])
! rowspan=3 | Memory clock ([[Hertz|MHz]])
! rowspan=3 | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=3 | [[Thermal Design Power|TDP]] (watts)
! rowspan=3 | Features
|-
! rowspan=2 | Pixel ([[Pixel|GP]]/s)
! rowspan=2 | Texture ([[Texel (graphics)|GT]]/s)
! rowspan=2 | Bandwidth ([[Gigabyte|GB]]/s)
! rowspan=2 | Bus type
! rowspan=2 | Bus width ([[bit]])
! rowspan=2 | [[DirectX]]
! colspan=2 | [[OpenGL]]
|-
! Hardware
! Drivers (Software)
|-
! style="text-align:left;" | GeForce FX Go 5100<sup>*</sup>
| March 2003
| NV34M
| 150
| AGP x8
| 64
| 200
| 400
| 1:2:2:2 *:4:4:4
| 0.8
| 0.8
| 3.2
| DDR
| 64
| 9.0
| 1.5
| 2.1**
| {{unk}}
|
|-
! style="text-align:left;" | GeForce FX Go 5200<sup>*</sup>
| March 2003
| NV34M
| 150
| AGP x8
| 32<br>64
| 300
| 600
| 1:2:2:2 *:4:4:4
| 1.2
| 1.2
| 9.6
| DDR
| 128
| 9.0
| 1.5
| 2.1**
| {{unk}}
|
|-
! style="text-align:left;" | GeForce FX Go 5600<sup>*</sup>
| March 2003
| NV31M
| 130
| AGP x8
| 32
| 350
| 600
| 1:2:2:2 *:4:4:4
| 1.4
| 1.4
| 9.6
| DDR
| 128
| 9.0
| 1.5
| 2.1**
| {{unk}}
|
|-
! style="text-align:left;" | GeForce FX Go 5650<sup>*</sup>
| March 2003
| NV31M
| 130
| AGP x8
| 32
| 350
| 600
| 1:2:2:2 *:4:4:4
| 1.4
| 1.4
| 9.6
| DDR
| 128
| 9.0
| 1.5
| 2.1**
| {{unk}}
|
|-
! style="text-align:left;" | GeForce FX Go 5700<sup>*</sup>
| February 1, 2005
| NV36M
| 130
| AGP x8
| 32
| 450
| 550
| 3:2:2:2 *:4:4:4
| 1.8
| 1.8
| 8.8
| DDR
| 128
| 9.0
| 1.5
| 2.1**
| {{unk}}
|
|}

===GeForce Go 6 (Go 6xxx) Series===
* All models support [[DirectX]] 9.0c and [[OpenGL]] 2.1

{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
|-
!style="text-align:left"|GeForce Go 6100 + nForce Go 430
|{{unk}}
|C51M
|110
|HyperTransport
|Up to 128 MB system
|425
|System Memory
|2:1:2:1
|850
|425
|850
|106.25
|System Memory
|DDR2
|64/128
|-
!style="text-align:left"|GeForce Go 6150 + nForce Go 430
|{{unk}}
|C51M
|110
|HyperTransport
|Up to 128 MB system
|425
|System Memory
|2:1:2:1
|850
|425
|850
|106.25
|System Memory
|DDR2
|64/128
|-
!style="text-align:left"|GeForce Go 6200
|{{unk}}
|NV44M
|110
|PCI-E x16
|16
|300
|600
|4:3:4:2
|1200
|600
|1200
|225
|2.4 
|DDR
|32
|-
!style="text-align:left"|GeForce Go 6400
|{{unk}}
|NV44M
|110
|PCI-E x16
|16
|400
|700
|4:3:4:2
|1600
|800
|1600
|250
|5.6
|DDR
|64
|-
!style="text-align:left"|GeForce Go 6600
|{{unk}}
|NV43M
|110
|PCI-E x16
|128
|300
|700
|8:3:8:4
|3000
|1500
|3000
|281.25
|11.2
|DDR
|128
|-
!style="text-align:left"|GeForce Go 6800
|November 8, 2004
|NV41M
|130
|PCI-E x16
|128
|300
|700<br>1100
|12:5:12::12
|3000
|1500
|3000
|375
|22.4<br>35.2
|DDR, DDR2<br>DDR3
|256
|-
!style="text-align:left"|GeForce Go 6800 Ultra
|February 24, 2005
|NV41M
|130
|PCI-E x16
|256
|450
|700<br>1100
|12:5:12::12
|5400
|3600
|5400
|562.5
|22.4<br>35.2
|DDR, DDR2<br>DDR3
|256
|}

* <sup>1</sup> [[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

===GeForce Go 7 (Go 7xxx) Series===
The GeForce Go 7 Series for notebooks architecture.
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Graphics card supports [[TurboCache]], memory size entries in bold indicate total memory (VRAM + System RAM), otherwise entries are VRAM only
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Features
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
!style="text-align:left;" | GeForce 7000M
| February 1, 2006
| MCP67MV
| 90
| [[HyperTransport|Hyper Transport]]
| Up to 256 from system memory
| 350
| System Memory
| 1:2:2:2
| 0.7
| 0.7
| System Memory
| DDR2
| 64/128
| 9.0c
| 2.1
| {{unk}}
|
|-
!style="text-align:left;" | GeForce 7150M
| February 1, 2006
| MCP67M
| 90
| [[HyperTransport|Hyper Transport]]
| Up to 256 from system memory
| 425
| System Memory
| 1:2:2:2
| 0.85
| 0.85
| System Memory
| DDR2
| 64/128
| 9.0c
| 2.1
| {{unk}}
|
|-
! style="text-align:left;" | GeForce Go 7200<sup>2</sup>
| Jan 2006
| G72M
| 90
| PCIe x16
| 64
| 450
| 700
| 3:4:4:1
| 0.45
| 1.8
| 2.8
| GDDR3
| 32
| 9.0c
| 2.1
| {{unk}}
| Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7300<sup>2</sup>
| Jan 2006
| G72M
| 90
| PCIe x16
| 128, 256, '''512'''
| 350
| 700
| 3:4:4:2
| 0.7
| 1.4
| 5.60
| GDDR3
| 64
| 9.0c
| 2.1
| {{unk}}
| Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7400<sup>2</sup>
| Jan 2006
| G72M
| 90
| PCIe x16
| 64, '''256'''
| 450
| 900
| 3:4:4:2
| 0.9
| 1.8
| 7.20
| GDDR3
| 64
| 9.0c
| 2.1
| {{unk}}
| Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7600
| Mar 2006
| G73M
| 90
| PCIe x16
| 256, 512
| 450
| 1000
| 5:8:8:8
| 3.6
| 3.6
| 16
| GDDR3
| 128
| 9.0c
| 2.1
| {{unk}}
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7600 GT
| 2006
| G73M
| 90
| PCIe x16
| 256
| 500
| 1200
| 5:12:12:8
| 4
| 6
| 19.2
| GDDR3
| 128
| 9.0c
| 2.1
| {{unk}}
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7700
| 2006
| G73-N-B1
| 80
| PCIe x16
| 512
| 450
| 1000
| 5:12:12:8
| 3.6
| 5.4
| 16
| GDDR3
| 128
| 9.0c
| 2.1
| {{unk}}
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7800
| March 3, 2006
| G70M
| 110
| PCIe x16
| 256
| 400
| 1100
| 6:16:16:8
| 3.2
| 6.4
| 35.2
| GDDR3
| 256
| 9.0c
| 2.1
| 35
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7800 GTX
| Oct 2005
| G70M
| 110
| PCIe x16
| 256
| 400
| 1100
| 8:24:24:16
| 6.4
| 9.6
| 35.2
| GDDR3
| 256
| 9.0c
| 2.1
| 65
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7900 GS
| Apr 2006
| G71M
| 90
| PCIe x16
| 256
| 375
| 1000
| 7:20:20:16
| 6
| 7.5
| 32.0
| GDDR3
| 256
| 9.0c
| 2.1
| 20
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7900 GTX
| Apr 2006
| G71M
| 90
| PCIe x16
| 256/512
| 500
| 1200
| 8:24:24:16
| 8
| 12
| 38.4
| GDDR3
| 256
| 9.0c
| 2.1
| 45
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|-
! style="text-align:left;" | GeForce Go 7950 GTX
| Oct 2006
| G71M
| 90
| PCIe x16
| 512
| 575
| 1400
| 8:24:24:16
| 9.2
| 13.8
| 44.8
| GDDR3
| 256
| 9.0c
| 2.1
| 45
| Scalable Link Interface (SLI), Transparency Anti-Aliasing
|}

===GeForce 8M (8xxxM) Series===
The GeForce 8M Series for notebooks architecture [[Tesla (microarchitecture)|Tesla]].
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power [[GigaFLOPS|GFLOPS]]
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 8200M G <ref>{{cite web|url=http://www.geforce.com/hardware/notebook-gpus/geforce-8200m-g-mgpu/specifications|title=GeForce 8200M G mGPU. Specifications}}</ref>
| June 2008
| MCP77MV, MCP79MVL
| 80
| Integrated (PCIe 2.0 x16)
| Up to 256 from system memory
| 8:8:4
| 400
| 800
| 800<br>1066<br>(system memory)
| 1.6
| 3.2
| 12.8<br>17.056
| DDR2<br>DDR3
| 128
| 10.0
| 3.3
| 19.2
| {{unk}}
| {{unk}}
| [[PureVideo]] HD with VP3, Full H.264 / VC-1 / MPEG-2 HW Decode
|-
! style="text-align:left;" | GeForce 8400M G
| May 2007
| NB8M(G86)
| 80
| PCIe x16
| 128 / 256
| 8:8:4
| 400
| 800
| 800
| 1.6
| 3.2
| 6.4
| DDR2 / GDDR3
| 64
| 10.0
| 3.3
| 19.2
| 10
| 1.92
| [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8400M GS
| May 2007
| NB8M(G86)
| 80
| PCIe x16
| 128 / 256
| 16:8:4
| 400
| 800
| 800
| 1.6
| 3.2
| 6.4
| DDR2 / GDDR3
| 64
| 10.0
| 3.3
| 38.4
| 11
| 3.49
| [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8400M GT
| May 2007
| NB8M(G86)
| 80
| PCIe x16
| 256 / 512
| 16:8:4
| 450
| 900
| 1200
| 1.8
| 3.6
| 19.2
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 43.2
| 14
| 3.09
| [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8600M GS
| May 2007
| NB8P(G84)
| 80
| PCIe x16
| 256 / 512
| 16:8:4
| 600
| 1200
| 1400
| 2.4
| 4.8
| 22.4
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 57.6
| 20
| 2.88
| [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8600M GT
| May 2007
| NB8P(G84)
| 80
| PCIe x16
| 256 / 512
| 32:16:8
| 475
| 950
| 800 / 1400
| 3.8
| 7.6
| 12.8 / 22.4
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 91.2
| 20
| 4.56
| [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8700M GT
| June 2007
| NB8P(G84)
| 80
| PCIe x16
| 256 / 512
| 32:16:8
| 625
| 1250
| 1600
| 5
| 10
| 25.6
| GDDR3
| 128
| 10.0
| 3.3
| 120
| 29
| 4.14
| [[Scalable Link Interface]], [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8800M GTS
| November 2007
| NB8P(G92)
| 65
| PCIe 2.0 x16
| 512
| 64:32:16
| 500
| 1250
| 1600
| 8
| 16
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 240
| 50
| 4.8
| [[Scalable Link Interface]], [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|-
! style="text-align:left;" | GeForce 8800M GTX
| November 2007
| NB8P(G92)
| 65
| PCIe 2.0 x16
| 512
| 96:48:16
| 500
| 1250
| 1600
| 8
| 24
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 360
| 65
| 5.54
| [[Scalable Link Interface]], [[PureVideo]] HD with VP2, BSP Engine, and AES128 Engine
|}

===GeForce 9M (9xxxM) Series===
The GeForce 9M Series for notebooks architecture. [[Tesla (microarchitecture)]]
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power GFLOPS
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 9100M G <br>mGPU
| 2008
| MCP77MH, MCP79MH
| 65
| Integrated <br>(PCIe 2.0 x16)
| Up to 256 from system memory
| 8:8:4
| 450
| 1100
| 1066<br>(system memory)
| 1.8
| 3.6
| 17.056
| DDR3
| 128
| 10.0
| 3.3
| 26.4
| 12
| 2.2
| Similar to 8400M G
|-
! style="text-align:left;" | GeForce 9200M GS
| 2008
| NB9M-GE(G98)
| 65
| PCIe 2.0 x16
| 256
| 8:8:4
| 550
| 1300
| 1400
| 2.2
| 4.4
| 11.2
| DDR2/GDDR3
| 64
| 10.0
| 3.3
| 31.2
| 13
| 2.4
|
|-
! style="text-align:left;" | GeForce 9300M G
| 2008
| NB9M-GE(G86)
| 80
| PCIe 2.0 x16
| 256/512
| 16:8:4
| 400
| 800
| 1200
| 1.6
| 3.2
| 9.6
| DDR2/GDDR3
| 64
| 10.0
| 3.3
| 38.4
| 13
| 2.95
| 
|-
! style="text-align:left;" | GeForce 9300M GS
| 2008
| NB9M-GE(G98)
| 65
| PCIe 2.0 x16
| 256/512
| 8:8:4
| 550
| 1400
| 1400
| 2.2
| 4.4
| 11.2
| DDR2/GDDR3
| 64
| 10.0
| 3.3
| 33.6
| 13
| 2.58
|
|-
! style="text-align:left;" | GeForce 9400M G
| October 15, 2008
| MCP79MX
| 65
| Integrated(PCIe 2.0 x16)
| Up to 256 from system memory
| 16:8:4
| 450
| 1100
| 800<br>1066<br>(system memory)
| 1.8
| 3.6
| 12.8<br>17.056
| DDR2<br>DDR3
| 128
| 10.0
| 3.3
| 54
| 12
| 4.5
| PureVideo HD with VP3. Known as the GeForce 9400M in Apple systems<ref>[http://www.nvidia.com/object/product_geforce_9400m_g_us.html accessed 22 September 2009]</ref> and [[Nvidia ION]] based systems
|-
! style="text-align:left;" | GeForce 9500M G
| 2008
| NB9P(G96)
| 65
| PCIe 2.0 x16
| 512
| 16:8:8
| 500
| 1250
| 1600
| 4
| 4
| 25.6
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 60
| 20
| 3.0
|
|-
! style="text-align:left;" | GeForce 9500M GS
| 2008
| NB9P-GV(G96)
| 80
| PCIe x16
| 512
| 32:16:8
| 475
| 950
| 1400
| 3.8
| 7.6
| 22.4
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 91.2
| 20
| 4.56
|Rebranded 8600M GT
|-
! style="text-align:left;" | GeForce 9600M GS
| 2008
| NB9P-GE2(G96)
| 65
| PCIe 2.0 x16
| 1024
| 32:16:8
| 430
| 1075
| 800<br>1600
| 3.44
| 6.88
| 12.8<br>25.6
| DDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 103.2
| 20
| 5.16
|
|-
! style="text-align:left;" | GeForce 9600M GT
| 2008
| NB9P-GS(G96)
| 65
| PCIe 2.0 x16
| 512/1024
| 32:16:8
| 500
| 1250
| 1600
| 4
| 8
| 25.6
| DDR2 / GDDR3
| 128
| 10.0
| 3.3
| 120
| 23
| 5.22
|
|-
! style="text-align:left;" | GeForce 9650M GS
| 2008
| NB9P-GS1(G84)
| 80
| PCIe 2.0 x16
| 512
| 32:16:8
| 625
| 1250
| 1600
| 5
| 10
| 25.6
| GDDR3
| 128
| 10.0
| 3.3
| 120
| 29
| 4.14
|Rebranded 8700M GT
|-
! style="text-align:left;" | GeForce 9650M GT
| 2008
| NB9P-GT(G96)
| 65/55
| PCIe 2.0 x16
| 1024
| 32:16:8
| 550
| 1325
| 1600
| 4.4
| 8.8
| 25.6
| GDDR3
| 128
| 10.0
| 3.3
| 127.2
| 23
| 5.53
|
|-
! style="text-align:left;" | GeForce 9700M GT
| July 29, 2008
| NB9E-GE(G96)
| 65
| PCIe x16
| 512
| 32:16:8
| 625
| 1550
| 1600
| 5
| 10
| 25.6
| GDDR3
| 128
| 10.0
| 3.3
| 148.8
| 45
| 3.31
|
|-
! style="text-align:left;" | GeForce 9700M GTS
| July 29, 2008
| NB9E-GS(G94)
| 65
| PCIe 2.0 x16
| 512
| 48:24:16
| 530
| 1325
| 1600
| 8.48
| 12.7
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 190.8
| 60
| 3.18
|
|-
! style="text-align:left;" | GeForce 9800M GS
| 2008
| NB9E-GT(G94)
| 65
| PCIe 2.0 x16
| 512
| 64:32:16
| 530
| 1325
| 1600
| 8.48
| 16.96
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 254
| 60
| 4.23
|Down Clocked 9800M GTS Via Firmware
|-
! style="text-align:left;" | GeForce 9800M GTS
| July 29, 2008
| NB9E-GT(G94)
| 65/55
| PCIe 2.0 x16
| 512 / 1024
| 64:32:16
| 600
| 1500
| 1600
| 9.6
| 19.2
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 288
| 75
| 3.84
|
|-
! style="text-align:left;" | GeForce 9800M GT
| July 29, 2008
| NB9E-GT2(G92)
| 65/55
| PCIe 2.0 x16
| 512
| 96:48:16
| 500
| 1250
| 1600
| 8
| 24
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 360
| 65
| 5.54
|Rebranded 8800M GTX
|-
! style="text-align:left;" | GeForce 9800M GTX
| July 29, 2008
| NB9E-GTX(G92)
| 65
| PCIe 2.0 x16
| 1024
| 112:56:16
| 500
| 1250
| 1600
| 8
| 28
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 420
| 75
| 5.6
|
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! rowspan=2 | GFLOPS (MADD/MUL)
! rowspan=2 | [[Thermal Design Power|TDP]] (Watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Notes
|-
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
|}

===GeForce 100M (1xxM) Series===
The GeForce 100M Series for notebooks architecture. [[Tesla (microarchitecture)]] (103M, 105M, 110M, 130M are rebranded GPU i.e. using the same GPU cores of previous generation, 9M, with promised optimisation on other features)
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power GFLOPS
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce G 102M
| January 8, 2009
| MCP79XT
| 65
| Integrated<br>(PCIe 1.0 x16)
| Up to 512 from system memory
| 16:8:4
| 450?
| 1000
| 800<br>(system memory)
| 1.8
| 3.6
| 6.4
| DDR2
| 64
| 10.0
| 3.3
| 48
| 14
| 3.43
| PureVideo HD, CUDA, Hybrid SLI, based on GeForce 9400M G
|-
! style="text-align:left;" | GeForce G 103M
| January 1, 2009
| N10M-GE2(G98)
| 65
| PCIe 2.0 x16
| 512
| 8:8:4
| 640
| 1600
| 1000
| 2.56
| 5.12
| 8
| DDR2
| 64
| 10.0
| 3.3
| 38
| 14
| 2.71
| PureVideo HD, CUDA, Hybrid SLI, comparable to the GeForce 9300M GS
|-
! style="text-align:left;" | GeForce G 105M
| January 8, 2009
| N10M-GE1(G98)
| 65
| PCIe 2.0 x16
| 512
| 8:8:4
| 640
| 1600
| 1000<br>1400
| 2.56
| 5.12
| 8<br>11
| GDDR2<br>GDDR3
| 64
| 10.0
| 3.3
| 38
| 14
| 2.71
| PureVideo HD, CUDA, Hybrid SLI, comparable to the GeForce 9300M GS
|-
! style="text-align:left;" | GeForce G 110M
| January 8, 2009
| N10M-GE1(G96b)
| 55
| PCIe 2.0 x16
| 1024
| 16:8:4
| 400
| 1000
| 1000<br>1400
| 1.6
| 3.2
| 8<br>11
| DDR2<br>GDDR3
| 64
| 10.0
| 3.3
| 48
| 14
| 3.43
| PureVideo HD, CUDA, Hybrid SLI
|-
! style="text-align:left;" | GeForce GT 120M
| February 11, 2009
| N10P-GV1(G96b)
| 55
| PCIe 2.0 x16
| 1024
| 32:16:8
| 500
| 1250
| 1000
| 4
| 8
| 16
| DDR2
| 128
| 10.0
| 3.3
| 110
| 23
| 4.78
| PureVideo HD, CUDA, Hybrid SLI, Comparable to the 9500M GT and 9600M GT DDR2 (500/1250/400)
|-
! style="text-align:left;" | GeForce GT 130M
| January 8, 2009
| N10P-GE1(G96b)
| 55
| PCIe 2.0 x16
| 1024
| 32:16:8
| 600
| 1500
| 1000<br>1600
| 4.8
| 9.6
| 16<br>25.6
| DDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 144
| 23
| 6.26
| PureVideo HD, CUDA, Hybrid SLI, comparable to the 9650M GT
|-
! style="text-align:left;" | GeForce GTS 150M
| March 3, 2009
| N10E-GE1(G94b)
| 55
| PCIe 2.0 x16
| 1024
| 64:32:16
| 400
| 1000
| 1600
| 6.4
| 12.8
| 51.2
| GDDR3
| 256

| 10.0
| 3.3
| 192
| {{unk}}
| {{unk}}
| PureVideo HD, CUDA, Hybrid SLI
|-
! style="text-align:left;" | GeForce GTS 160M
| March 3, 2009
| N10E-GS1(G94b)
| 55
| PCIe 2.0 x16
| 1024
| 64:32:16
| 600
| 1500
| 1600
| 9.6
| 19.2
| 51.2
| GDDR3
| 256
| 10.0
| 3.3
| 288
| 60
| 4.8
| PureVideo HD, CUDA, Hybrid SLI
|}

===GeForce 200M (2xxM) Series===
The GeForce 200M Series is a graphics processor architecture for notebooks, [[Tesla (microarchitecture)]]
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce G210M
| June 15, 2009
| GT218
| 40
| PCIe 2.0 x16
| 512
| 16:8:4
| 625
| 1500
| 1600
| 2.5
| 5
| 12.8
| GDDR3
| 64
| 10.1
| 3.3
| 72
| 14
| 5.14
| Lower clocked versions of the GT218 core is also known as [[Nvidia Ion|Nvidia ION 2]]
|-
! style="text-align:left;" | GeForce GT 220M
| 2009
| G96b
| 55
| PCIe 2.0 x16
| 1024
| 32:16:8
| 500
| 1250
| 1000<br>1600
| 4
| 8
| 16<br>25.6
| DDR2<br>GDDR3
| 128
| 10.0
| 3.3
| 120
| 14
| 8.57
| rebranded 9600M GT @55&nbsp;nm node shrink
|-
! style="text-align:left;" | GeForce GT 230M
| June 15, 2009
| GT216
| 40
| PCIe 2.0 x16
| 1024
| 48:16:8
| 500
| 1100
| 1600
| 4
| 8
| 25.6
| GDDR3
| 128
| 10.1
| 3.3
| 158
| 23
| 6.87
|
|-
! style="text-align:left;" | GeForce GT 240M
| June 15, 2009
| GT216
| 40
| PCIe 2.0 x16
| 1024
| 48:16:8
| 550
| 1210
| 1600
| 4.4
| 8.8
| 25.6
| GDDR3
| 128
| 10.1
| 3.3
| 174
| 23
| 7.57
|
|-
! style="text-align:left;" | GeForce GTS 250M
| June 15, 2009
| GT215
| 40
| PCIe 2.0 x16
| 1024
| 96:32:8
| 500
| 1250
| 3200
| 4
| 16
| 51.2
| GDDR5
| 128
| 10.1
| 3.3
| 360
| 28
| 12.86
|
|-
! style="text-align:left;" | GeForce GTS 260M
| June 15, 2009
| GT215
| 40
| PCIe 2.0 x16
| 1024
| 96:32:8
| 550
| 1375
| 3600
| 4.4
| 17.6
| 57.6
| GDDR5
| 128
| 10.1
| 3.3
| 396
| 38
| 10.42
|
|-
! style="text-align:left;" | GeForce GTX 260M
| March 3, 2009
| G92b
| 55
| PCIe 2.0 x16
| 1024
| 112:56:16
| 550
| 1375
| 1900
| 8.8
| 30.8
| 60.8
| GDDR3
| 256
| 10.0
| 3.3
| 462
| 65
| 7.11
|
|-
! style="text-align:left;" | GeForce GTX 280M
| March 3, 2009
| G92b
| 55
| PCIe 2.0 x16
| 1024
| 128:64:16
| 585
| 1463
| 1900
| 9.36
| 37.44
| 60.8
| GDDR3
| 256
| 10.0
| 3.3
| 562
| 75
| 7.49
|
|-
! style="text-align:left;" | GeForce GTX 285M
| February, 2010
| G92b
| 55
| PCIe 2.0 x16
| 1024
| 128:64:16
| 600
| 1500
| 2000
| 9.6
| 38.4
| 64.0
| GDDR3
| 256
| 10.0
| 3.3
| 576
| 75
| 7.68
| Higher Clocked Version of GTX280M with new memory
|}

===GeForce 300M (3xxM) Series===
The GeForce 300M Series for notebooks architecture, [[Tesla (microarchitecture)]]
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Each Streaming Multiprocessor(SM) in the chip of G80/GT200 architecture contains 8 SPs and 2 SFUs.  Each SP can fulfill up to two single precision operations MAD per clock. Each SFU can fulfill up to four operations SF per clock (these units can also handle single-precision floating-point multiplications per clock). The approximate ratio of operations MAD to operations SF is equal 2:1. The theoretical SP + SFU performance in single-precision floating point operations [''FLOPS<sub>sp+sfu</sub>'', [[GigaFLOPS|GFLOPS]]] of the graphics card with shader count [''n''] and shader frequency [''f'', GHz], is estimated by the following formula: ''FLOPS<sub>sp+sfu</sub>''  f  n  3. Alternative formula:  ''FLOPS<sub>sp+sfu</sub>''  f  m  ( 8 SPs * 2 (MAD) + 4 * 2 SFUs ). [''m''] - SM count.<ref name="nvidiaanandtechGT200"/><ref name="nvidiaanandtechG80"/>
SP - Shader Processor (Unified Shader, [[CUDA]] Core), SFU - Special Function Unit, SM - Streaming Multiprocessor, MAD - ADD+MUL.

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | GFLOPS/W
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 305M
| January 10, 2010
| GT218
| 40
| PCIe 2.0 x16
| 512
| 16:8:4
| 525
| 1150
| 1400
| 2.1
| 4.2
| 11.2
| DDR3<br>GDDR3
| 64
| 10.1
| 3.3
| 55
| 14
| 3.93
|-
! style="text-align:left;" | GeForce 310M
| January 10, 2010
| GT218
| 40
| PCIe 2.0 x16
| 512
| 16:8:4
| 625
| 1530
| 1600
| 2.5
| 5
| 12.8
| DDR3<br>GDDR3
| 64
| 10.1
| 3.3
| 73
| 14
| 5.21
|-
! style="text-align:left;" | GeForce 315M
| January 5, 2011
| GT218
| 40
| PCIe 2.0 x16
| 512
| 16:8:4
| 606
| 1212
| 1600
| 2.42
| 4.85
| 12.8
| DDR3<br>GDDR3
| 64
| 10.1
| 3.3
| 58.18
| 14
| 4.16
|-
! style="text-align:left;" | GeForce 320M
| April 1, 2010
| MCP89
| 40
| Integrated <br> PCIe 2.0 x16
| dedicated video memory: 256 shared <br>system memory: 1595<ref>[http://www.anandtech.com/show/3762/apples-13inch-macbook-pro-early-2010-reviewed-shaking-the-cpugpu-balance/2 Apple's 13-inch MacBook Pro (Early 2010) Reviewed: Shaking the CPU/GPU Balance]</ref>
| 48:16:8
| 450
| 950
| 1066
| 3.6
| 7.2
| 17.056
| DDR3
| 128
| 10.1
| 3.3
| 136.8
| 20
| 6.84
|-
! style="text-align:left;" | GeForce GT 320M
| January 21, 2010
| GT216
| 40
| PCIe 2.0 x16
| 1024
| 24:8:8
| 500
| 1100
| 1580
| 4
| 4
| 25.3
| DDR3<br>GDDR3
| 128
| 10.1
| 3.3
| 90
| 14
| 6.43
|-
! style="text-align:left;" | GeForce GT 325M
| January 10, 2010
| GT216
| 40
| PCIe 2.0 x16
| 1024
| 48:16:8
| 450
| 990
| 1600
| 3.6
| 7.2
| 25.6
| DDR3<br>GDDR3
| 128
| 10.1
| 3.3
| 142
| 23
| 6.17
|-
! style="text-align:left;" | GeForce GT 330M
| January 10, 2010
| GT216
| 40
| PCIe 2.0 x16
| 1024
| 48:16:8
| 575
| 1265
| 1600
| 4.6
| 9.2
| 25.6
| DDR3<br>GDDR3
| 128
| 10.1
| 3.3
| 182
| 23
| 7.91
|-
! style="text-align:left;" | GeForce GT 335M
| January 7, 2010
| GT215
| 40
| PCIe 2.0 x16
| 1024
| 72:24:8
| 450
| 1080
| 1600
| 3.6
| 10.8
| 25.6
| DDR3<br>GDDR3
| 128
| 10.1
| 3.3
| 233
| 28?
| 8.32?
|-
! style="text-align:left;" | GeForce GTS 350M
| January 7, 2010
| GT215
| 40
| PCIe 2.0 x16
| 1024
| 96:32:8
| 500
| 1249
| 3200
| 4
| 16
| 51.2
| DDR3<br>GDDR3<br>GDDR5
| 128
| 10.1
| 3.3
| 360
| 28
| 12.86
|-
! style="text-align:left;" | GeForce GTS 360M
| January 7, 2010
| GT215
| 40
| PCIe 2.0 x16
| 1024
| 96:32:8
| 550
| 1436
| 3600
| 4.4
| 17.6
| 57.6
| DDR3<br>GDDR3<br>GDDR5
| 128
| 10.1
| 3.3
| 413
| 38
| 10.87
|}

===GeForce 400M (4xxM) Series===
The GeForce 400M Series for notebooks architecture, [[Fermi (microarchitecture)]]

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Each Streaming Multiprocessor(SM) in the GPU of GF100 architecture contains 32 SPs and 4 SFUs. Each Streaming Multiprocessor(SM) in the GPU of GF104/106/108 architecture contains 48 SPs and 8 SFUs. Each SP can fulfill up to two single precision operations FMA per clock. Each SFU can fulfill up to four operations SF per clock. The approximate ratio of operations FMA to operations SF is equal: for GF100 4:1 and for GF104/106/108 3:1. The theoretical shader performance in single-precision floating point operations(FMA) [''FLOPS<sub>sp</sub>'', [[GigaFLOPS|GFLOPS]]] of the graphics card with shader count [''n''] and shader frequency [''f'', GHz], is estimated by the following: ''FLOPS<sub>sp</sub>''  f  n  2. Alternative formula: for GF100 ''FLOPS<sub>sp</sub>''  f  m  (32 SPs  2(FMA)) and for GF104/106/108 ''FLOPS<sub>sp</sub>''  f  m  (48 SPs  2(FMA)). [''m''] - SM count. Total Processing Power: for GF100 ''FLOPS<sub>sp</sub>''  f  m (32 SPs  2(FMA) + 4  4 SFUs) and for GF104/106/108 ''FLOPS<sub>sp</sub>''  f  m  (48 SPs  2(FMA) + 4  8 SFUs) or for GF100 ''FLOPS<sub>sp</sub>''  f  n  2.5 and for GF104/106/108 ''FLOPS<sub>sp</sub>''  f  n  8 / 3.<ref name="nvidiatesla-siliconmadness"/>
SP - Shader Processor (Unified Shader, [[CUDA]] Core), SFU - Special Function Unit, SM - Streaming Multiprocessor, [[Fused multiplyadd|FMA]] - Fused MUL+ADD.
* <sup>3</sup> Each SM in the GF100 also contains 4 texture address units and 16 texture filtering units. Total for the full GF100 64 texture address units and 256 texture filtering units.<ref name="anandtech.com"/> Each SM in the GF104/106/108 architecture contains 8 texture filtering units for every texture address unit. The complete GF104 die contains 64 texture address units and 512 texture filtering units, the complete GF106 die contains 32 texture address units and 256 texture filtering units and the complete GF108 die contains 16 texture address units and 128 texture filtering units.

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 410M
| January 5, 2011
| GF119
| 40
| PCIe 2.0 x16
| 512
| 48:8<sup>3</sup>:4
| 575
| 1150
| 1600
| 2.3
| 4.6
| 12.8
| DDR3
| 64
| 11.0
| 4.5
| 110.4
| 12
|Similar to Desktop GT420 OEM
|-
! style="text-align:left;" | GeForce GT 415M
| September 3, 2010
| GF108
| 40
| PCIe 2.0 x16
| 512
| 48:8<sup>3</sup>:4
| 500
| 1000
| 1600
| 2
| 4
| 25.6
| DDR3
| 128
| 11.0
| 4.5
| 96
| <12(GPU only)<ref name="TDP_400M">[http://www.hardwarecanucks.com/forum/hardware-canucks-reviews/35860-nvidias-geforce-400m-mobile-gpus-7-new-fermis-introduced-3.html 400M-Series TDP: An Explanation & Our Findings]</ref>
|Similar to Desktop GT420 OEM
|-
! style="text-align:left;" | GeForce GT 420M
| September 3, 2010
| GF108
| 40
| PCIe 2.0 x16
| 512
| 96:16<sup>3</sup>:4
| 500
| 1000
| 1600
| 2
| 8
| 25.6
| DDR3
| 128
| 11.0
| 4.5
| 192
| 10-23(GPU only)<ref name="TDP_400M"/>
|Similar to Desktop GT430
|-
! style="text-align:left;" | GeForce GT 425M
| September 3, 2010
| GF108
| 40
| PCIe 2.0 x16
| 1024
| 96:16<sup>3</sup>:4
| 560
| 1120
| 1600
| 2.24
| 8.96
| 25.6
| DDR3
| 128
| 11.0
| 4.5
| 215.04
| 20-23(GPU only)<ref name="TDP_400M"/>
|Similar to Desktop GT430
|-
! style="text-align:left;" | GeForce GT 435M
| September 3, 2010
| GF108
| 40
| PCIe 2.0 x16
| 2048
| 96:16<sup>3</sup>:4
| 650
| 1300
| 1600
| 2.6
| 10.4
| 25.6
| DDR3
| 128
| 11.0
| 4.5
| 249.6
| 32-35(GPU only)<ref name="TDP_400M"/>
|Similar to Desktop GT430/440
|-
! style="text-align:left;" | GeForce GT 445M
| September 3, 2010
| GF106
| 40
| PCIe 2.0 x16
| 1024<br>1536
| 144:24<sup>3</sup>:16<br>144:24<sup>3</sup>:24
| 590
| 1180
| 1600<br>2500
| 9.44<br>14.16
| 14.16
| 25.6<br>60
| DDR3<br>GDDR5
| 128<br>192
| 11.0
| 4.5
| 339.84
| 30-35(GPU only)<ref name="TDP_400M"/>
|Similar to Desktop GTS450 OEM)
|-
! style="text-align:left;" | GeForce GTX 460M
| September 3, 2010
| GF106
| 40
| PCIe 2.0 x16
| 1536
| 192:32<sup>3</sup>:24
| 675
| 1350
| 2500
| 16.2
| 21.6
| 60
| GDDR5
| 192
| 11.0
| 4.5
| 518.4
| 45-50(GPU only)<ref name="TDP_400M"/>
|Similar to Desktop GTX550 Ti
|-
! style="text-align:left;" | GeForce GTX 470M
| September 3, 2010
| GF104
| 40
| PCIe 2.0 x16
| 1536
| 288:48<sup>3</sup>:24
| 550
| 1100
| 2500
| 13.2
| 26.4
| 60
| GDDR5
| 256
| 11.0
| 4.5
| 633.6
| 45-50(GPU only)<ref name="TDP_400M"/>
|Similar to Desktop GTX 460/560SE
|-
! style="text-align:left;" | GeForce GTX 480M
| May 25, 2010
| GF100
| 40
| PCIe 2.0 x16
| 2048
| 352:44<sup>3</sup>:32
| 425
| 850
| 2400
| 13.6
| 18.7
| 76.8
| GDDR5
| 256
| 11.0
| 4.5
| 598.4
| 100(MXM module)
|Similar to Desktop GTX465
|-
! style="text-align:left;" | GeForce GTX 485M
| January 5, 2011
| GF104
| 40
| PCIe 2.0 x16
| 2048
| 384:64<sup>3</sup>:32
| 575
| 1150
| 3000
| 18.4
| 36.8
| 96.0
| GDDR5
| 256
| 11.0
| 4.5
| 883.2
| 100(MXM module)
|Similar to Desktop GTX560 Ti
|}

===GeForce 500M (5xxM) Series===
The GeForce 500M Series for notebooks architecture.

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Hertz|MHz]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce GT 520M
| January 5, 2011
| GF119
| 40
| PCIe 2.0 x16
| 1024
| 48:8:4
| 740
| 1480
| 1600
| 2.96
| 5.92
| 12.8
| DDR3
| 64
| 11.0
| 4.5
| 142.08
| 12
|Similar to Desktop 510/520
|-
! style="text-align:left;" | GeForce GT 520M
| 
| GF108
| 40
| PCIe 2.0 x16
| 1024
| 96:16:4
| 515
| 1030
| 1600
| 2.06
| 8.24
| 12.8
| DDR3
| 64
| 11.0
| 4.5
| 197.76
| 20
| Noticed in [[Lenovo]] laptops, similar to Desktop 530/430/440
|-
! style="text-align:left;" | GeForce GT 520MX
| May 30, 2011
| GF119
| 40
| PCIe 2.0 x16
| 1024
| 48:8:4
| 900
| 1800
| 1800
| 3.6
| 7.2
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 172.8
| 20
|Similar to Desktop 510 & GT520
|-
! style="text-align:left;" | GeForce GT 525M
| January 5, 2011
| GF108
| 40
| PCIe 2.0 x16
| 1024
| 96:16:4
| 600
| 1200
| 1800
| 2.4
| 9.6
| 28.8
| DDR3
| 128
| 11.0
| 4.5
| 230.4
| 20-23
|Similar to Desktop GT 530/430/440
|-
! style="text-align:left;" | GeForce GT 540M
| January 5, 2011
| GF108
| 40
| PCIe 2.0 x16
| 2048<br>1024
| 96:16:4
| 672
| 1344
| 1800
| 2.688
| 10.752
| 28.8
| DDR3
| 128
| 11.0
| 4.5
| 258.048
| 32-35
|Similar to Desktop GT 530/440
|-
! style="text-align:left;" | GeForce GT 550M
| January 5, 2011
| GF108
| 40
| PCIe 2.0 x16
| 1024
| 96:16:4
| 740
| 1480
| 1800
| 2.96
| 11.84
| 28.8
| DDR3
| 128
| 11.0
| 4.5
| 284.16
| 32-35
|Similar to Desktop GT 530/440
|-
! style="text-align:left;" | GeForce GT 555M
| January 5, 2011
| GF106<br><br>GF108
| 40
| PCIe 2.0 x16
| 1536<br>2048<br>1024
| 144:24:24<br>144:24:16<br>96:16:4
| 590<br>650<br>753
| 1180<br>1300<br>1506
| 1800<br>1800<br>3138
| 14.6<br>10.4<br>3
| 14.6<br>15.6<br>12
| 43.2<br>28.8<br>50.2
| DDR3<br>DDR3<br>GDDR5
| 192<br>128<br>128
| 11.0
| 4.5
| 339.84<br>374.4<br>289.15
| 30-35
|Similar to Desktop GT545
|-
! style="text-align:left;" | GeForce GTX 560M
| May 30, 2011
| GF116
| 40
| PCIe 2.0 x16
| 2048<br>1536, 3072
| 192:32:16<br>192:32:24
| 775
| 1550
| 2500
| 18.6
| 24.8
| 40.0<br>60.0
| GDDR5
| 128<br>192
| 11.0
| 4.5
| 595.2
| 75
|Similar to Desktop GTX 550Ti
|-
! style="text-align:left;" | GeForce GTX 570M<ref>http://www.geforce.com/#/Hardware/GPUs/geforce-gtx-570m/specifications</ref>
| June 28, 2011
| GF114
| 40
| PCIe 2.0 x16
| 1536
| 336:56:24
| 575
| 1150
| 3000
| 13.8
| 32.2
| 72.0
| GDDR5
| 192
| 11.0
| 4.5
| 772.8
| 75
|Similar to Desktop GTX 560
|-
! style="text-align:left;" | GeForce GTX 580M
| June 28, 2011
| GF114
| 40
| PCIe 2.0 x16
| 2048
| 384:64:32
| 620
| 1240
| 3000
| 19.8
| 39.7
| 96.0
| GDDR5
| 256
| 11.0
| 4.5
| 952.3
| 100
|Similar to Desktop GTX 560 Ti
|}

===GeForce 600M (6xxM) Series===
{{Main|GeForce 600 Series }}
The GeForce 600M Series for notebooks architecture. The processing power is obtained by multiplying shader clock speed, the number of cores and how many instructions the cores are capable of performing per cycle.

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 610M <ref>[http://www.nvidia.in/object/geforce-610m-in.html#pdpContent=2 GeForce 610M Graphics Card with Optimus technology | NVIDIA<!-- Bot generated title -->]</ref>
| Dec 2011
| GF119 (N13M-GE)
| 40
| PCIe 2.0 x16
| 1024<br>2048
| 48:8:4
| 900
| 1800
| 1800
| 3.6
| 7.2
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 142.08
| 12
| OEM. Rebadged GT 520MX
|-
! style="text-align:left;" | GeForce GT 620M <ref name="ReferenceA">[http://www.anandtech.com/show/5697/nvidias-geforce-600m-Series-keplers-and-fermis-and-die-shrinks-oh-my/2 AnandTech | NVIDIA's GeForce 600M Series: Mobile Kepler and Fermi Die Shrinks<!-- Bot generated title -->]</ref>
| Apr 2012
| GF117 (N13M-GS)
| 28
| PCIe 2.0 x16
| 1024<br>2048
| 96:16:4
| 625
| 1250
| 1800
| 2.5
| 10
| 14.4<br>28.8
| DDR3
| 64<br>128
| 11.0
| 4.5
| 240
| 15
| OEM. Die-Shrink GF108
|-
! style="text-align:left;" | GeForce GT 625M
| October 2012
| GF117 (N13M-GS)
| 28
| PCIe 2.0 x16
| 1024<br>2048
| 96:16:4
| 625
| 1250
| 1800
| 2.5
| 10
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 240
| 15
| OEM. Die-Shrink GF108
|-
! style="text-align:left;" | GeForce GT 630M<ref name="ReferenceA"/><ref>[http://www.nvidia.in/object/geforce-gt-630m-in.html#pdpContent=2 GeForce GT 630M Graphics Card with Optimus technology | NVIDIA<!-- Bot generated title -->]</ref><ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-gt-630m/specifications GeForce GT 630M | Specifications | GeForce<!-- Bot generated title -->]</ref>
| Apr 2012
| GF108 (N13P-GL)<br>GF117
| 40<br>28
| PCIe 2.0 x16
| 1024<br>2048
| 96:16:4
| 660<br>800
| 1320<br>1600
| 1800<br>4000
| 2.6<br>3.2
| 10.7<br>12.8
| 28.8<br>32.0
| DDR3<br>GDDR5
| 128<br>64
| 11.0
| 4.5
| 258.0<br>307.2
| 33
| GF108: OEM. Rebadged GT 540M<br>GF117: OEM Die-Shrink GF108
|-
! style="text-align:left;" | GeForce GT 635M<ref name="ReferenceA"/><ref>[http://www.nvidia.in/object/geforce-gt-635m-in.html#pdpContent=2 GeForce GT 635M GPU with NVIDIA Optimus technology | NVIDIA<!-- Bot generated title -->]</ref><ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-gt-635m/specifications GeForce GT 635M | Specifications | GeForce<!-- Bot generated title -->]</ref>
| Apr 2012
| GF106 (N12E-GE2)<br>GF116
| 40
| PCIe 2.0 x16
| 2048<br>1536
| 144:24:24
| 675
| 1350
| 1800
| 16.2
| 16.2
| 28.8<br>43.2
| DDR3
| 128<br>192
| 11.0
| 4.5
| 289.2<br>388.8
| 35
| GF106: OEM. Rebadged GT 555M<br>GF116: 94% of desktop GT640
|-
! style="text-align:left;" | GeForce GT 640M LE<ref name="ReferenceA"/>
| March 22, 2012
| GF108<br>GK107 (N13P-LP)
| 40<br>28
| PCIe 2.0 x16<br>PCIe 3.0 x16
| 1024<br>2048
| 96:16:4<br><br>384:32:16<br>(2 SMX)
| 762<br>500
| 1524<br>500
| 3130<br>1800
| 3<br>8
| 12.2<br>16
| 50.2<br>28.8
| GDDR5<br>DDR3
| 128
| 11.0
| 4.5
| 292.6<br>384
| 32<br>20
| GF108: 94% of desktop GT630<br>GK107: 47% of desktop GTX650 
|-
! style="text-align:left;" | GeForce GT 640M<ref name="ReferenceA"/><ref>[http://www.anandtech.com/show/5672/acer-aspire-timelineu-m3-life-on-the-kepler-verge AnandTech | Acer Aspire TimelineU M3: Life on the Kepler Verge<!-- Bot generated title -->]</ref>
| March 22, 2012
| GK107 (N13P-GS)
| 28
| PCIe 3.0 x16
| 1024<br>2048
| 384:32:16<br>(2 SMX)
| 625
| 625
| 1800<br>4000
| 10
| 20
| 28.8<br>64.0
| DDR3<br>GDDR5
| 128
| 11.0
| 4.5
| 480
| 32
| 59% of desktop GTX650
|-
! style="text-align:left;" | GeForce GT 645M
| October 2012
| GK107 (N13P-GS)
| 28
| PCIe 3.0 x16
| 1024<br>2048
| 384:32:16<br>(2 SMX)
| 710
| 710
| 1800<br>4000
| 11.36
| 22.72
| 28.8<br>64.0
| DDR3<br>GDDR5
| 128
| 11.0
| 4.5
| 545
| 32
| 67% of desktop GTX650
|-
! style="text-align:left;" | GeForce GT 650M<ref name="ReferenceA"/><ref>[http://www.laptopreviews.com/hp-lists-new-ivy-bridge-2012-mosaic-design-laptops-available-april-8th-2012-03 HP Lists New Ivy Bridge 2012 Mosaic Design Laptops, Available April 8thLaptop User Reviews<!-- Bot generated title -->]</ref><ref name="ReferenceB">[http://content.dell.com/us/en/home/d/help-me-choose/hmc-aw-video-card-laptops Help Me Choose | Dell<!-- Bot generated title -->]</ref>
| March 22, 2012 
| GK107 (N13P-GT)
| 28
| PCIe 3.0 x16
| 1024<br>2048
| 384:32:16<br>(2 SMX)
| 835<br>745<br>900*
| 835<br>745<br>900*
| 1800<br>4000<br>5000*
| 13.4<br>11.9<br>14.4*
| 26.7<br>23.8<br>28.8*
| 28.8<br>64.0<br>80.0*
| DDR3<br>GDDR5
| 128
| 11.2
| 4.5
| 641.3<br>572.2<br>691.2*
| 45
| 79% of desktop GTX650<br>*
|-
! style="text-align:left;" | GeForce GTX 660M<ref name="ReferenceA"/><ref name="ReferenceB"/><ref>[http://www.engadget.com/2012/01/08/lenovo-ideapad-laptops-CES-2012/ Lenovo unveils six mainstream consumer laptops (and one desktop replacement)<!-- Bot generated title -->]</ref><ref>[http://forum.notebookreview.com/asus-reviews-owners-lounges/659534-asus-g75vw-ivy-bridge-660m-review-owners-lounge-4.html 660m power draw tested in Asus G75VW]</ref>
| March 22, 2012
| GK107 (N13E-GE)
| 28
| PCIe 3.0 x16
| 2048
| 384:32:16<br>(2 SMX)
| 950
| 950
| 5000
| 13.4
| 26.7
| 80.0
| GDDR5
| 128
| 11.2
| 4.5
| 730
| 50
| 79% of desktop GTX650<br>
|-
! style="text-align:left;" | GeForce GTX 670M<ref name="ReferenceA"/>
| April 2012
| GF114 (N13E-GS1-LP)
| 40
| PCIe 2.0 x16
| 1536<br>3072
| 336:56:24
| 620
| 1240
| 3000
| 14.35
| 33.5
| 72.0
| GDDR5
| 192
| 11.0
| 4.5
| 833
| 75
| 73% of desktop GTX 560
|-
! style="text-align:left;" | GeForce GTX 670MX
| October 2012
| GK104 (N13E-GR)
| 28
| PCIe 3.0 x16
| 1536<br>3072
| 960:80:24<br>(5 SMX)
| 615
| 615
| 2800
| 14.4
| 48.0
| 67.2
| GDDR5
| 192
| 11.0
| 4.5
| 1181
| 75
| 61% of desktop GTX 660
|-
! style="text-align:left;" | GeForce GTX 675M<ref name="ReferenceA"/>
| April 2012
| GF114 (N13E-GS1)
| 40
| PCIe 2.0 x16
| 2048
| 384:64:32
| 632
| 1265
| 3000
| 19.8
| 39.7
| 96.0
| GDDR5
| 256
| 11.0
| 4.5
| 972
| 100
| 75% of desktop GTX 560Ti
|-
! style="text-align:left;" | GeForce GTX 675MX
| October 2012
| GK104  (N13E-GSR)
| 28
| PCIe 3.0 x16
| 4096
| 1344:112:32<br>(7 SMX)
| 667
| 667
| 3600
| 19.2
| 48.0
| 115.2
| GDDR5
| 256
| 11.0
| 4.5
| 1793
| 100
| 61% of desktop GTX 660
|-
! style="text-align:left;" | GeForce GTX 680M
| June 4, 2012
| GK104 (N13E-GTX)
| 28
| PCIe 3.0 x16
| 4096
| 1344:112:32<br>(7 SMX)
| 719
| 719
| 3600
| 23
| 80.6
| 115.2
| GDDR5
| 256
| 11.0
| 4.5
| 1933
| 100
| 78% of desktop GTX 670
|-
! style="text-align:left;" | GeForce GTX 680MX
| October 23, 2012
| GK104
| 28
| PCIe 3.0 x16
| 4096
| 1536:128:32<br>(8 SMX)
| 719
| 719
| 5000
| 23
| 92.2
| 160
| GDDR5
| 256
| 11.0
| 4.5
| 2209
| 122
| 72% of desktop GTX 680
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
|}

===GeForce 700M (7xxM) Series===
{{Main|GeForce 700 Series }}
The GeForce 700M Series for notebooks architecture. The processing power is obtained by multiplying shader clock speed, the number of cores and how many instructions the cores are capable of performing per cycle.

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 710M
| Jan 2013
| GF117
| 28
| PCIe 2.0 x16
| 1024<br>2048
| 96:16:4
| 800
| 1600
| 1800
| 3.2
| 12.8
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 307.2
| 12
| OEM. About 115% of Mobile 620 & Desktop 530
|-
! style="text-align:left;" | GeForce GT 720M
| April 1, 2013
| GF117
| 28
| PCIe 2.0 x16
| 2048
| 96:16:4
| 938
| 1876
| 2000
| 3.8
| 15.0
| 16.0
| DDR3
| 64
| 11.0
| 4.5
| 360.19
| ?
| OEM. About 130% of Mobile 625/630 & Desktop 620
|-
! style="text-align:left;" | GeForce GT 730M
| Jan 2013
| GK208
| 28
| PCIe 3.0 x8
| 2048
| 384:32:8<br>(2 SMX)
| 719
| 719
| 2000
| 5.8
| 23.0
| 16.0
| DDR3
| 128
| 11.0
| 4.5
| 552.2
| 33
| Kepler, similar to Desktop GT640
|-
! style="text-align:left;" | GeForce GT 735M
| April 1, 2013
| GK208
| 28
| PCIe 3.0 x8
| 2048
| 384:32:8<br>(2 SMX)
| 889
| 889
| 2000
| 7.11
| 28.4
| 16.0
| DDR3
| 64
| 11.0
| 4.5
| 682.8 
| ?
| Kepler, similar to Desktop GT640
|-
! style="text-align:left;" | GeForce GT 740M
| April 1, 2013
| GK208
| 28
| PCIe 3.0 x8
| 2048
| 384:32:8<br>(2 SMX)
| 980
| 980
| 1800
| 7.84
| 31.4
| 14.4
| DDR3
| 64
| 11.0
| 4.5
| 752.6
| ?
| Similar or slightly slower than GK 107.
|-
! style="text-align:left;" | GeForce GT 740M
| April 1, 2013
| GK107
| 28
| PCIe 3.0 x16
| 2048<ref name="740M Notebookcheck">{{cite web|title=http://www.notebookcheck.net/NVIDIA-GeForce-GT-740M.89900.0.html|url=http://www.notebookcheck.net/NVIDIA-GeForce-GT-740M.89900.0.html|accessdate=15 April 2013}}</ref>
| 384:32:16<br>(2 SMX)
| 810<ref name="740M Notebookcheck" /> 
| 810<ref name="740M Notebookcheck" /> 
| 1800<br>5000
| 12.96
| 25.92
| 28.8<br>80
| DDR3/GDDR5<ref name="740M Notebookcheck" /> 
| 128
| 11.0
| 4.5
| 622.1
| 45
| about 76% of Desktop GTX650
|-
! style="text-align:left;" | GeForce GT 745M
| April 1, 2013
| GK107
| 28
| PCIe 3.0 x16
| 2048
| 384:32:16<br>(2 SMX)
| 837 
| 837
| 2000<br>5000
| 13.4
| 26.8
| 32<br>80
| DDR3/GDDR5
| 128
| 11.0
| 4.5
| 642.8
| 45
| about 79% of Desktop GTX650
|-
! style="text-align:left;" | GeForce GT 750M
| April 1, 2013
| GK107
| 28
| PCIe 3.0 x16
| 2048
| 384:32:16<br>(2 SMX)
| 967
| 967
| 2000<br>5000
| 15.5
| 30.9
| 32<br>80
| DDR3/GDDR5
| 128
| 11.0
| 4.5
| 742.7
| 50
| about 91% of Desktop GTX650
|-
! style="text-align:left;" | GeForce GT 755M <ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-gt-755m/specifications GeForce GT 755M | Specifications | GeForce<!-- Bot generated title -->]</ref>
| ?
| GK107
| 28
| PCIe 3.0 x16
| 2048
| 384:32:16<br>(2 SMX)
| 1020
| 1020
| 5400
| 15.7
| 31.4
| 86.4
| GDDR5
| 128
| 11.0
| 4.5
| 783
| 50
| about 93% of Desktop GTX650
|-
! style="text-align:left;" | GeForce GTX 760M
| May 2013
| GK106
| 28
| PCIe 3.0 x16
| 2048
| 768:64:16<br>(4 SMX)
| 719
| 719
| 4000
| 10.5
| 42.1
| 64
| GDDR5
| 128
| 11.0
| 4.5
| 1104
| 55
| about 71% of Desktop GTX 650Ti
|-
! style="text-align:left;" | GeForce GTX 765M
| May 2013
| GK106
| 28
| PCIe 3.0 x16
| 2048
| 768:64:16<br>(4 SMX)
| 863
| 863
| 4000
| 13.6
| 54.4
| 64
| GDDR5
| 128
| 11.0
| 4.5
| 1326
| 65
| about 92% of Desktop GTX 650Ti
|-
! style="text-align:left;" | GeForce GTX 770M
| May 2013
| GK106
| 28
| PCIe 3.0 x16
| 3072
| 960:80:24<br>(5 SMX)
| 797
| 797
| 4000
| 19.5
| 64.9
| 96
| GDDR5
| 192
| 11.0
| 4.5
| 1530
| 75
| about 83% of Desktop GTX660
|-
! style="text-align:left;" | GeForce GTX 780M
| May 2013
| GK104
| 28
| PCIe 3.0 x16
| 4096
| 1536:128:32<br>(8 SMX)
| 797
| 797
| 5000
| 26.3
| 105.3
| 160
| GDDR5
| 256
| 11.0
| 4.5
| 2448
| 122
| about 78% of Desktop GTX770
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
|}

===GeForce 800M (8xxM) Series===
{{Main|GeForce 800M series}}
The GeForce 800M Series for notebooks architecture. The processing power is obtained by multiplying shader clock speed, the number of cores and how many instructions the cores are capable of performing per cycle.

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Gigabyte|GB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
! style="text-align:left;" | GeForce 810M
| February 2014
| GF117
| 28
| PCIe 2.0 x16
| 1
| 48:8:4
| 738-888
| 1476-1776
| 1800
| 2.95-3.55
| 5.9-7.1
| 14.4
| DDR3
| 64
| 12.0
| 4.5
| 141.7-170.5
| 15
| 
|-
! style="text-align:left;" | GeForce 820M <ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-820m/specifications GeForce 820M | Specifications | GeForce]</ref>
| February 2014
| GF117
| 28
| PCIe 2.0 x16
| 2
| 96:16:4
| 719-954
| 1438-1908
| 2000
| 2.9-3.8
| 11.5-15.3
| 16
| DDR3
| 64
| 12.0
| 4.5
| 276.1-366.3
| 15<ref>http://www.techpowerup.com/gpudb/2524/geforce-820m.html</ref>
| 115% of 620 (Fermi)
|-
! style="text-align:left;" | GeForce 825M <ref>http://www.notebookcheck.net/NVIDIA-GeForce-825M.110063.0.html</ref>
| January 27, 2014
| GK208
| 28
| PCIe 3.0 x8
| 2
| 384:16:8<br>(2 SMX)
| 850
| 850
| 1800
| 6.8
| 13.6
| 14.4
| DDR3
| 64
| 12.0
| 4.5
| 652.8
| 33
| 94% of 630 (Kepler)
|-
! style="text-align:left;" | GeForce 830M <ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-830m/specifications GeForce 830M | Specifications | GeForce]</ref>
| March 12, 2014
| GM108
| 28
| PCIe 3.0 x16
| 2
| 256:16:8<br>(2 SMM)
| 1029
| 1029
| 1800
| 8.2
| 16.5
| 14.4
| DDR3
| 64
| 12.0
| 4.5
| 526.8
| ~25
|50% of 750 (Maxwell)
|-
! style="text-align:left;" | GeForce 840M <ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-840m/specifications GeForce 840M | Specifications | GeForce]</ref>
| March 12, 2014
| GM108
| 28
| PCIe 3.0 x16
| 2
| 384:24:8<br>(3 SMM)
| 1029
| 1029
| 2000
| 8.2
| 24.7
| 16
| DDR3
| 64
| 12.0
| 4.5
| 790.3
| 30
| 50-80% of 745 (Maxwell)
|-
! style="text-align:left;" | GeForce 845M <ref>[http://www.asus.com/Notebooks_Ultrabooks/N551JQ/ N551JQ | Specifications | Asus]</ref>
| 
| 
| 
| PCIe 3.0 x16
| 
| 
| 
| 
| 
| 
| 
| 16
| DDR3
| 64
| 
| 
| 
| 
| 
|-
! rowspan=2  style="text-align:left;" | GeForce GTX 850M <ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-gtx-850m/specifications GeForce GTX 850M | Specifications | GeForce]</ref>
| rowspan=2 | March 12, 2014
| rowspan=2 | GM107
| rowspan=2 | 28
| rowspan=2 | PCIe 3.0 x16
| rowspan=2 | 2
| rowspan=2 | 640:40:16<br>(5 SMM)
| 876+Boost
| 876+Boost
| 5000
| 14.0
| 35.0
| 80
| GDDR5
| rowspan=2 | 128
| rowspan=2 | 12.0
| rowspan=2 | 4.5
| 1121.3
| rowspan=2 | 40
| 85% of 750Ti
|-
| 936+Boost
| 936+Boost
| 2000
| 15.0
| 37.4
| 32
| DDR3
| 1198.1
| 80% of 750Ti
|-
! rowspan=2 style="text-align:left;" | GeForce GTX 860M <ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-gtx-860m/specifications GeForce GTX 860M | Specifications | GeForce]</ref>
| rowspan=2 | March 12, 2014
| GM107
| rowspan=2 | 28
| rowspan=2 | PCIe 3.0 x16
| 2
| 640:40:16<br>(5 SMM)
| 1020-1085
| 1020-1085
| rowspan=2 | 5000
| 16.5
| 41.2
| rowspan=2 | 80
| rowspan=2 | GDDR5
| rowspan=2 | 128
| 12.0
| rowspan=2 | 4.5
| 1389
| 40-45
| equal to 750Ti
|- 
| GK104
| 4
| 1152:96:16<br>(6 SMX)
| 797-915
| 797-915
| 12.8
| 76.5
| 12.0
| 2108
| 75
| similar to 660 OEM.
|-
! style="text-align:left;" | GeForce GTX 870M <ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-gtx-870m/specifications GeForce GTX 870M | Specifications | GeForce]</ref>
| March 12, 2014
| GK104
| 28
| PCIe 3.0 x16
| 3<br>6
| 1344:112:24<br>(7 SMX)
| 941-967
| 941-967
| 5000
| 22.6
| 105.4
| 120
| GDDR5
| 192
| 12.0
| 4.5
| 2599
| 110
| 105% of 660Ti
|-
! style="text-align:left;" | GeForce GTX 880M <ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-gtx-880m/specifications GeForce GTX 880M | Specifications | GeForce]</ref>
| March 12, 2014
| GK104
| 28
| PCIe 3.0 x16
| 4<br>8
| 1536:128:32<br>(8 SMX)
| 954-993
| 954-993
| 5000
| 30.5
| 122.1
| 160
| GDDR5
| 256
| 12.0
| 4.5
| 3104
| 130
| 90% of 770
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Gigabyte|GB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Core ([[Hertz|MHz]])
! Shader ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
|-
|}

===GeForce 900M (9xxM) Series===
{{Main|GeForce 900 series}}
The GeForce 900M Series for notebooks architecture. The processing power is obtained by multiplying shader clock speed, the number of cores and how many instructions the cores are capable of performing per cycle.

* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Gigabyte|GB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Min ([[Hertz|MHz]])
! Average ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]
|-
! style="text-align:left;" | GeForce 920M
| March 12, 2015
| GK208
| 28
| PCIe 3.0 x16
| 2
| 384:32:8<br>(2 SMX)
| 575
| {{unk}}
| 1800
| 4.6
| 18.4
| 14.4
| DDR3
| 64
| 12.0
| 4.5
| 1.1/1.2
| 441
| {{unk}}
| 
|-
! style="text-align:left;" | GeForce 930M
| March 12, 2015
| GM108
| 28
| PCIe 3.0 x16
| 2
| 256:16:8<br>(2 SMM)
| 1029
| 1150
| 1800
| 8.2
| 16.5
| 14.4
| DDR3
| 64
| 12.0
| 4.5
| 1.2
| 527
| {{unk}}
| 
|-
! style="text-align:left;" | GeForce 940M
| March 12, 2015
| GM108
| 28
| PCIe 3.0 x16
| 2
| 384:24:8<br>(3 SMM)
| 1072
| 1176
| 2000
| 8.6
| 25.7
| 16
| DDR3
| 64
| 12.0
| 4.5
| 1.2
| 823
| {{unk}}
| 
|-
! rowspan="2" style="text-align:left;" | GeForce GTX 950M
| rowspan="2" | March 12, 2015
| rowspan="2" | GM107
| rowspan="2" | 28
| rowspan="2" | PCIe 3.0 x16
| rowspan="2" | 2, 4
| rowspan="2" | 640:40:16<br>(5 SMM)
| rowspan="2" | 914
| rowspan="2" {{unk}}
| 5000
| rowspan="2" | 14.6
| rowspan="2" | 36.6
| 80
| GDDR5
| rowspan="2" | 128
| rowspan="2" | 12.0
| rowspan="2" | 4.5
| rowspan="2" | 1.2
| rowspan="2" | 1170
| rowspan="2" {{unk}}
| rowspan="2" | similar to Desktop 750{{OR|date=April 2015}}
|-
| 2000
| 32
| DDR3
|-
! style="text-align:left;" | GeForce GTX 960M
| March 12, 2015
| GM107
| 28
| PCIe 3.0 x16
| 2, 4
| 640:40:16<br>(5 SMM)
| 1096
| {{unk}}
| 5000
| 17.5
| 43.8
| 80
| GDDR5
| 128
| 12.0
| 4.5
| 1.2
| 1403
| {{unk}}
| 105% of Desktop 750Ti{{OR|date=April 2015}}
|-
! style="text-align:left;" | GeForce GTX 965M <ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-gtx-965m | Specifications | GeForce]</ref>
| January 5, 2015
| GM204
| 28
| PCIe 3.0 x16
| 2, 4
| 1024:64:32<br>(8 SMM)
| 944
| {{unk}}
| 5000
| 30.2
| 60.4
| 80
| GDDR5
| 128
| 12.0
| 4.5
| 1.2
| 1933
| {{unk}}
| 85% of GTX960{{OR|date=April 2015}}
|-
! style="text-align:left;" | GeForce GTX 970M <ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-gtx-970m/specifications GeForce GTX 970M | Specifications | GeForce]</ref>
| October 7, 2014
| GM204
| 28
| PCIe 3.0 x16
| 3, 6
| 1280:80:48<br>(10 SMM)
| 924
| 993
| 5000
| 44.4
| 73.9
| 120
| GDDR5
| 192
| 12.0
| 4.5
| 1.2
| 2365
| 75
| 80% of GTX 970{{OR|date=April 2015}}
|-
! style="text-align:left;" | GeForce GTX 980M <ref>[http://www.geforce.com/hardware/notebook-gpus/geforce-gtx-980m/specifications GeForce GTX 980M | Specifications | GeForce]</ref>
| October 7, 2014
| GM204
| 28
| PCIe 3.0 x16
| 4, 8
| 1536:96:64<br>(12 SMM)
| 1038
| 1127
| 5000
| 66.4
| 99.6
| 160
| GDDR5
| 256
| 12.0
| 4.5
| 1.2
| 3189
| 100
| 80% of GTX 980{{OR|date=April 2015}}
|-
! rowspan=2 | Model
! rowspan=2 | Launch
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Gigabyte|GB]])
! rowspan=2 | Core config<sup>1</sup>
! colspan=3 style="text-align:center;" | Clock speed
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=3 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | Processing Power<sup>2</sup><br> (GFLOPS)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Min ([[Hertz|MHz]])
! Average ([[Hertz|MHz]])
! Memory ([[Transfer (computing)|MT/s]])
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[DirectX]]
! [[OpenGL]]
! [[OpenCL]]
|-
|}

==Comparison table: Workstation GPUs==

===Quadro===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing power<br>GFLOPS<ref name="NVcomp1">http://www.nvidia.com/content/PDF/product-comparison/Quadro-Product-Comparison.pdf</ref><ref name="NVcomp2">[http://hgpu.org/?cat=92 Quadro FX Series | hgpu.org<!-- Bot generated title -->]</ref>
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro
|NV10GL
|220
|AGP 4x
|64
|135
|135
|166
|0:4:4:4
|0.54
|0.54
|2.66
|SDR
|128
|
|
|7
|1.2
|
|
|-
!Quadro2 MXR
|NV11GL
|180
|AGP 4x
|64
|175
|175
|183
|0:2:4:4
|0.7
|0.7
||2.93
|SDR
|128
|
|
|7
|1.2
|
|
|-
!Quadro2 EX
|NV11GL
|180
|AGP 4x
|64
|175
|175
|166
|0:2:4:4
|0.7
|0.7
|2.7
|SDR
|128
|
|
|7
|1.2
|
|
|-
!Quadro2 PRO
|NV15GL
|150
|AGP 4x
|64
|250
|250
|400
|0:4:8:8
|2
|2
|6.4
|DDR
|128
|
|
|7
|1.2
|
|
|-
!Quadro DCC
||NV20GL
|180
|AGP 4x
|128
|200
|200
|460
|1:4:8:8
|1.6
|1.6
|7.4
|DDR
|128
|
|
|8
|1.4
|
|
|-
!Quadro4 380XGL
|NV18GL
|150
|AGP 8x
|128
|275
|275
|513
|0:2:4:4
|1.1
|1.1
|8.2
|DDR
|128
|
|
|7
|1.4
|
|
|-
!Quadro4 500XGL
|NV17GL
|150
|AGP 4x
|128
|250
|250
|166
|0:2:4:4
|1
|1
|2.7
|SDR
|128
|
|
|7
|1.4
|
|
|-
!Quadro4 550XGL
|NV17GL
|150
|AGP 4x
|64
|270
|270
|400
|0:2:4:4
|1.08
|1.08
|6.4
|DDR
|128
|
|
|7
|1.4
|
|
|-
!Quadro4 580XGL
|NV18GL
|150
|AGP 8x
|64
|300
|300
|400
|0:2:4:4
|1.2
|1.2
|6.4
|DDR
|128
|
|
|7
|1.4
|
|
|-
!Quadro4 700XGL
|NV25
|150
|AGP 4x
|64
|275
|275
|550
|2:4:8:8
|2.2
|2.2
|8.8
|DDR
|128
|
|
|8
|1.4
|
|
|-
!Quadro4 750XGL
|NV25
|150
|AGP 4x
|128
|275
|275
|550
|2:4:8:8
|2.2
|2.2
|8.8
|DDR
|128
|
|
|8
|1.5
|
|Stereo Display
|-
!Quadro4 900XGL
|NV25
|150
|AGP 4x
|128
|300
|300
|650
|2:4:8:8
|2.4
|2.4
|10.4
|DDR
|128
|
|
|8
|1.4
|
|Stereo Display
|-
!Quadro4 980XGL
|NV28GL
|150
|AGP 8x
|128
|300
|300
|650
|2:4:8:8
|2.4
|2.4
|10.4
|DDR
|128
|
|
|8
|1.4
|
|Stereo Display
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
! rowspan=2 | TDP (Watts)
! rowspan=2 | Features
|-
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | API support (version)
|}

===Quadro FX Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>*</sup> NV31, NV34 and NV36 are 2x2 pipeline designs if running vertex shader, otherwise they are 4x1 pipeline designs.
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1*</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 500
|NV34GL
|150
|AGP 8x
|128
|270
|270
|480
|1:2:2:2<br>*:4:4:4
|1.08
|1.08
|7.687
|DDR
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 600
|NV34GL
|150
|PCI
|256
|350
|350
|800
|1:2:2:2<br>*:4:4:4
|1
|1
|7.8
|DDR
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 700
|NV35GL
|150
|AGP 8x
|128
|275
|275
|275
|1:2:2:2<br>*:4:4:4
|1.1
|1.1
|4.4
|DDR
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 1000
|NV30GL
|130
|AGP 8x
|128
|300
|300
|300
|2:4:8:8
|2.4
|2.4
|9.6
|DDR2
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 1100
|NV36GL
|130
|AGP 8x
|256
|425
|425
|325
|3:2:2:2<br>*:4:4:4
|1.7
|1.7
|5.2
|DDR2
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 2000
|NV30GL
|130
|AGP 8x
|128
|400
|400
|800
|2:4:8:8
|3.2
|3.2
|12.8
|DDR2
|128
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 3000
|NV35GL
|130
|AGP 8x
|256
|400
|400
|850
|3:4:8:8
|3.2
|3.2
|27.2
|DDR
|256
|
|
|9.0
|2.0
|
|Stereo Display
|-
!Quadro FX 3000G
|NV35GL
|130
|AGP 8x
|256
|400
|400
|850
|3:4:8:8
|3.2
|3.2
|27.2
|DDR
|256
|
|
|9.0
|2.0
|
|Stereo Display, [[Genlock]]
|-
!Quadro FX 4000
|NV40GL
|130
|AGP 8x
|256
|375
|375
|1000
|5:12:12:8
|3
|4.5
|32.0
|GDDR3
|256
|
|
|9.0c
|2.1
|142
|Stereo Display
|-
!Quadro FX 4000 SDI
|NV40GL
|130
|AGP 8x
|256
|375
|375
|1000
|5:12:12:8
|3
|4.5
|32.0
|GDDR3
|256
|
|
|9.0c
|2.1
|
|Stereo Display, Genlock
|}

===Quadro FX (x300) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 330
|NV37GL
|150
|PCIe x16
|64
|250
|250
|400
|2:4:4:2
|1
|1
|3.2
|DDR
|128
|
|
|9.0
|2.0
|21
|
|-
!Quadro FX 1300
|NV41
|130
|PCIe x16
|128
|350
|350
|550
|3:8:8:8
|2.8
|2.8
|8.8
|DDR
|256
|
|
|9.0c
|2.1
|55
|
|}

===Quadro FX (x400) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 540
|NV43GL
|90
|PCIe x16
|128
|300
|300
|550
|4:8:8:8
|2.4
|2.4
|8.8
|GDDR3
|128
|
|
|9.0c
|2.1
|35
|
|-
!Quadro FX 1400
|NV41
|130
|PCIe x16
|128
|350
|350
|600
|5:12:12:8
|2.8
|4.2
|19.2
|DDR
|256
|
|
|9.0c
|2.1
|70
|Stereo Display, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 3400
|NV45GL
|130
|PCIe x16
|256
|350
|350
|900
|6:16:16:16
|5.6
|5.6
|28.8
|GDDR3
|256
|
|
|9.0c
|2.1
|101
|Stereo display, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 3450
|NV41
|130
|PCIe x16
|256
|425
|425
|1000
|5:12:12:8
|3.4
|5.1
|32.0
|GDDR3
|256
|
|
|9.0c
|2.1
|83
|Stereo display, [[Scalable Link Interface|SLI]]
|}

===Quadro FX (x500) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 350
|G72GL
|90
|PCIe x16
|128
|550
|550
|810
|3:4:4:2
|1.1
|1.1
|6.48
|DDR2
|64
|
|
|9.0c
|2.1
|21
|
|-
!Quadro FX 550
|NV43GL
|90
|PCIe x16
|128
|360
|360
|800
|4:8:8:8
|2.88
|2.88
|12.8
|GDDR3
|128
|
|
|9.0c
|2.1
|25
|
|-
!Quadro FX 1500
|G71
|90
|PCIe x16
|256
|375
|375
|800
|7:20:20:16
|6
|7.5
|40.0
|GDDR3
|256
|
|
|9.0c
|2.1
|65
|
|-
!Quadro FX 3500
|G71GL
|90
|PCIe x16
|256
|470
|470
|1320
|7:20:20:16
|7.52
|9.4
|42.2
|GDDR3
|256
|
|
|9.0c
|2.1
|80
|Stereo display, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 4500
|G70
|110
|PCIe x16
|512
|470
|470
|1050
|8:24:24:16
|7.52
|11.28
|33.6
|GDDR3
|256
|
|
|9.0c
|2.1
|109
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|-
!Quadro FX 4500X2
|G70
|110
|PCIe x16
|1024
|470
|470
|1050
|2x 8:24:24:16
|15.04
|22.56
|33.6
|GDDR3
|256
|
|
|9.0c
|2.1
|145
|Stereo display, Genlock
|-
!Quadro FX 4500 SDI
|G70
|110
|PCIe x16
|512
|470
|470
|1050
|8:24:24:16
|7.52
|11.28
|33.6
|GDDR3
|256
|
|
|9.0c
|2.1
|116
|Stereo display, Genlock
|-
!Quadro FX 5500
|G71
|90
|PCIe x16
|1024
|700
|700
|1050
|8:24:24:16
|11.2
|16.8
|33.6
|GDDR3
|256
|
|
|9.0c
|2.1
|96
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|-
!Quadro FX 5500 SDI
|G71
|90
|PCIe x16
|1024
|700
|700
|1050
|8:24:24:16
|11.2
|16.8
|33.6
|GDDR3
|256
|
|
|9.0c
|2.1
|104
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|}

===Quadro FX (x600) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>12</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 560
|G73GL
|90
|PCIe x16
|128
|350
|350
|1200
|5:12:12:8
|2.8
|4.2
|19.2
|GDDR3
|128
|
|
|9.0c
|2.1
|30
|
|-
!Quadro FX 4600<sup>2</sup>
|G80
|90
|PCIe x16
|768
|500
|1200
|1400
|96:24:24
|12
|24
|67.2
|GDDR3
|384
|345
| -
|10.0
|3.3
|134
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|-
!Quadro FX 4600 SDI<sup>2</sup>
|G80
|90
|PCIe x16
|768
|500
|1200
|1400
|96:24:24
|12
|24
|67.2
|GDDR3
|384
|345
| -
|10.0
|3.3
|154
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|-
!Quadro FX 5600<sup>2</sup>
|G80
|90
|PCIe 2.0 x16
|1536
|600
|1350
|1600
|128:32:24
|14.4
|38.4
|76.8
|GDDR3
|384
|518.4
| -
|10.0
|3.3
|171
|Stereo display, [[Scalable Link Interface|SLI]], Genlock
|}

===Quadro FX (x700) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 370
|G84
|80
|PCIe x16
|256
|360
|720
|1000
|16:8:4
|1.44
|2.88
|6.4
|DDR2
|64
|34.56
| -
|10.0
|3.3
|35
|
|-
!Quadro FX 370 LP
|G86
|80
|PCIe x16
|256
|540
|1080
|1000
|8:8:4
|2.16
|4.32
|8
|DDR2
|64
|25.92
| -
|10.0
|3.3
|25
|DMS-59 for two Single Link DVI
|-
!Quadro FX 470
|MCP7A-U
|65
|PCIe 2.0 x16<br>(Integrated)
|Up to 256MB from system memory.
|580
|1400
|800<br>(system memory)
|16:8:4
|2.32
|4.64
|12.8
|DDR2
|128
|67.2
| -
|10.0
|3.3
|30
|based on GeForce 9400 mGPU
|-
!Quadro FX 570
|G84GL
|80
|PCIe x16
|256
|460
|920
|800
|16:8:8
|3.68
|3.68
|12.8
|DDR2
|128
|44.1
| -
|10.0
|3.3
|38
|
|-
!Quadro FX 1700
|G84GL
|80
|PCIe x16
|512
|460
|920
|800
|32:16:8
|3.68
|7.36
|12.8
|DDR2
|128
|88.32
| -
|10.0
|3.3
|42
|
|-
!Quadro FX 3700
|G92
|65
|PCIe 2.0 x16
|512
|500
|1250
|1600
|112:56:16
|8
|28
|51.2
|GDDR3
|256
|420
| -
|10.0
|3.3
|78
|Stereo display, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 4700X2
|2xG92
|65
|PCIe 2.0 x16
|2x1024
|500
|1250
|1600
|2x(128:64:16)
|2x8
|2x32
|2x51.2
|GDDR3
|2x256
|2x480
| -
|10.0
|3.3
|226
|
|-
!Quadro VX 200
|G92
|65
|PCIe 2.0 x16
|512
|450
|1125
|1600
|112:56:16
|8
|28
|51.2
|GDDR3
|256
|420
| -
|10
|3.3
|75
|2 Dual-link DVI, S-Video, optimised for [[AutoCAD|Autodesk AutoCAD]]
|}

===Quadro FX (x800) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 380
|G96
|65
|PCIe 2.0 x16
|256
|450
|1100
|1400
|16:8:8
|3.6
|3.6
|22.4
|GDDR3
|128
|52.8
| -
|10.0
|3.3
|34
|Two Dual Link DVI, no DisplayPort
|-
!Quadro FX 380 LP
|GT218GL
|40
|PCIe 2.0 x16
|512
|589
|1402
|1600
|16:8:4
|2.356
|4.712
|12.8
|GDDR3
|64
|67.296
| -
|10.1
|3.3
|28
|DisplayPort, Dual Link DVI
|-
!Quadro FX 580
|G96
|65
|PCIe 2.0 x16
|512
|450
|1125
|1600
|32:16:8
|3.6
|7.2
|25.6
|GDDR3
|128
|108
| -
|10.0
|3.3
|40
|Dual DisplayPort, Dual Link DVI
|-
!Quadro FX 1800
|G100GL-U(G94)
|65
|PCIe 2.0 x16
|768
|550
|1375
|1600
|64:32:12
|6.6
|17.6
|38.4
|GDDR3
|192
|264
| -
|10.0
|3.3
|59
|Stereo DP Dual Link DVI, Dual DisplayPort, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 3800
|GT200GL
|55
|PCIe 2.0 x16
|1024
|602
|1204
|1600
|192:64:16
|9.632
|38.528
|51.2
|GDDR3
|256
|693.504
|86.688
|10.0
|3.3
|108
|Stereo DP Dual Link DVI, Dual DisplayPort, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 4800
|GT200GL
|55
|PCIe 2.0 x16
|1536
|602
|1204
|1600
|192:64:24
|14.448
|38.528
|76.8
|GDDR3
|384
|693.504
|86.688
|10.0
|3.3
|150
|Stereo DP Dual Link DVI, Dual DisplayPort, [[Scalable Link Interface|SLI]]
|-
!Quadro FX 5800
|GT200GL
|55
|PCIe 2.0 x16
|4096
|648
|1296
|1600
|240:80:32
|20.736
|51.840
|102.4
|GDDR3
|512
|933.12
|116.64
|10.1
|3.3
|189
|Stereo DP two Dual Link DVI, DisplayPort, [[Scalable Link Interface|SLI]]
|-
!Quadro CX<ref>[http://www.nvidia.com/object/product_quadro_cx_us.html NVIDIA Quadro CX is the accelerator for Adobe Creative Suite 4<!-- Bot generated title -->]</ref>
|GT200GL
|55
|PCIe 2.0 x16
|1536
|602
|1204
|1600
|192:64:24
|14.448
|38.528
|76.8
|GDDR3
|384
|693.504
|86.688
|10.0
|3.3
|150
|Display Port and dual-link DVI Output, optimised for [[Cs4|Adobe Creative Suite 4]]
|}

===Quadro x000 Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>4</sup> Each SM in the Fermi architecture contains 4 texture filtering units for every texture address unit. Total for the full GF100 64 texture address units and 256 texture filtering units<ref name="anandtech.com"/>
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro 400
|GT216GL
|40
|PCIe 2.0 x16
|512
|450
|1125
|1540
|48:16:4
|1.8
|7.2
|12.3
|DDR3
|64
|108
| -
|10.1
|3.3
|32
|DisplayPort, Dual Link DVI
|-
!Quadro 600
|GF108GL
|40
|PCIe 2.0 x16
|1024
|640
|1280
|1600
|96:16<sup>4</sup>:4
|2.56
|10.24
|25.6
|DDR3
|128
|245.76
| -
|11.0
|4.5
|40
|DisplayPort, Dual Link DVI
|-
!Quadro 2000
|GF106GL (GF106-875)
|40
|PCIe 2.0 x16
|1024
|625
|1250
|2600
|192:32<sup>4</sup>:16
|10
|20
|41.6
|GDDR5
|128
|480
| -
|11.0
|4.5
|62
|Stereo DP Dual Link DVI, Dual DisplayPort
|-
!Quadro 4000
|GF100
|40
|PCIe 2.0 x16
|2048
|475
|950
|2800
|256:32<sup>4</sup>:32
|15.2
|15.2
|89.6
|GDDR5
|256
|486.4
|243
|11.0
|4.5
|142
|
|-
!Quadro 5000
|GF100
|40
|PCIe 2.0 x16
|2560
|513
|1026
|3000
|352:44<sup>4</sup>:40
|20.53
|22.572
|120
|GDDR5
|320
|722.304
|359
|11.0
|4.5
|152
|
|-
!Quadro 6000
|GF100
|40
|PCIe 2.0 x16
|6144
|574
|1148
|3000
|448:56<sup>4</sup>:48
|27.552
|32.144
|144
|GDDR5
|384
|1028.608
|515
|11.0
|4.5
|204
|
|-
!Quadro 7000
|GF110
|40
|PCIe 2.0 x16
|6144
|651
|1301
|3696
|512:64<sup>4</sup>:48
|31.248
|41.7
|177
|GDDR5
|384
|1332
|667
|11.0
|4.5
|204
|
|}

===Quadro Kxxx Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro 410
|GK107
|28
|PCIe 3.0 x16
|512
|706
|706
|1800
|192:16:8<br>(1 SMX)
|5.65
|11.3
|14.4
|DDR3<ref>[http://www.nvidia.com/object/quadro-410-graphics-card.html#pdpContent=2 NVIDIA Quadro 410 Entry Level Professional Graphics Card | NVIDIA | NVIDIA<!-- Bot generated title -->]</ref>
|64
|271.10
|
|11.0
|4.5
|38
|
|-
!Quadro K600
|GK107
|28
|PCIe 2.0 x16
|1024
|876
|876
|891<br>(1782) 
|192:16:16<br>(1 SMX)
|14.0
|14.0
|28.5
|DDR3
|128
|336.38
|
|11.0
|4.5
|41
| 6.3" Card
|-
!Quadro K2000
|GK107
|28
|PCIe 2.0 x16
|2048
|954
|954
|1000<br>(4000) 
|384:32:16<br>(2 SMX)
|15.2
|30.5
|64
|GDDR5
|128
|732.67
|
|11.0
|4.5
|51
| 7.97" Card
|-
|-
!Quadro K2000D
|GK107
|28
|PCIe 2.0 x16
|2048
|954
|954
|1000<br>(4000) 
|384:32:16<br>(2 SMX)
|15.2
|30.5
|64
|GDDR5
|128
|732.67
|
|11.0
|4.5
|51
| 7.97" Card
|-
!Quadro K4000
|GK106
|28
|PCIe 2.0 x16
|3072
|810.5
|810.5
|1404<br>(5616) 
|768:64:24<br>(4 SMX)
|19.4
|51.9
|134.8
|GDDR5
|192
|1244.93
|
|11.0
|4.5
|80
| 9.5" Card
|-
!Quadro K5000
|GK104
|28
|PCIe 2.0 x16
|4096
|706
|706
|1350<br>(5400)
|1536:128:32<br>(8 SMX)
|22.6
|90.4
|172.8
|GDDR5
|256
|2168.83
|90.4
|11.0
|4.5
|122
| 10.5" Card
|-
!Quadro K6000
|GK110
|28
|PCIe 3.0 x16
|12288
|901.5
|901.5
|1502<br>(6008)
|2880:240:48<br>(15 SMX)
|54.1
|216
|288
|GDDR5
|384
|5196
|1732
|11.0
|4.5
|225
| 10.5" Card
|}

{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro K420
|GK107
|28
|PCIe 2.0 x16
|1024
|780
|780
|1800
|192:16:16<br>(1 SMX)
|12.48
|12.48
|14.4
|DDR3
|128
|299.52
|
|11.0
|4.5
|41
|
|-
!Quadro K620
|GM107
|28
|PCIe 2.0 x16
|2048
|1000
|1000
|900<br>(1800) 
|384:24:16<br>(3 SMM)
|16.0
|24.0
|28.8
|DDR3
|128
|768.0
|
|11.0
|4.5
|45
| 6.3" Card
|-
!Quadro K1200
|GM107
|28
|PCIe 2.0 x16
|4096
|
|
| 
|512:32:16<br>(4 SMM)
|
|
|
|GDDR5
|128
|
|
|11.0
|4.5
|45
| 7.97" Card
|-
!Quadro K2200
|GM107
|28
|PCIe 2.0 x16
|4096
|1000
|1000
|1250<br>(5000) 
|640:40:16<br>(5 SMM)
|16
|40
|80
|GDDR5
|128
|1280.0
|
|11.0
|4.5
|68
| 7.97" Card
|-
!Quadro K4200
|GK104
|28
|PCIe 2.0 x16
|4096
|780
|780
|1350<br>(5400) 
|1344:112:32<br>(7 SMX)
|24.96
|87.36
|172.8
|GDDR5
|256
|2096.64
|87.36
|11.0
|4.5
|105
| 9.5" Card
|-
!Quadro K5200
|GK110B
|28
|PCIe 3.0 x16
|8192
|650
|650
|1500<br>(6000)
|2304:192:32<br>(12 SMX)
|20.8
|124.8
|192
|GDDR5
|256
|2995.2
|124.8
|11.0
|4.5
|150
| 10.5" Card
|}

===Quadro Mxxx Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
! colspan=2 style="text-align:center;" | Processing Power<br>GFLOPS<ref name="NVcomp1" /><ref name="NVcomp2" />
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! [[Single precision floating-point format|Single Precision]]
! [[Double precision floating-point format|Double Precision]]
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro M6000
|GM200
|28
|PCIe 3.0 x16
|12288
|988
|988
|1653<br>(6612)
|3072:192:96<br>(24 SMM)
|94.8
|189.7
|317
|GDDR5
|384
|6070
|190
|12.0
|4.5
|225
| 10.5" Card
|}

===Quadro NVS===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>*</sup> NV31, NV34 and NV36 are 2x2 pipeline designs if running vertex shader, otherwise they are 4x1 pipeline designs.
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>12*</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power<br>GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!NVS 50
|NV18
|150
|AGP 4x/PCI
|64
|250
|250
|200
|0:2:4:2
|0.5
|1.0
|1.6
|DDR
|32
|
|7
|1.2
|
|[[DVI-I]], [[S-Video]]
|-
!NVS 100
|NV17
|150
|AGP 4x/PCI
|64
|
|
|333
|0:2:4:2
|
|
|5.328
|DDR
|128
|
|7
|1.2
|
|2x DVI-I, [[VGA]], S-Video
|-
!NVS 200
|NV17
|150
|AGP 4x/PCI
|64
|250
|250
|250
|0:2:4:2
|0.5
|1.0
|8.0

|DDR
|128
|
|7
|1.2
|
|[[Low Force Helix|LFH-60]]
|-
!NVS 210S
|MCP51
|90
|Integrated
|Up to 256 from system memory
|425
|
|
|1:2:2:1
| 0.425
| 0.850
|
|DDR
|128
|
|9.0c
|1.2
|
|[[Digital Visual Interface|DVI]] + [[VGA]]
|-
!NVS 280
|NV34GL
|150
|PCI-Express 16/AGP 8 / PCI
|64
|275
|275
|250
|0:2:4:2/<br>1:2:2:2 *:4:4:4
|0.55
|1.1
|8.0
|DDR
|128
|
|9.0
|1.5
|13
|[[DMS-59]]
|-
!NVS 285
|NV44
|110
|PCI-Express 1/16
|128
|275
|275
|275
|3:4:4:2
|0.55
|1.1
|8.8
|DDR
|128
|
|9.0
|2.1
|18
|[[DMS-59]]
|-
!NVS 290
|G86
|80
|PCI-Express 1/16
|256
|460
|920
|800
|16:8:4
|1.84
|3.68
|6.4
|DDR2
|64
|44.16
|10
|3.3
|21
|[[DMS-59]]
|-
!NVS 295
|G98
|65
|PCI-Express 1/16
|256
|550
|1300
|1400
|8:8:4
|2.2
|4.4
|11.2
|GDDR3
|64
|31.2
|10
|3.3
|23
|2 DisplayPort or 2 DVI-D
|-
!NVS 300
|GT218
|40
|PCI-Express 1/16
|512
|589
|1402
|1580
|16:8:4
|2.356
|4.712
|12.64
|DDR3
|64
|67.3
|10.1
|3.3
|17.5
|[[DMS-59]]
|-
!NVS 310
|GF119
|40
|PCI-Express 16
|512
|
|
|1750
|48:8:4
|
|
|14
|DDR3
|64
|
|11.0
|4.5
|19.5
|2 DisplayPort
|-
!NVS 315
|GF119
|40
|PCI-Express 16
|1024
|
|
|1800
|48:8:4
|
|
|14
|GDDR3
|64
|
|11.0
|4.5
|19.5
|[[DMS-59]]
|-
!NVS 400
|2 NV17
|150
|PCI
|2 64
|220
|220
|343
|2 0:2:4:2
|2 0.44
|2 0.88
|2 11.0
|DDR
|2 128
|2 5.328
|
|
|
|DMS-59
|-
!NVS 420
|2G98
|65
|PCI-Express 1/16
|2 256
|550
|1300
|1400
|2 8:8:4
|2 2.2
|2 4.4
|2 11.2
|GDDR3
|2 64
|2 31.2
|10
|3.3
|40
|through VHDCI to (4 DisplayPort or 4 DVI-D)
|-
|-
!NVS 440
|2NV43
|110
|PCI-Express 16
|2 128
|
|
|
|
|
|
|
|
|
|
|
|
|31
|2x [[DMS-59]]<ref>{{cite web|title=NVIDIA Quadro NVS Technical Specications|url=http://http.download.nvidia.com/ndemand/Quadro_extranet/Product_Overview/PO_QUADRO_NVS_MAY06_REV2.pdf|work=Nvidia press release|accessdate=15 May 2014}}</ref>
|-
!NVS 510
|GK107
|28
|PCI-Express 16
|2048
|
|
|1800
|192:16:8<br>(1 SMX)
|
|
|28.5
|GDDR3
|128
|
|11.0
|4.5
|35
|4 miniDisplayPort
|}

===Tesla===
{{Main|NVIDIA Tesla}}
* <sup>1</sup> Specifications not specified by NVIDIA assumed to be based on the [[GeForce 8 series#GeForce 8800 Series|GeForce 8800GTX]]
* <sup>2</sup> Specifications not specified by NVIDIA assumed to be based on the [[GeForce 200 Series#GeForce GTX 200|GeForce GTX 280]]
* <sup>3</sup> Specifications not specified by NVIDIA are assumed to be based on the [[GeForce 400 Series]]
* <sup>4</sup> With ECC on, a portion of the dedicated memory is used for ECC bits, so the available user memory is reduced by 12.5%. (e.g. 3 GB total memory yields 2.625 GB of user available memory.)
* <sup>5</sup> Fermi implements the new [[fused multiplyadd]] (FMA) instruction for both 32-bit single-precision and 64-bit double-precision floating point numbers (GT200 supported FMA only in double precision) that improves upon multiplyadd by retaining full precision in the intermediate stage.<ref>{{PDFlink|[http://www.nvidia.com/content/PDF/fermi_white_papers/NVIDIA_Fermi_Compute_Architecture_Whitepaper.pdf NVIDIA Fermi Compute Architecture Whitepaper.pdf]|855KB}}, Page 13 of 22</ref>
* <sup>6</sup> Specifications not specified by NVIDIA assumed to be based on the Quadro FX 5800
* For the basic specifications of Tesla, refer to the GPU Computing Processor specifications.
* Due to Tesla's non-output nature, fillrate and graphics API compatibility are not applicable.
{| class="wikitable" style="font-size: 85%; text-align: center;"
|-
! rowspan=2 style="width:12em" | Configuration
! rowspan=2 | Model
! rowspan=2 | Archi-<br>tecture
! rowspan=2 | # of GPUs
! rowspan=2 | Core clock<br>(MHz)
! colspan=2 style="text-align:center;" | Shaders
! colspan=5 style="text-align:center;" | Memory
! colspan=3 style="text-align:center;" | Processing Power (peak) <br> GFLOPS<ref name=autogenerated1>[http://www.siliconmadness.com/2009/11/nvidia-announces-tesla-20-series.html nVidia Announces Tesla 20 Series]</ref>
! rowspan=2 | Compute capability
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes/Form factor
|-
! Thread Processors<br>(total)
! Clock (MHz)
! Bus type
! Bus width<br>([[bit]])
! Memory<br>([[Megabyte|MB]])
! Clock (MHz)
! Bandwidth<br>(total)<br>([[Gigabyte|GB]]/s)
! [[Single precision floating-point format|Single Precision(SP)]] Total(MUL+ADD+SF)
! [[Single precision floating-point format|Single Precision(SP)]] MAD(MUL+ADD)
! [[Double precision floating-point format|Double Precision(DP)]] [[Fused multiplyadd|FMA]]
|- valign="top"
! style="text-align:left;" | C870<br>GPU Computing Module
| C870<sup>1</sup>
| G80
| 1
| 600
| 128
| 1350
| GDDR3
| 384
| 1536
| 1600
| 76.8
| 518.4
| 345.6
| 0
| 1.0
| 170.9
| Internal GPU <br> (Full-height card)
|- valign="top"
! style="text-align:left;" | D870<br>Deskside Computer
| D870<sup>1</sup>
| G80
| 2
| 600
| 256
| 1350
| GDDR3
| 384
| 2x1536
| 1600
| 153.6
| 2x 518.4
| 2x 345.6
| 0
| 1.0
| 520
| Deskside External GPUs
|- valign="top"
! style="text-align:left;" | S870<br>GPU Computing Server
| S870<sup>1</sup>
| G80
| 4
| 600
| 512
| 1350
| GDDR3
| 384
| 4x 1536
| 1600
| 307.2
| 4x 518.4
| 4x 345.6
| 0
| 1.0
|
| 1U [[19-inch rack|Rackmount]] External GPUs
|- valign="top"
! style="text-align:left;" | C1060<br>GPU Computing Module
| C1060<sup>2</sup>
| GT200
| 1
| 602
| 240
| 1300
| GDDR3
| 512
| 4096
| 1600
| 102.4
| 933.12
| 622.08
| 77.76
| 1.3
| 187.8
| Internal GPU <br> (Full-height card)
|- valign="top"
! style="text-align:left;" | Quadro Plex Visual Computing System
| 2200 D2<sup>6</sup>
| GT200GL
| 2
| 648
| 2 x 240 (480)
| 1296
| GDDR3
| 512
| 2x 4096 (8192)
| 1600
| 2x 102.4
| 2x 933.12
| 2x 622.08
| 2x 77.76
| 1.3
|
| 4 dual-link DVI<br>Deskside or 3U rackmount
|- valign="top"
! style="text-align:left;" | Quadro Plex Visual Computing System
| 2200 S4<sup>6</sup>
| GT200GL
| 4
| 648
| 4 x 240 (960)
| 1296
| GDDR3
| 512
| 4x 4096 (16384)
| 1600
| 4x 102.4
| 4x 933.12
| 4x 622.08
| 4x 77.76
| 1.3
|
| display readback Via PCI-Express Gen 2.0<br>1U server
|- valign="top"
! style="text-align:left;" | S1070<br>GPU Computing Server
| S1070<sup>2</sup>
| GT200
| 4
| 602
| 4 x 240 (960)
| 1440/1296
| GDDR3
| 512
| 4x4096
| 1538.4
| 4x 98.5
| 4x 1036.8
| 4x 691.2
| 4x 86.4
| 1.3
| 800
| 1U [[19-inch rack|Rackmount]] External GPUs<br>connect via 2x PCIe (x8 or x16)
|- valign="top"
! style="text-align:left;" | S1075<br>GPU Computing Server
| S1075<sup>2</sup> <ref>[http://forums.nvidia.com/index.php?showtopic=80850 Difference between Tesla S1070 and S1075]</ref>
| GT200
| 4
| 602
| 4x 240 (960)
| 1500
| GDDR3
| 512
| 4x 4096
| 1600
| 4x 102.4
| 4x 1036.8
| 4x 691.2
| 4x 86.4
| 1.3
|
| 1U [[19-inch rack|Rackmount]] External GPUs<br>connect via 1x PCIe (x8 or x16)
|- valign="top"
! style="text-align:left;" | C2050<br>GPU Computing Module
| C2050<sup>3</sup>
| GF100
| 1
| 575
| 448
| 1150
| GDDR5
| 384
| 3072<sup>4</sup>
| 3000
| 144
| 1288
| 1030.4<sup>5</sup>
| 515.2
| 2.0
| 238
| Internal GPU<br>(Full-height card)
|- valign="top"
! style="text-align:left;" | C2070<br>GPU Computing Module
| C2070<sup>3</sup>
| GF100
| 1
| 575
| 448
| 1150
| GDDR5
| 384
| 6144<sup>5</sup>
| 3000
| 144
| 1288
| 1030.4<sup>6</sup>
| 515.2
| 2.0
| 247
| Full-height [[video card]]<br>[[IEEE 754-2008]] [[Multiplyaccumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | C2075<br>GPU Computing Module
| C2075
| GF100
| 1
| 575
| 448
| 1150
| GDDR5
| 384
| 6144
| 3000
| 144
| 1288
| 1030.4<sup>6</sup>
| 515.2
| 2.0
| 225
| Full-height [[video card]]<br>[[IEEE 754-2008]] [[Multiplyaccumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | M2050<br>GPU Computing Module
| M2050
| GF100
| 1
| 575
| 448
| 1150
| GDDR5
| 384
| 3072<sup>5</sup>
| 3092
| 148.4
| 1288
| 1030.4<sup>6</sup>
| 515.2
| 2.0
| 225
| Computing Module <br>[[IEEE 754-2008]] [[Multiplyaccumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | M2070/M2070Q<br>GPU Computing Module
| M2070/M2070Q <ref>[http://www.vizworld.com/2010/08/nvidia-tesla-m2050-m2070m2070q-specs-online/ NVidia Tesla M2050 & M2070/M2070Q Specs Online]</ref>
| GF100
| 1
| 575
| 448
| 1150
| GDDR5
| 384
| 6144<sup>5</sup>
| 3132
| 150.336
| 1288
| 1030.4<sup>6</sup>
| 515.2
| 2.0
| 225
| Computing Module<br>[[IEEE 754-2008]] [[Multiplyaccumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | M2090<br>GPU Computing Module
| M2090
| GF110
| 1
| 650
| 512
| 1300
| GDDR5
| 384
| 6144<sup>5</sup>
| 3700
| 177.4
| 1664
| 1331.2<sup>6</sup>
| 665.6
| 2.0
| 250
| Computing Module <br>[[IEEE 754-2008]] [[Multiplyaccumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | S2050<br>GPU Computing Server
| S2050
| GF100
| 4
| 575
| 4x 448 (1792)
| 1150
| GDDR5
| 384
| 12288<sup>5</sup>
| 3092
| 4x 148.4 (593.6)
| 5152
| 4121.6<sup>6</sup>
| 2060.8
| 2.0
| 900
| [[19-inch rack|1U Rack]]<br>[[IEEE 754-2008]] [[Multiplyaccumulate|FMA]] capabilities
|- valign="top"
! style="text-align:left;" | K10<br>GPU Computing Module
| K10
| GK104
| 2
| 745
| 2x 1536 (3072)
| 745
| GDDR5
| 2x 256
| 2x 4096
| 5000
| 2x 160 (320)
| 5340
| 4577
| 190
| 3.0
| 250W
| Internal GPU<br>(Full-height card)
|- valign="top"
! style="text-align:left;" | K20<br>GPU Computing Module
| K20
| GK110
| 1
| 705
| 2496 FP32, 832 FP64
| 705
| GDDR5
| 320
| 5120
| 5200
| 208
| 4106
| 3519
| 1173
| 3.5
| 225W
| Internal GPU<br>(Full-height card)
|- valign="top"
! style="text-align:left;" | K20X<br>GPU Computing Module
| K20X
| GK110
| 1
| 732
| 2688 FP32, 896 FP64
| 732
| GDDR5
| 384
| 6144
| 5200
| 250
| 4591
| 3935
| 1312
| 3.5
| 235W
| Internal GPU<br>(Full-height card)
|
|- valign="top"
! style="text-align:left;" | K40<br>GPU Computing Module
| K40
| GK110B
| 1
| 745
| 2880 FP32, 960 FP64
| 745
| GDDR5
| 384
| 12288
| 6000
| 288
| 5364
| 4291
| 1430
| 3.5
| 235W
| Internal GPU<br>(Full-height card)
|
|- valign="top"
! style="text-align:left;" | K80<br>GPU Computing Module
| K80
| GK210
| 2
| 745
| 2 x 2496 (4992)
| 562
| GDDR5
| 2 x 384
| 2 x 12288
| 5000
| 2 x 240
| 8740
| 6992
| 2330
| 3.7
| 300W
| Internal GPU<br>(Full-height card)
|
|-
! rowspan=2 style="width:12em" | Configuration
! rowspan=2 | Model
! rowspan=2 | Archi-<br>tecture
! rowspan=2 | # of GPUs
! rowspan=2 | Core clock<br>(MHz)
! colspan=2 style="text-align:center;" | Shaders
! colspan=5 style="text-align:center;" | Memory
! colspan=3 style="text-align:center;" | Processing Power (peak) <br> GFLOPS<ref name=autogenerated1 />
! rowspan=2 | Compute capability
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes/Form factor
|-
! Thread Processors<br>(total)
! Clock (MHz)
! Bus type
! Bus width<br>([[bit]])
! Memory<br>([[Megabyte|MB]])
! Clock (MHz)
! Bandwidth<br>(total)<br>([[Gigabyte|GB]]/s)
! [[Single precision floating-point format|Single Precision(SP)]] Total(MUL+ADD+SF)
! [[Single precision floating-point format|Single Precision(SP)]] MAD(MUL+ADD)
! [[Double precision floating-point format|Double Precision(DP)]] [[Fused multiplyadd|FMA]]
|}

==Comparison table: Mobile workstation GPUs==

===Quadro FX (xxxM) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>12</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 350M
|G72GLM
|90
|PCIe 1.0 x16
|256
|450
|450
|900
|3:4:4:2
|0.9
|1.8
|14.4
|GDDR3
|128
|
|9.0c
|2.1
|15
|
|-
!Quadro FX 360M
|G86M
|80
|PCIe 1.0 x16
|256
|400
|800
|1200
|16:8:4
|1.6
|3.2
|9.6
|DDR2
|64
|38.4
|10.0
|3.3
|17
|
|-
!Quadro FX 370M
|G98M
|65
|PCIe 1.0 x16
|256
|550
|1400
|1200
|8:4:4
|2.2
|2.2
|9.6
|GDDR3
|64
|33.6
|10.0
|3.3
|20
|
|-
!Quadro FX 380M
|GT218M
|40
|PCIe 2.0 x16
|512
|625
|1530
|1600
|16:8:4
|2.5
|5
|12.8
|GDDR3
|64
|73.44
|10.1
|3.3
|25
|
|-
!Quadro FX 560M
|G73GLM
|90
|PCIe 1.0 x16
|512
|500
|500
|1200
|5:12:12:8
|4
|6
|19.2
|GDDR3
|128
|
|9.0c
|2.1
|35?
|
|-
!Quadro FX 570M
|G84M
|80
|PCIe 1.0 x16
|512
|475
|950
|1400
|32:16:8
|3.8
|7.6
|22.4
|GDDR3
|128
|91.2
|10.0
|3.3
|45
|
|-
!Quadro FX 770M
|G96M
|65
|PCIe 1.0 x16
|512
|500
|1250
|1600
|32:16:8
|4
|8
|25.6
|GDDR3
|128
|119.0
|10.0
|3.3
|35
|
|-
!Quadro FX 880M
|GT216M
|40
|PCIe 2.0 x16
|1024
|550
|1210
|1600
|48:16:8
|4.4
|8.8
|25.6
|GDDR3
|128
|174.24
|10.1
|3.3
|35
|
|}

===Quadro FX (x500M) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 1500M
|G71GLM
|90
|PCIe 1.0 x16
|512
|375
|375
|1000
|8:24:24:16
|6
|9
|32
|GDDR3
|256
|
|9.0c
|2.1
|45
|
|-
!Quadro FX 2500M
|G71GLM
|90
|PCIe 1.0 x16
|512
|500
|500
|1200
|8:24:24:16
|8
|12
|38.4
|GDDR3
|256
|
|9.0c
|2.1
|45
|
|-
!Quadro FX 3500M
|G71GLM
|90
|PCIe 1.0 x16
|512
|575
|575
|1200
|8:24:24:16
|9.2
|13.8
|38.4
|GDDR3
|256
|
|9.0c
|2.1
|45
|
|}

===Quadro FX (x600M) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 1600M
|G84M
|80
|PCIe 1.0 x16
|512
|625
|1250
|1600
|32:16:8
|5
|10
|25.6
|GDDR3
|128
|120
|10.0
|3.3
|50?
|
|-
!Quadro FX 3600M
|G92M
|65
|PCIe 1.0 x16
|512
|500
|1250
|1600
|64:32:16<br>96:48:16
|8<br>8
|16<br>24
|51.2
|GDDR3
|256
|240<br>360
|10.0
|3.3
|70
|based on 8800M GTS/<br>8800M GTX
|}

===Quadro FX (x700M) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 1700M
|G96M
|65
|PCIe 1.0 x16
|512
|625
|1550
|1600
|32:16:8
|5
|10
|25.6
|GDDR3
|128
|148.8
|10.0
|3.3
|50
|
|-
!Quadro FX 2700M
|G94M
|65
|PCIe 1.0 x16
|512
|530
|1325
|1600
|48:24:16
|8.48
|12.72
|51.2
|GDDR3
|256
|190.8
|10.0
|3.3
|65
|
|-
!Quadro FX 3700M
|G92M
|65
|PCIe 1.0 x16
|1024
|550
|1375
|1600
|128:64:16
|8.8
|35.2
|51.2
|GDDR3
|256
|528
|10.0
|3.3
|75
|
|}

===Quadro FX (x800M) Series===
{{Main|NVIDIA Quadro}}
*<sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro FX 1800M
|GT215M
|40
|PCIe 2.0 x16
|1024
|450
|1080
|1600<br>2200
|72:24:8
|3.6
|10.8
|25.6<br>35.2
|GDDR3<br>GDDR5
|128
|233.28
|10.1
|3.3
|45
|
|-
!Quadro FX 2800M
|G92M
|55
|PCIe 2.0 x16
|1024
|500
|1250
|2000
|96:48:16
|8
|16
|64
|GDDR3
|256
|360
|10.0
|3.3
|75
|
|-
!Quadro FX 3800M
|G92M
|55
|PCIe 2.0 x16
|1024
|675
|1688
|2000
|128:64:16
|10.8
|43.2
|64
|GDDR3
|256
|648.192
|10.0
|3.3
|100
|
|}

===Quadro (xxxxM) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> Each SM in the Fermi architecture contains 4 texture filtering units for every texture address unit
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>12</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro 500M
|GF108
|40
|PCIe 2.0 x16
|1024
|700
|1400
|1800
|96:16:4
|2.8
|11.2
|28.8
|DDR3
|128
|268.8
|11.0
|4.5
|35
|
|-
!Quadro 1000M
|GF108
|40
|PCIe 2.0 x16
|2048
|700
|1400
|1800
|96:16:4
|2.8
|11.2
|28.8
|DDR3
|128
|268.8
|11.0
|4.5
|45
|
|-
!Quadro 2000M
|GF106
|40
|PCIe 2.0 x16
|2048
|550
|1100
|1800
|192:32:16
|8.8
|17.6
|28.8
|DDR3
|128
|422.4
|11.0
|4.5
|55
|
|-
!Quadro 3000M
|GF104
|40
|PCIe 2.0 x16
|2048
|450
|900
|2500
|240:40:32
|14.4
|18
|80
|GDDR5
|256
|432
|11.0
|4.5
|75
|
|-
!Quadro 4000M
|GF104
|40
|PCIe 2.0 x16
|2048
|475
|950
|2500
|336:56:32
|15.2
|26.6
|80
|GDDR5
|256
|638.4
|11.0
|4.5
|100
|
|-
!Quadro 5000M
|GF100
|40
|PCIe 2.0 x16
|2048
|405
|810
|2400
|320:40:32
|12.96
|16.2
|76.8
|GDDR5
|256
|518.4
|11.0
|4.5
|100
|
|-
!Quadro 5010M
|GF110
|40
|PCIe 2.0 x16
|4096
|450
|900
|2600
|384:48:32
|14.4
|21.6
|83.2
|GDDR5
|256
|691.2
|11.0
|4.5
|100
|
|}

===Quadro (Kx000M) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Nvidia Optimus]] <br> Technology
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro K500M
|GK107
|28
|PCIe 3.0 x16
|1024
|850
|850
|1600
|192:16:8<br>(1 SMX)
|6.8
|13.6
|12.8
|DDR3
|64
|326.4
|11.0
|4.5
|Yes
|35
|
|-
!Quadro K1000M
|GK107
|28
|PCIe 3.0 x16
|2048
|850
|850
|1800
|192:16:16<br>(1 SMX)
|13.6
|13.6
|28.8
|DDR3
|128
|326.4
|11.0
|4.5
|Yes
|45
|
|-
!Quadro K2000M
|GK107
|28
|PCIe 3.0 x16
|2048
|745
|745
|1800
|384:32:16<br>(2 SMX)
|11.92
|23.84
|28.8
|DDR3
|128
|572.16
|11.0
|4.5
|Yes
|55
|
|-
!Quadro K3000M
|GK104
|28
|PCIe 3.0 x16
|2048
|654
|654
|2800
|576:48:32<br>(3 SMX)
|20.93
|31.39
|89.6
|GDDR5
|256
|753.41
|11.0
|4.5
|Yes
|75
|
|-
!Quadro K4000M
|GK104
|28
|PCIe 3.0 x16
|4096
|600
|600
|2800
|960:80:32<br>(5 SMX)
|19.2
|48
|89.6
|GDDR5
|256
|1152
|11.0
|4.5
|Yes
|100
|
|-
!Quadro K5000M
|GK104
|28
|PCIe 3.0 x16
|4096
|706
|706
|3000
|1344:112:32<br>(7 SMX)
|22.59
|79.07
|96
|GDDR5
|256
|1897.73
|11.0
|4.5
|Yes
|100
|
|}

===Quadro (Kx100M) Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Nvidia Optimus]] <br> Technology
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro K510M
|GK208
|28
|PCIe 3.0 x8
|1024
|850
|850
|1200 <br> (2400)
|192:16:8<br>(1 SMX)
|
|
|19.2
|GDDR5
|64
|326.4
|11.0
|4.5
|Yes
|30
|
|-
!Quadro K610M
|GK208
|28
|PCIe 3.0 x16
|1024
|980
|980
|1300 <br> (2600)
|192:16:8<br>(1 SMX)
|
|
|20.8
|GDDR5
|64
|376.32
|11.0
|4.5
|Yes
|30
|
|-
!Quadro K1100M
|GK107
|28
|PCIe 3.0 x16
|2048
|716
|716
|1400 <br> (2800)
|384:32:16<br>(2 SMX)
|
|
|44.8
|GDDR5
|128
|549.89
|11.0
|4.5
|Yes
|45
|
|-
!Quadro K2100M
|GK106
|28
|PCIe 3.0 x16
|2048
|654
|654
|1500 <br> (3000)
|576:48:16<br>(3 SMX)
|
|
|48.0
|GDDR5
|128
|753.41
|11.0
|4.5
|Yes
|55
|
|-
!Quadro K3100M
|GK104
|28
|PCIe 3.0 x16
|4096
|680
|680
|800 <br> (3200)
|768:64:32<br>(4 SMX)
|
|
|102.4
|GDDR5
|256
|1044.48
|11.0
|4.5
|Yes
|75
|
|-
!Quadro K4100M
|GK104
|28
|PCIe 3.0 x16
|4096
|706
|706
|800 <br> (3200)
|1152:96:32<br>(6 SMX)
|
|
|102.4
|GDDR5
|256
|1626.624
|11.0
|4.5
|Yes
|100
|
|-
!Quadro K5100M
|GK104
|28
|PCIe 3.0 x16
|8192
|771
|771
|900 <br> (3600)
|1536:128:32<br>(8 SMX)
|
|
|115.2
|GDDR5
|256
|2368.51
|11.0
|4.5
|Yes
|100
|
|}

===Mobility Quadro NVS Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup> [[Vertex shader]]s : [[Pixel shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s
* <sup>2</sup> [[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>12</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS 
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!Quadro NVS 110M
|G72M
|90
|PCIe 1.0 x16
|up to 512
|300
|300
|600
|3:4:4:2
|0.6
|1.2
|4.8
|DDR
|64
|
|9.0c
|2.1
|10
|
|-
!Quadro NVS 120M
|G72GLM
|90
|PCIe 1.0 x16
|up to 512
|450
|450
|700
|3:4:4:2
|0.9
|1.8
|5.6
|DDR2
|64
|
|9.0c
|2.1
|10
|
|-
!Quadro NVS 130M
|G86M
|80
|PCIe 2.0 x16
|up to 256
|400?
|800?
|700
|8:4:4
|1.6?
|1.6?
|6.4?
|DDR2
|64
|19.2
|10.0
|3.3
|10
|
|-
!Quadro NVS 135M
|G86M
|80
|PCIe 2.0 x16
|up to 256
|400
|800
|1188
|16:8:4
|1.6
|3.2
|9.504
|GDDR3
|64
|38.4
|10.0
|3.3
|10
|
|-
!Quadro NVS 140M
|G86M
|80
|PCIe 2.0 x16
|up to 512
|400
|800
|1200
|16:8:4
|1.6
|3.2
|9.6
|GDDR3
|64
|38.4
|10.0
|3.3
|10
|
|-
!Quadro NVS 150M
|G98M
|65
|PCIe 2.0 x16
|up to 256
|530
|1300
|1400
|8:4:4
|2.12
|2.12
|11.2
|GDDR3
|64
|31.2
|10.0
|3.3
|10
|
|-
!Quadro NVS 160M
|G98M
|65
|PCIe 2.0 x16
|256
|580
|1450
|1400
|8:8:4
|2.12
|4.24
|11.2
|GDDR3
|64
|34.8
|10.0
|3.3
|12
|
|-
!Quadro NVS 300M
|G72GLM
|90
|PCIe 1.0 x16
|up to 512
|450
|450
|1000
|3:4:4:2
|0.9
|1.8
|8
|DDR2
|64
|
|9.0c
|2.1
|16
|
|-
!Quadro NVS 320M
|G84M
|65
|PCIe 2.0 x16
|up to 512
|575
|1150
|1400
|32:16:8
|4.6
|9.2
|22.4
|GDDR3
|128
|110.4
|10.0
|3.3
|20
|
|-
!Quadro NVS 510M
|G72GLM
|90
|PCIe 1.0 x16
|up to 1024
|500
|500
|1200
|8:24:24:16
|8
|12
|38.4
|GDDR3
|256
|
|9.0c
|2.1
|45?
|based on Go 7900 GTX
|-
|}

===Mobility NVS Series===
{{Main|NVIDIA Quadro}}
* <sup>1</sup>[[Unified shader model|Unified Shaders]] : [[Texture mapping unit]]s : [[Render output unit]]s
{| class="wikitable" style="font-size: 85%; text-align: center; width: auto;"
|-
! rowspan=2 | Model
! rowspan=2 | [[Code name]]
! rowspan=2 | Fab ([[Nanometer|nm]])
! rowspan=2 | [[Computer bus|Bus]] [[I/O interface|interface]]
! rowspan=2 | Memory ([[Megabyte|MB]])
! rowspan=2 | Core clock ([[Hertz|MHz]])
! rowspan=2 | Shader clock ([[Hertz|MHz]])
! rowspan=2 | Memory clock ([[Hertz|MHz]])
! rowspan="2" | Core config<sup>1</sup>
! colspan=2 style="text-align:center;" | [[Fillrate]]
! colspan=3 style="text-align:center;" | Memory
!| Processing Power <br> GFLOPS 
! colspan=2 style="text-align:center;" | [[Application programming interface|API]] support (version)
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
! rowspan=2 | Notes
|-
! Pixel ([[Pixel|GP]]/s)
! Texture ([[Texel (graphics)|GT]]/s)
! Bandwidth ([[Gigabyte|GB]]/s)
! Bus type
! Bus width ([[bit]])
! Single precision
! [[DirectX]]
! [[OpenGL]]
|-
!NVS 2100M
|GT218M
|40
|PCIe 2.0 x16
|up to 512
|535
|1230
|1600
|16:8:4
|2.14
|4.28
|12.8
|GDDR3
|64
|59.04
|10.1
|3.3
|14
|
|-
!NVS 3100M
|GT218M
|40
|PCIe 2.0 x16
|up to 512
|600
|1470
|1600
|16:8:4
|2.4
|4.8
|12.8
|GDDR3
|64
|70.56
|10.1
|3.3
|14
|based on G210M/310M
|-
!NVS 4200M
|GF119
|40
|PCIe 2.0 x16
|up to 1024
|810
|1620
|1600
|48:8:4
|3.24
|6.48
|12.8
|GDDR3
|64
|155.52
|11
|4.5
|
|based on GT 520M
|-
!NVS 5100M
|GT216M
|40
|PCIe 2.0 x16
|up to 1024
|550
|1210
|1600
|48:16:8
|4.4
|8.8
|25.6
|GDDR3
|128
|174.24
|10.1
|3.3
|35
|
|-
!NVS 5200M
|GF108
|40/28
|PCIe 2.0 x16
|up to 1024
|625
|1250
|1800
|96:16:4
|2.5
|10
|14.4
|GDDR3
|64
|240
|11
|4.5
|35
|
|-
!NVS 5400M
|GF108
|40/28
|PCIe 2.0 x16
|up to 2048
|660
|1320
|1800
|96:16:4
|2.64
|10.56
|28.8
|GDDR3
|128
|253.44
|11
|4.5
|35
|
|}

==Comparison table: Grid GPUs==
{| class="wikitable" style="font-size: 85%; text-align: center;"
|-
! rowspan=2 | Model
! rowspan=2 | Archi-<br>tecture
! rowspan=2 | # of GPUs
! rowspan=2 | Thread Processors<br>(total)
! rowspan=2 | Bus Interface
! colspan=2 style="text-align:center;" | Memory
! rowspan=2 | [[Thermal Design Power|TDP]] (watts)
|-
! Bus type
! Memory<br>([[Gigabyte|GB]])
|- valign="top"
!style="text-align:left"|GRID K1 
|GK107<ref>http://www.nvidia.com/content/grid/pdf/GRID_K1_BD-06633-001_v02.pdf</ref>
|4
|768
|PCIe 3.0 x16
|DDR3
|16
|130
|- valign="top"
! style="text-align:left;"|GRID K2
|GK104-895<ref>[http://www.sabrepc.com/p-3968-supermicro-aoc-gpu-nvk2-rl-vgx-grid-k2-kepler-8gb-gpu-passive.aspx Overview for Supermicro AOC-GPU-NVK2-RL (VGX) GRID K2 Kepler 3072 CUDA 8GB PCI-Express 3.0 x16 GPU -Passive - SabrePC.com<!-- Bot generated title -->]</ref>
|2
|3072
|PCIe 3.0 x16
|GDDR5
|8
|225
|}
* Data from GRID GPUS<ref>[http://www.nvidia.com/object/grid-boards.html GRID Boards for GPU Virtualization | NVIDIA GRID | NVIDIA<!-- Bot generated title -->]</ref>

==Comparison table: Console GPUs==
{{no footnotes|section|date = October 2013}}
{| class="wikitable" style="font-size: 85%; text-align: center"
|-
!rowspan=2|Model
!rowspan=2|Launch
!rowspan=2|[[Code name]]
!rowspan=2|Fab ([[nanometer|nm]])
!rowspan=2|[[Computer bus|Bus]] [[I/O interface|interface]]
!rowspan=2|Memory ([[Megabyte|MB]])
!rowspan=2|Core clock ([[Hertz|MHz]])
!rowspan=2|Memory clock ([[Hertz|MHz]])
!rowspan=2|Core config<sup>1</sup>
!colspan=4|[[Fillrate]]
!colspan=3|Memory
!colspan=2|[[Application Programming Interface|API]] support
|-
!MOperations/s
!MPixels/s
!MTextels/s
!MVertices/s
!Bandwidth ([[Gigabyte|GB]]/s)
!Bus type
!Bus width ([[bit]])
![[DirectX]]
![[OpenGL]]
|-
!style="text-align:left"|XGPU([[Xbox (console)|Xbox]]) 
|November 15, 2001
|NV2A
|150
|Integrated
|64
|233
|200
|4:2:8:4
|932
|932
|1864
|116.5
|6.4
|DDR
|128
|8.1
|1.4
|-
!style="text-align:left"|[[RSX 'Reality Synthesizer'|RSX]]([[PS3]]) 
|November 11, 2006
|G70
|90, 65, 40
|FlexIO
|256<br>256
|550
|700 
|24:8:24:8
|13200
|4400
|13200
|1100
|22.4<br>20 (read), 15 (write)
|GDDR3<br>XDR
|128
|N/A
|ES 1.1 w/Cg
|}

* <sup>1</sup> [[Pixel shader]]s : [[Vertex shader]]s : [[Texture mapping unit]]s : [[Render output unit]]s

==See also==
* [[nouveau (software)|nouveau]]
* [[Scalable Link Interface]] (SLI)
* [[TurboCache]]
* [[Tegra]]
* [[CUDA]]
* [[Comparison of Nvidia chipsets]]
* [[List of AMD graphics processing units]]
* [[List of Intel graphics processing units]]

==References==
{{Reflist|2}}

==External links==
* [http://download.nvidia.com/developer/Papers/2005/OpenGL_2.0/NVIDIA_OpenGL_2.0_Support.pdf OpenGL 2.0 support on NVIDIA GPUs (PDF document)]
* [http://developer.download.nvidia.com/opengl/glsl/glsl_release_notes.pdf Release Notes for NVIDIA OpenGL Shading Language Support (PDF document)]
* [http://www.opengl.org/ OpenGL homepage]
* [http://www.microsoft.com/windows/directx/default.mspx DirectX homepage]
* [http://www.tomshardware.com/charts/ Benchmarks and comparisons for some consumer graphics cards]
* [http://www.anandtech.com/video/showdoc.aspx?i=2977 AnandTech Comparison of PureVideo HD with VP1 and VP2]
* [http://www.anandtech.com/video/showdoc.aspx?i=2984 AnandTech GeForce 8M Features]
* [http://www.mwave.com.au/blog/2014/6/2/timeline-popular-games-and-video-cards-requirements Timeline for popular games and graphic cards requirements]
* [http://www.techpowerup.com/forums/showthread.php?t=171000 TechPowerUp! GPU Database]

{{NVIDIA}}

{{DEFAULTSORT:Nvidia Graphics Processing Units, List Of}}
[[Category:Computing comparisons|NVIDIA Graphics Processing Units]]
[[Category:Nvidia|*List Of NVIDIA Graphics Processing Units]]
[[Category:Video cards|*List Of NVIDIA Graphics Processing Units]]
